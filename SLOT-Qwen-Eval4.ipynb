{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3d0216445bd77a79"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from pylab import mpl, plt\n",
    "import matplotlib.patches as mpatches\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# best font and style settings for notebook \n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style(\"white\")\n",
    "mpl.rcParams['font.family'] = 'MiSans'\n",
    "\n",
    "model_path = r\"D:\\pythonProject\\DeepSeek\\Recsys\\AnimeLLMRec\\Qwen3-0.6B\"  # modify to your Qwen Path\n",
    "model_path = r\"./Qwen3-1.7B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c40a0c8ce972a1a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from delta_trainer import train_delta_from_H, generate_by_H, evaluate_slot_ceval, evaluate_slot_ceval_eos, \\\n",
    "    evaluate_slot_ceval_eos_2\n",
    "\n",
    "# æ„é€  prompt & å¾—åˆ° H_state\n",
    "prompt = \"è¯·å†™ä¸€æ®µå…³äºAIæ•™è‚²çš„å¼•è¨€ã€‚\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs, output_hidden_states=True, return_dict=True)\n",
    "H = outputs.hidden_states[-1]\n",
    "\n",
    "# è°ƒç”¨ delta è®­ç»ƒ\n",
    "delta_3 = train_delta_from_H(model, tokenizer, prompt, H, step=3)\n",
    "delta_10 = train_delta_from_H(model, tokenizer, prompt, H, step=10)\n",
    "delta_30 = train_delta_from_H(model, tokenizer, prompt, H, step=30)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc16caa5c81a8ab2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# generate_by_H(model=model, prompt=prompt, tokenizer=tokenizer, delta=delta_3, answer_len=200)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d86f37fe68c63257",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from datasets import get_dataset_config_names\n",
    "\n",
    "# è·å–æœ¬åœ°è·¯å¾„ \"./ceval-exam\" ä¸­å¯ç”¨çš„æ‰€æœ‰å­æ•°æ®é›†åç§°ï¼ˆconfig namesï¼‰\n",
    "dataset_path = \"./ceval-exam\"\n",
    "dataset_names = get_dataset_config_names(path=dataset_path)\n",
    "dataset_names"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c9ac52d60c83894",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(r\"./ceval-exam\", name=\"computer_network\")\n",
    "print(dataset['val'][0])"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def evaluate_slot_ceval_eos(model, tokenizer, delta, example, max_len=20, verbose=True):\n",
    "    \"\"\"\n",
    "    åŸºäº generate_by_H_eos çš„è¯„ä¼°å‡½æ•°ï¼Œç”¨äº C-Eval å•é€‰é¢˜ç›®ã€‚\n",
    "\n",
    "    è¿”å›ï¼š\n",
    "    - predict_option: é¢„æµ‹é€‰é¡¹ï¼Œå¦‚ 'A'\n",
    "    - is_correct: æ˜¯å¦é¢„æµ‹æ­£ç¡®\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"ä»¥ä¸‹æ˜¯ä¸€é“å•é¡¹é€‰æ‹©é¢˜ï¼Œè¯·ä½ é˜…è¯»é¢˜ç›®å¹¶é€‰æ‹©æœ€åˆé€‚çš„é€‰é¡¹ã€‚\n",
    "\n",
    "é¢˜ç›®ï¼š{example['question']}\n",
    "\n",
    "é€‰é¡¹ï¼š\n",
    "A. {example['A']}\n",
    "B. {example['B']}\n",
    "C. {example['C']}\n",
    "D. {example['D']}\n",
    "\n",
    "ç­”æ¡ˆæ˜¯ï¼š\"\"\"\n",
    "\n",
    "    output_text = generate_by_H_eos(model, prompt, tokenizer, delta, answer_len=max_len)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"ğŸ” æ¨¡å‹ç”Ÿæˆç»“æœ:\\n\", output_text)\n",
    "\n",
    "    predict_option = None\n",
    "    for option in ['A', 'B', 'C', 'D']:\n",
    "        if option in output_text:\n",
    "            predict_option = option\n",
    "            break\n",
    "\n",
    "    is_correct = (predict_option == example['answer'])\n",
    "    # return predict_option, is_correct\n",
    "    return output_text, predict_option, example['answer'], is_correct"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "154970daa54d317c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# dataset_name = \"computer_network\"\n",
    "# dataset = load_dataset(r\"./ceval-exam\", name=dataset_name)\n",
    "# \n",
    "# correct = 0\n",
    "# total = 0\n",
    "# \n",
    "# answer_sheet = []\n",
    "# for ex in tqdm(dataset['val'], desc=\"Evaluating per-question delta\"):\n",
    "#     # === æ„é€ æ¯é“é¢˜çš„ Prompt ===\n",
    "#     prompt = f\"\"\"ä»¥ä¸‹æ˜¯ä¸€é“å•é¡¹é€‰æ‹©é¢˜ï¼Œè¯·ä½ é˜…è¯»é¢˜ç›®ï¼Œç»“åˆé¢˜ç›®çš„çŸ¥è¯†èƒŒæ™¯ï¼Œé€‰æ‹©æœ€åˆé€‚çš„é€‰é¡¹ã€‚\n",
    "#     é¢˜ç›®ï¼š{ex['question']}\n",
    "#     \n",
    "#     é€‰é¡¹ï¼š\n",
    "#     A. {ex['A']}\n",
    "#     B. {ex['B']}\n",
    "#     C. {ex['C']}\n",
    "#     D. {ex['D']}\n",
    "#     \n",
    "#     ç­”æ¡ˆæ˜¯ï¼š\"\"\"\n",
    "# \n",
    "#     # === è·å– H_state ===\n",
    "#     inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs, output_hidden_states=True, return_dict=True)\n",
    "#     H = outputs.hidden_states[-1]\n",
    "# \n",
    "#     # === è®­ç»ƒ deltaï¼ˆä¾‹å¦‚3æ­¥ï¼‰===\n",
    "#     delta = train_delta_from_H(model, tokenizer, prompt, H, step=30)\n",
    "# \n",
    "#     # === æ¨ç†ä¸è¯„ä¼° ===\n",
    "#     pred, pre_answer, answer, is_correct = evaluate_slot_ceval_eos(model, tokenizer, delta, ex, max_len=20,\n",
    "#                                                                    verbose=False)\n",
    "#     correct += int(is_correct)\n",
    "#     total += 1\n",
    "#     answer_sheet.append([pred, pre_answer, answer, is_correct, dataset_name])\n",
    "# print(f\"ğŸ¯ Accuracy (per-question delta): {correct}/{total} = {correct / total:.2%}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52ec9dd491c117a1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def evaluate_slot_ceval_eos(model, tokenizer, delta, example, prompt, max_len=20, verbose=True):\n",
    "    \"\"\"\n",
    "    åŸºäº generate_by_H_eos çš„è¯„ä¼°å‡½æ•°ï¼Œç”¨äº C-Eval å•é€‰é¢˜ç›®ã€‚\n",
    "\n",
    "    è¿”å›ï¼š\n",
    "    - predict_option: é¢„æµ‹é€‰é¡¹ï¼Œå¦‚ 'A'\n",
    "    - is_correct: æ˜¯å¦é¢„æµ‹æ­£ç¡®\n",
    "    # \"\"\"\n",
    "\n",
    "    output_text = generate_by_H_eos(model, prompt, tokenizer, delta, answer_len=max_len)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"ğŸ” æ¨¡å‹ç”Ÿæˆç»“æœ:\\n\", output_text)\n",
    "\n",
    "    predict_option = None\n",
    "    for option in ['A', 'B', 'C', 'D']:\n",
    "        if option in output_text:\n",
    "            predict_option = option\n",
    "            break\n",
    "\n",
    "    is_correct = (predict_option == example['answer'])\n",
    "    # return predict_option, is_correct\n",
    "    return output_text, predict_option, example['answer'], is_correct\n",
    "\n",
    "\n",
    "def eval_dataset(dataset_name, step=3, max_len=50, lr=1e-2):\n",
    "    # dataset_name = \"computer_network\"\n",
    "    dataset = load_dataset(r\"./ceval-exam\", name=dataset_name)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    answer_sheet = []\n",
    "    for ex in tqdm(dataset['val']):\n",
    "        # === æ„é€ æ¯é“é¢˜çš„ Prompt ===\n",
    "        prompt = f\"\"\"ä»¥ä¸‹æ˜¯ä¸€é“å•é¡¹é€‰æ‹©é¢˜ï¼Œè¯·ä½ é˜…è¯»é¢˜ç›®ï¼Œé€‰æ‹©æœ€åˆé€‚çš„é€‰é¡¹ã€‚\n",
    "        é¢˜ç›®ï¼š{ex['question']}\n",
    "        é€‰é¡¹ï¼š\n",
    "        A. {ex['A']}\n",
    "        B. {ex['B']}\n",
    "        C. {ex['C']}\n",
    "        D. {ex['D']}\n",
    "        ç­”æ¡ˆæ˜¯ï¼š\"\"\"\n",
    "        prompt = f\"\"\"è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\n",
    "        \n",
    "        é¢˜ç›®ï¼š\n",
    "        {ex['question']}\n",
    "        \n",
    "        é€‰é¡¹ï¼š\n",
    "        A. {ex['A']}\n",
    "        B. {ex['B']}\n",
    "        C. {ex['C']}\n",
    "        D. {ex['D']}\n",
    "        \n",
    "        è¯·ç›´æ¥å›ç­”é€‰é¡¹å­—æ¯ï¼ˆA/B/C/Dï¼‰ã€‚\n",
    "        ç­”æ¡ˆæ˜¯ï¼š\"\"\"\n",
    "\n",
    "        # === è·å– H_state ===\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs, output_hidden_states=True, return_dict=True)\n",
    "        H = outputs.hidden_states[-1]\n",
    "\n",
    "        # === è®­ç»ƒ deltaï¼ˆä¾‹å¦‚3æ­¥ï¼‰===\n",
    "        delta = train_delta_from_H(model, tokenizer, prompt, H, step=step, lr=lr)\n",
    "\n",
    "        # === æ¨ç†ä¸è¯„ä¼° ===\n",
    "        pred_txt, pre_answer, answer, is_correct = evaluate_slot_ceval_eos(model=model, tokenizer=tokenizer,\n",
    "                                                                           delta=delta,\n",
    "                                                                           example=ex, max_len=max_len, prompt=prompt,\n",
    "                                                                           verbose=False)\n",
    "        correct += int(is_correct)\n",
    "        total += 1\n",
    "        answer_sheet.append([prompt, pred_txt, pre_answer, answer, is_correct, dataset_name])\n",
    "    print(f\"ğŸ¯ {dataset_name} Accuracy (per-question delta): {correct}/{total} = {correct / total:.2%}\")\n",
    "    return answer_sheet"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24d29f838758eb6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from delta_trainer import generate_by_H_eos\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d14006ad9fb5ee14",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(dataset_names)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d1a41f8865f96fe",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "step = 9\n",
    "max_len = 10\n",
    "answer_sheet = []\n",
    "for i in tqdm(dataset_names[:]):\n",
    "    answer_sheet += eval_dataset(i, step=step, max_len=max_len)\n",
    "    df_answer = pd.DataFrame(answer_sheet)\n",
    "    df_answer.to_csv(f\"./eval_result/1_7B/answer_step_{step}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b1d64dcbc199153",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "step = 6\n",
    "max_len = 10\n",
    "answer_sheet = []\n",
    "for i in tqdm(dataset_names[:]):\n",
    "    answer_sheet += eval_dataset(i, step=step, max_len=max_len)\n",
    "    df_answer = pd.DataFrame(answer_sheet)\n",
    "    df_answer.to_csv(f\"./eval_result/1_7B/answer_step_{step}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b893d03f381eabb2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "step = 3\n",
    "max_len = 10\n",
    "answer_sheet = []\n",
    "for i in tqdm(dataset_names[:]):\n",
    "    answer_sheet += eval_dataset(i, step=step, max_len=max_len)\n",
    "    df_answer = pd.DataFrame(answer_sheet)\n",
    "    df_answer.to_csv(f\"./eval_result/1_7B/answer_step_{step}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6f11cbd929207da",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "step = 0\n",
    "max_len = 10\n",
    "answer_sheet = []\n",
    "for i in tqdm(dataset_names[:]):\n",
    "    answer_sheet += eval_dataset(i, step=step, max_len=max_len)\n",
    "    df_answer = pd.DataFrame(answer_sheet)\n",
    "    df_answer.to_csv(f\"./eval_result/1_7B/answer_step_{step}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "723b68c8959da502",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                                      0  \\\n0     è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...   \n1     è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...   \n2     è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...   \n3     è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...   \n4     è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...   \n...                                                 ...   \n1341  è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...   \n1342  è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...   \n1343  è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...   \n1344  è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...   \n1345  è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...   \n\n                                         1  2  3      4                    5  \n0                      D\\n        ä½ çš„å›ç­”åº”ä¸ºï¼šD  D  D   True           accountant  \n1     C\\n        è¯·è¯´æ˜ç†ç”±ã€‚\\n        \\n         C  C   True           accountant  \n2     D\\n        è¯·è¯´æ˜ç†ç”±ã€‚\\n        \\n         D  D   True           accountant  \n3             A\\n        è¯·è¯´æ˜ç†ç”±ã€‚\\n        ï¿½  A  A   True           accountant  \n4     C\\n        è¯·è¯´æ˜ç†ç”±ã€‚\\n        \\n         C  C   True           accountant  \n...                                    ... .. ..    ...                  ...  \n1341  A\\n        è¯·è¯´æ˜ç†ç”±ã€‚\\n        \\n         A  A   True  veterinary_medicine  \n1342                   D\\n        è¯·è¯´æ˜ç†ç”±ï¼š æœ¬  D  D   True  veterinary_medicine  \n1343                   C\\n        è¯·è¯´æ˜ç†ç”±ï¼š è¯¥  C  A  False  veterinary_medicine  \n1344  C\\n        è¯·è¯´æ˜ç†ç”±ã€‚\\n        \\n         C  C   True  veterinary_medicine  \n1345          C\\n        è¯·è¯´æ˜ç†ç”±ï¼š\\n        ï¿½  C  C   True  veterinary_medicine  \n\n[1346 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...</td>\n      <td>D\\n        ä½ çš„å›ç­”åº”ä¸ºï¼šD</td>\n      <td>D</td>\n      <td>D</td>\n      <td>True</td>\n      <td>accountant</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...</td>\n      <td>C\\n        è¯·è¯´æ˜ç†ç”±ã€‚\\n        \\n</td>\n      <td>C</td>\n      <td>C</td>\n      <td>True</td>\n      <td>accountant</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...</td>\n      <td>D\\n        è¯·è¯´æ˜ç†ç”±ã€‚\\n        \\n</td>\n      <td>D</td>\n      <td>D</td>\n      <td>True</td>\n      <td>accountant</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...</td>\n      <td>A\\n        è¯·è¯´æ˜ç†ç”±ã€‚\\n        ï¿½</td>\n      <td>A</td>\n      <td>A</td>\n      <td>True</td>\n      <td>accountant</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...</td>\n      <td>C\\n        è¯·è¯´æ˜ç†ç”±ã€‚\\n        \\n</td>\n      <td>C</td>\n      <td>C</td>\n      <td>True</td>\n      <td>accountant</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1341</th>\n      <td>è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...</td>\n      <td>A\\n        è¯·è¯´æ˜ç†ç”±ã€‚\\n        \\n</td>\n      <td>A</td>\n      <td>A</td>\n      <td>True</td>\n      <td>veterinary_medicine</td>\n    </tr>\n    <tr>\n      <th>1342</th>\n      <td>è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...</td>\n      <td>D\\n        è¯·è¯´æ˜ç†ç”±ï¼š æœ¬</td>\n      <td>D</td>\n      <td>D</td>\n      <td>True</td>\n      <td>veterinary_medicine</td>\n    </tr>\n    <tr>\n      <th>1343</th>\n      <td>è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...</td>\n      <td>C\\n        è¯·è¯´æ˜ç†ç”±ï¼š è¯¥</td>\n      <td>C</td>\n      <td>A</td>\n      <td>False</td>\n      <td>veterinary_medicine</td>\n    </tr>\n    <tr>\n      <th>1344</th>\n      <td>è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...</td>\n      <td>C\\n        è¯·è¯´æ˜ç†ç”±ã€‚\\n        \\n</td>\n      <td>C</td>\n      <td>C</td>\n      <td>True</td>\n      <td>veterinary_medicine</td>\n    </tr>\n    <tr>\n      <th>1345</th>\n      <td>è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...</td>\n      <td>C\\n        è¯·è¯´æ˜ç†ç”±ï¼š\\n        ï¿½</td>\n      <td>C</td>\n      <td>C</td>\n      <td>True</td>\n      <td>veterinary_medicine</td>\n    </tr>\n  </tbody>\n</table>\n<p>1346 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(answer_sheet)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-06T13:19:57.383527900Z",
     "start_time": "2025-06-06T13:19:57.360527600Z"
    }
   },
   "id": "a2795484e22285b5",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for ex in tqdm(dataset['test'], desc=\"Evaluating per-question delta\"):\n",
    "    # === æ„é€ æ¯é“é¢˜çš„ Prompt ===\n",
    "    prompt = f\"\"\"ä»¥ä¸‹æ˜¯ä¸€é“å•é¡¹é€‰æ‹©é¢˜ï¼Œè¯·ä½ é˜…è¯»é¢˜ç›®å¹¶é€‰æ‹©æœ€åˆé€‚çš„é€‰é¡¹ã€‚\n",
    "\n",
    "é¢˜ç›®ï¼š{ex['question']}\n",
    "\n",
    "é€‰é¡¹ï¼š\n",
    "A. {ex['A']}\n",
    "B. {ex['B']}\n",
    "C. {ex['C']}\n",
    "D. {ex['D']}\n",
    "\n",
    "ç­”æ¡ˆæ˜¯ï¼š\"\"\"\n",
    "\n",
    "    # === è·å– H_state ===\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True, return_dict=True)\n",
    "    H = outputs.hidden_states[-1]\n",
    "\n",
    "    # === è®­ç»ƒ deltaï¼ˆä¾‹å¦‚3æ­¥ï¼‰===\n",
    "    delta = train_delta_from_H(model, tokenizer, prompt, H, step=3)\n",
    "\n",
    "    # === æ¨ç†ä¸è¯„ä¼° ===\n",
    "    pred, is_correct = evaluate_slot_ceval_eos(model, tokenizer, delta, ex, max_len=200, verbose=False)\n",
    "    print(pred, ex)\n",
    "    correct += int(is_correct)\n",
    "    total += 1\n",
    "\n",
    "print(f\"ğŸ¯ Accuracy (per-question delta): {correct}/{total} = {correct / total:.2%}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbe6e22059438a2c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_empty_delta(H_state):\n",
    "    hidden_size = H_state.size(-1)\n",
    "    delta = nn.Parameter(torch.zeros((1, 1, hidden_size), device=H_state.device, requires_grad=True))\n",
    "\n",
    "    return delta\n",
    "\n",
    "\n",
    "delta_empty = get_empty_delta(H_state=H)\n",
    "delta_empty.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce3f8fac32a9d102",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for ex in tqdm(dataset['test'], desc=\"Evaluating per-question delta\"):\n",
    "    # === æ„é€ æ¯é“é¢˜çš„ Prompt ===\n",
    "    prompt = f\"\"\"ä»¥ä¸‹æ˜¯ä¸€é“å•é¡¹é€‰æ‹©é¢˜ï¼Œè¯·ä½ é˜…è¯»é¢˜ç›®å¹¶é€‰æ‹©æœ€åˆé€‚çš„é€‰é¡¹ã€‚\n",
    "    \n",
    "    é¢˜ç›®ï¼š{ex['question']}\n",
    "    \n",
    "    é€‰é¡¹ï¼š\n",
    "    A. {ex['A']}\n",
    "    B. {ex['B']}\n",
    "    C. {ex['C']}\n",
    "    D. {ex['D']}\n",
    "    \n",
    "    ç­”æ¡ˆæ˜¯ï¼š\"\"\"\n",
    "\n",
    "    # === æ¨ç†ä¸è¯„ä¼° ===\n",
    "    pred, is_correct = evaluate_slot_ceval_eos(model, tokenizer, delta_empty, ex, max_len=20, verbose=True)\n",
    "    correct += int(is_correct)\n",
    "    total += 1\n",
    "\n",
    "print(f\"ğŸ¯ Accuracy (per-question delta): {correct}/{total} = {correct / total:.2%}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a559f50747db9f70",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from delta_trainer import generate_by_H_eos\n",
    "\n",
    "\n",
    "def evaluate_slot_ceval_eos_2(model, tokenizer, delta, example, max_len=20, verbose=True):\n",
    "    \"\"\"\n",
    "    åŸºäº generate_by_H_eos çš„è¯„ä¼°å‡½æ•°ï¼Œç”¨äº C-Eval å•é€‰é¢˜ç›®ã€‚\n",
    "\n",
    "    è¿”å›ï¼š\n",
    "    - predict_option: é¢„æµ‹é€‰é¡¹ï¼Œå¦‚ 'A'\n",
    "    - is_correct: æ˜¯å¦é¢„æµ‹æ­£ç¡®\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"ä»¥ä¸‹æ˜¯ä¸€é“å•é¡¹é€‰æ‹©é¢˜ï¼Œè¯·ä½ é˜…è¯»é¢˜ç›®å¹¶é€‰æ‹©æœ€åˆé€‚çš„é€‰é¡¹ã€‚\n",
    "\n",
    "é¢˜ç›®ï¼š{example['question']}\n",
    "\n",
    "é€‰é¡¹ï¼š\n",
    "A. {example['A']}\n",
    "B. {example['B']}\n",
    "C. {example['C']}\n",
    "D. {example['D']}\n",
    "\n",
    "ç­”æ¡ˆæ˜¯ï¼š\"\"\"\n",
    "\n",
    "    output_text = generate_by_H_eos(model, prompt, tokenizer, delta, answer_len=max_len)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"ğŸ” æ¨¡å‹ç”Ÿæˆç»“æœ:\\n\", output_text)\n",
    "\n",
    "    predict_option = None\n",
    "    for option in ['A', 'B', 'C', 'D']:\n",
    "        if option in output_text:\n",
    "            predict_option = option\n",
    "            break\n",
    "\n",
    "    print(predict_option, example['answer'])\n",
    "    is_correct = (predict_option == example['answer'])\n",
    "    return predict_option, predict_option, example['answer']\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7274c61d5f52b83d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for ex in tqdm(dataset['test'], desc=\"Evaluating per-question delta\"):\n",
    "    # === æ„é€ æ¯é“é¢˜çš„ Prompt ===\n",
    "    prompt = f\"\"\"ä»¥ä¸‹æ˜¯ä¸€é“å•é¡¹é€‰æ‹©é¢˜ï¼Œè¯·ä½ é˜…è¯»é¢˜ç›®å¹¶é€‰æ‹©æœ€åˆé€‚çš„é€‰é¡¹ã€‚\n",
    "    \n",
    "    é¢˜ç›®ï¼š{ex['question']}\n",
    "    \n",
    "    é€‰é¡¹ï¼š\n",
    "    A. {ex['A']}\n",
    "    B. {ex['B']}\n",
    "    C. {ex['C']}\n",
    "    D. {ex['D']}\n",
    "    \n",
    "    ç­”æ¡ˆæ˜¯ï¼š\"\"\"\n",
    "\n",
    "    # === æ¨ç†ä¸è¯„ä¼° ===\n",
    "    pred, predict, truth = evaluate_slot_ceval_eos_2(model, tokenizer, delta_empty, ex, max_len=20, verbose=False)\n",
    "    # print(predict,truth)\n",
    "    correct += int(predict == truth)\n",
    "    total += 1\n",
    "\n",
    "print(f\"ğŸ¯ Accuracy (per-question delta): {correct}/{total} = {correct / total:.2%}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bacbd63589b8d55",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for ex in tqdm(dataset['val'], desc=\"Evaluating per-question delta\"):\n",
    "    # === æ„é€ æ¯é“é¢˜çš„ Prompt ===\n",
    "    prompt = f\"\"\"ä»¥ä¸‹æ˜¯ä¸€é“å•é¡¹é€‰æ‹©é¢˜ï¼Œè¯·ä½ é˜…è¯»é¢˜ç›®å¹¶é€‰æ‹©æœ€åˆé€‚çš„é€‰é¡¹ã€‚\n",
    "\n",
    "é¢˜ç›®ï¼š{ex['question']}\n",
    "\n",
    "é€‰é¡¹ï¼š\n",
    "A. {ex['A']}\n",
    "B. {ex['B']}\n",
    "C. {ex['C']}\n",
    "D. {ex['D']}\n",
    "\n",
    "ç­”æ¡ˆæ˜¯ï¼š\"\"\"\n",
    "    print(prompt)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3be944ae2d6143b",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
