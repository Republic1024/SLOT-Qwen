{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3d0216445bd77a79"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from pylab import mpl, plt\n",
    "import matplotlib.patches as mpatches\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# best font and style settings for notebook \n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style(\"white\")\n",
    "mpl.rcParams['font.family'] = 'MiSans'\n",
    "\n",
    "model_path = r\"D:\\pythonProject\\DeepSeek\\Recsys\\AnimeLLMRec\\Qwen3-0.6B\"  # modify to your Qwen Path\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T20:31:30.114936900Z",
     "start_time": "2025-06-05T20:31:27.981911100Z"
    }
   },
   "id": "5c40a0c8ce972a1a",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from delta_trainer import train_delta_from_H, generate_by_H, evaluate_slot_ceval, evaluate_slot_ceval_eos, \\\n",
    "    evaluate_slot_ceval_eos_2\n",
    "\n",
    "# æ„é€  prompt & å¾—åˆ° H_state\n",
    "prompt = \"è¯·å†™ä¸€æ®µå…³äºAIæ•™è‚²çš„å¼•è¨€ã€‚\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs, output_hidden_states=True, return_dict=True)\n",
    "H = outputs.hidden_states[-1]\n",
    "\n",
    "# è°ƒç”¨ delta è®­ç»ƒ\n",
    "delta_3 = train_delta_from_H(model, tokenizer, prompt, H, step=3)\n",
    "delta_10 = train_delta_from_H(model, tokenizer, prompt, H, step=10)\n",
    "delta_30 = train_delta_from_H(model, tokenizer, prompt, H, step=30)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T20:31:30.381972100Z",
     "start_time": "2025-06-05T20:31:30.116937Z"
    }
   },
   "id": "cc16caa5c81a8ab2",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# generate_by_H(model=model, prompt=prompt, tokenizer=tokenizer, delta=delta_3, answer_len=200)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T20:31:30.397971600Z",
     "start_time": "2025-06-05T20:31:30.382971500Z"
    }
   },
   "id": "d86f37fe68c63257",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['accountant',\n 'advanced_mathematics',\n 'art_studies',\n 'basic_medicine',\n 'business_administration',\n 'chinese_language_and_literature',\n 'civil_servant',\n 'clinical_medicine',\n 'college_chemistry',\n 'college_economics',\n 'college_physics',\n 'college_programming',\n 'computer_architecture',\n 'computer_network',\n 'discrete_mathematics',\n 'education_science',\n 'electrical_engineer',\n 'environmental_impact_assessment_engineer',\n 'fire_engineer',\n 'high_school_biology',\n 'high_school_chemistry',\n 'high_school_chinese',\n 'high_school_geography',\n 'high_school_history',\n 'high_school_mathematics',\n 'high_school_physics',\n 'high_school_politics',\n 'ideological_and_moral_cultivation',\n 'law',\n 'legal_professional',\n 'logic',\n 'mao_zedong_thought',\n 'marxism',\n 'metrology_engineer',\n 'middle_school_biology',\n 'middle_school_chemistry',\n 'middle_school_geography',\n 'middle_school_history',\n 'middle_school_mathematics',\n 'middle_school_physics',\n 'middle_school_politics',\n 'modern_chinese_history',\n 'operating_system',\n 'physician',\n 'plant_protection',\n 'probability_and_statistics',\n 'professional_tour_guide',\n 'sports_science',\n 'tax_accountant',\n 'teacher_qualification',\n 'urban_and_rural_planner',\n 'veterinary_medicine']"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import get_dataset_config_names\n",
    "\n",
    "# è·å–æœ¬åœ°è·¯å¾„ \"./ceval-exam\" ä¸­å¯ç”¨çš„æ‰€æœ‰å­æ•°æ®é›†åç§°ï¼ˆconfig namesï¼‰\n",
    "dataset_path = \"./ceval-exam\"\n",
    "dataset_names = get_dataset_config_names(path=dataset_path)\n",
    "dataset_names"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T20:31:30.557972100Z",
     "start_time": "2025-06-05T20:31:30.398973100Z"
    }
   },
   "id": "1c9ac52d60c83894",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-05T20:31:30.729274300Z",
     "start_time": "2025-06-05T20:31:30.560974600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 0, 'question': 'ä½¿ç”¨ä½å¡«å……æ–¹æ³•ï¼Œä»¥01111110ä¸ºä½é¦–flagï¼Œæ•°æ®ä¸º011011111111111111110010ï¼Œæ±‚é—®ä¼ é€æ—¶è¦æ·»åŠ å‡ ä¸ª0____', 'A': '1', 'B': '2', 'C': '3', 'D': '4', 'answer': 'C', 'explanation': ''}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(r\"./ceval-exam\", name=\"computer_network\")\n",
    "print(dataset['val'][0])"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def evaluate_slot_ceval_eos(model, tokenizer, delta, example, max_len=20, verbose=True):\n",
    "    \"\"\"\n",
    "    åŸºäº generate_by_H_eos çš„è¯„ä¼°å‡½æ•°ï¼Œç”¨äº C-Eval å•é€‰é¢˜ç›®ã€‚\n",
    "\n",
    "    è¿”å›ï¼š\n",
    "    - predict_option: é¢„æµ‹é€‰é¡¹ï¼Œå¦‚ 'A'\n",
    "    - is_correct: æ˜¯å¦é¢„æµ‹æ­£ç¡®\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"ä»¥ä¸‹æ˜¯ä¸€é“å•é¡¹é€‰æ‹©é¢˜ï¼Œè¯·ä½ é˜…è¯»é¢˜ç›®å¹¶é€‰æ‹©æœ€åˆé€‚çš„é€‰é¡¹ã€‚\n",
    "\n",
    "é¢˜ç›®ï¼š{example['question']}\n",
    "\n",
    "é€‰é¡¹ï¼š\n",
    "A. {example['A']}\n",
    "B. {example['B']}\n",
    "C. {example['C']}\n",
    "D. {example['D']}\n",
    "\n",
    "ç­”æ¡ˆæ˜¯ï¼š\"\"\"\n",
    "\n",
    "    output_text = generate_by_H_eos(model, prompt, tokenizer, delta, answer_len=max_len)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"ğŸ” æ¨¡å‹ç”Ÿæˆç»“æœ:\\n\", output_text)\n",
    "\n",
    "    predict_option = None\n",
    "    for option in ['A', 'B', 'C', 'D']:\n",
    "        if option in output_text:\n",
    "            predict_option = option\n",
    "            break\n",
    "\n",
    "    is_correct = (predict_option == example['answer'])\n",
    "    # return predict_option, is_correct\n",
    "    return output_text, predict_option, example['answer'], is_correct"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T20:31:30.742273900Z",
     "start_time": "2025-06-05T20:31:30.729274300Z"
    }
   },
   "id": "154970daa54d317c",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# dataset_name = \"computer_network\"\n",
    "# dataset = load_dataset(r\"./ceval-exam\", name=dataset_name)\n",
    "# \n",
    "# correct = 0\n",
    "# total = 0\n",
    "# \n",
    "# answer_sheet = []\n",
    "# for ex in tqdm(dataset['val'], desc=\"Evaluating per-question delta\"):\n",
    "#     # === æ„é€ æ¯é“é¢˜çš„ Prompt ===\n",
    "#     prompt = f\"\"\"ä»¥ä¸‹æ˜¯ä¸€é“å•é¡¹é€‰æ‹©é¢˜ï¼Œè¯·ä½ é˜…è¯»é¢˜ç›®ï¼Œç»“åˆé¢˜ç›®çš„çŸ¥è¯†èƒŒæ™¯ï¼Œé€‰æ‹©æœ€åˆé€‚çš„é€‰é¡¹ã€‚\n",
    "#     é¢˜ç›®ï¼š{ex['question']}\n",
    "#     \n",
    "#     é€‰é¡¹ï¼š\n",
    "#     A. {ex['A']}\n",
    "#     B. {ex['B']}\n",
    "#     C. {ex['C']}\n",
    "#     D. {ex['D']}\n",
    "#     \n",
    "#     ç­”æ¡ˆæ˜¯ï¼š\"\"\"\n",
    "# \n",
    "#     # === è·å– H_state ===\n",
    "#     inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs, output_hidden_states=True, return_dict=True)\n",
    "#     H = outputs.hidden_states[-1]\n",
    "# \n",
    "#     # === è®­ç»ƒ deltaï¼ˆä¾‹å¦‚3æ­¥ï¼‰===\n",
    "#     delta = train_delta_from_H(model, tokenizer, prompt, H, step=30)\n",
    "# \n",
    "#     # === æ¨ç†ä¸è¯„ä¼° ===\n",
    "#     pred, pre_answer, answer, is_correct = evaluate_slot_ceval_eos(model, tokenizer, delta, ex, max_len=20,\n",
    "#                                                                    verbose=False)\n",
    "#     correct += int(is_correct)\n",
    "#     total += 1\n",
    "#     answer_sheet.append([pred, pre_answer, answer, is_correct, dataset_name])\n",
    "# print(f\"ğŸ¯ Accuracy (per-question delta): {correct}/{total} = {correct / total:.2%}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T20:31:30.773334400Z",
     "start_time": "2025-06-05T20:31:30.744274700Z"
    }
   },
   "id": "52ec9dd491c117a1",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def evaluate_slot_ceval_eos(model, tokenizer, delta, example, prompt, max_len=20, verbose=True):\n",
    "    \"\"\"\n",
    "    åŸºäº generate_by_H_eos çš„è¯„ä¼°å‡½æ•°ï¼Œç”¨äº C-Eval å•é€‰é¢˜ç›®ã€‚\n",
    "\n",
    "    è¿”å›ï¼š\n",
    "    - predict_option: é¢„æµ‹é€‰é¡¹ï¼Œå¦‚ 'A'\n",
    "    - is_correct: æ˜¯å¦é¢„æµ‹æ­£ç¡®\n",
    "    # \"\"\"\n",
    "\n",
    "    output_text = generate_by_H_eos(model, prompt, tokenizer, delta, answer_len=max_len)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"ğŸ” æ¨¡å‹ç”Ÿæˆç»“æœ:\\n\", output_text)\n",
    "\n",
    "    predict_option = None\n",
    "    for option in ['A', 'B', 'C', 'D']:\n",
    "        if option in output_text:\n",
    "            predict_option = option\n",
    "            break\n",
    "\n",
    "    is_correct = (predict_option == example['answer'])\n",
    "    # return predict_option, is_correct\n",
    "    return output_text, predict_option, example['answer'], is_correct\n",
    "\n",
    "\n",
    "def eval_dataset(dataset_name, step=3, max_len=50):\n",
    "    # dataset_name = \"computer_network\"\n",
    "    dataset = load_dataset(r\"./ceval-exam\", name=dataset_name)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    answer_sheet = []\n",
    "    for ex in dataset['val']:\n",
    "        # === æ„é€ æ¯é“é¢˜çš„ Prompt ===\n",
    "        prompt = f\"\"\"ä»¥ä¸‹æ˜¯ä¸€é“å•é¡¹é€‰æ‹©é¢˜ï¼Œè¯·ä½ é˜…è¯»é¢˜ç›®ï¼Œé€‰æ‹©æœ€åˆé€‚çš„é€‰é¡¹ã€‚\n",
    "        é¢˜ç›®ï¼š{ex['question']}\n",
    "        é€‰é¡¹ï¼š\n",
    "        A. {ex['A']}\n",
    "        B. {ex['B']}\n",
    "        C. {ex['C']}\n",
    "        D. {ex['D']}\n",
    "        ç­”æ¡ˆæ˜¯ï¼š\"\"\"\n",
    "        prompt = f\"\"\"è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\n",
    "        \n",
    "        é¢˜ç›®ï¼š\n",
    "        {ex['question']}\n",
    "        \n",
    "        é€‰é¡¹ï¼š\n",
    "        A. {ex['A']}\n",
    "        B. {ex['B']}\n",
    "        C. {ex['C']}\n",
    "        D. {ex['D']}\n",
    "        \n",
    "        è¯·ç›´æ¥å›ç­”é€‰é¡¹å­—æ¯ï¼ˆA/B/C/Dï¼‰ã€‚\n",
    "        ç­”æ¡ˆæ˜¯ï¼š\"\"\"\n",
    "\n",
    "        # === è·å– H_state ===\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs, output_hidden_states=True, return_dict=True)\n",
    "        H = outputs.hidden_states[-1]\n",
    "\n",
    "        # === è®­ç»ƒ deltaï¼ˆä¾‹å¦‚3æ­¥ï¼‰===\n",
    "        delta = train_delta_from_H(model, tokenizer, prompt, H, step=step, lr=1e-1)\n",
    "\n",
    "        # === æ¨ç†ä¸è¯„ä¼° ===\n",
    "        pred_txt, pre_answer, answer, is_correct = evaluate_slot_ceval_eos(model=model, tokenizer=tokenizer,\n",
    "                                                                           delta=delta,\n",
    "                                                                           example=ex, max_len=max_len, prompt=prompt,\n",
    "                                                                           verbose=False)\n",
    "        correct += int(is_correct)\n",
    "        total += 1\n",
    "        answer_sheet.append([prompt, pred_txt, pre_answer, answer, is_correct, dataset_name])\n",
    "    print(f\"ğŸ¯ {dataset_name} Accuracy (per-question delta): {correct}/{total} = {correct / total:.2%}\")\n",
    "    return answer_sheet"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T20:33:06.275776900Z",
     "start_time": "2025-06-05T20:33:06.264777600Z"
    }
   },
   "id": "24d29f838758eb6",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from delta_trainer import generate_by_H_eos\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T20:31:30.793337Z",
     "start_time": "2025-06-05T20:31:30.775335700Z"
    }
   },
   "id": "d14006ad9fb5ee14",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "52"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_names)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T20:31:30.808335500Z",
     "start_time": "2025-06-05T20:31:30.792334600Z"
    }
   },
   "id": "4d1a41f8865f96fe",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/52 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "05e7be5bd5b840dfa75f8acb41a5ea42"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ accountant Accuracy (per-question delta): 21/49 = 42.86%\n",
      "ğŸ¯ advanced_mathematics Accuracy (per-question delta): 5/19 = 26.32%\n",
      "ğŸ¯ art_studies Accuracy (per-question delta): 18/33 = 54.55%\n",
      "ğŸ¯ basic_medicine Accuracy (per-question delta): 13/19 = 68.42%\n",
      "ğŸ¯ business_administration Accuracy (per-question delta): 15/33 = 45.45%\n",
      "ğŸ¯ chinese_language_and_literature Accuracy (per-question delta): 12/23 = 52.17%\n",
      "ğŸ¯ civil_servant Accuracy (per-question delta): 17/47 = 36.17%\n",
      "ğŸ¯ clinical_medicine Accuracy (per-question delta): 11/22 = 50.00%\n",
      "ğŸ¯ college_chemistry Accuracy (per-question delta): 12/24 = 50.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "step = 1\n",
    "max_len = 10\n",
    "answer_sheet = []\n",
    "for i in tqdm(dataset_names[:]):\n",
    "    answer_sheet += eval_dataset(i, step=step, max_len=max_len)\n",
    "    df_answer = pd.DataFrame(answer_sheet)\n",
    "    df_answer.to_csv(f\"./eval_result/answer_step_{step}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T20:33:56.078837100Z",
     "start_time": "2025-06-05T20:33:10.697578700Z"
    }
   },
   "id": "d6f11cbd929207da",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/52 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aab6085ea632480ba8f0190306608423"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ accountant Accuracy (per-question delta): 22/49 = 44.90%\n",
      "ğŸ¯ advanced_mathematics Accuracy (per-question delta): 4/19 = 21.05%\n",
      "ğŸ¯ art_studies Accuracy (per-question delta): 15/33 = 45.45%\n",
      "ğŸ¯ basic_medicine Accuracy (per-question delta): 12/19 = 63.16%\n",
      "ğŸ¯ business_administration Accuracy (per-question delta): 16/33 = 48.48%\n",
      "ğŸ¯ chinese_language_and_literature Accuracy (per-question delta): 12/23 = 52.17%\n",
      "ğŸ¯ civil_servant Accuracy (per-question delta): 18/47 = 38.30%\n",
      "ğŸ¯ clinical_medicine Accuracy (per-question delta): 11/22 = 50.00%\n",
      "ğŸ¯ college_chemistry Accuracy (per-question delta): 11/24 = 45.83%\n",
      "ğŸ¯ college_economics Accuracy (per-question delta): 27/55 = 49.09%\n",
      "ğŸ¯ college_physics Accuracy (per-question delta): 11/19 = 57.89%\n",
      "ğŸ¯ college_programming Accuracy (per-question delta): 16/37 = 43.24%\n",
      "ğŸ¯ computer_architecture Accuracy (per-question delta): 7/21 = 33.33%\n",
      "ğŸ¯ computer_network Accuracy (per-question delta): 7/19 = 36.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "step = 2\n",
    "max_len = 10\n",
    "answer_sheet = []\n",
    "for i in tqdm(dataset_names[:]):\n",
    "    answer_sheet += eval_dataset(i, step=step, max_len=max_len)\n",
    "    df_answer = pd.DataFrame(answer_sheet)\n",
    "    df_answer.to_csv(f\"./eval_result/answer_step_{step}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T20:35:09.897408Z",
     "start_time": "2025-06-05T20:33:58.137094100Z"
    }
   },
   "id": "737b124c4a261e39",
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/52 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "984526951272498e90b6fead98da877d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ accountant Accuracy (per-question delta): 22/49 = 44.90%\n",
      "ğŸ¯ advanced_mathematics Accuracy (per-question delta): 4/19 = 21.05%\n",
      "ğŸ¯ art_studies Accuracy (per-question delta): 18/33 = 54.55%\n",
      "ğŸ¯ basic_medicine Accuracy (per-question delta): 13/19 = 68.42%\n",
      "ğŸ¯ business_administration Accuracy (per-question delta): 16/33 = 48.48%\n",
      "ğŸ¯ chinese_language_and_literature Accuracy (per-question delta): 11/23 = 47.83%\n",
      "ğŸ¯ civil_servant Accuracy (per-question delta): 19/47 = 40.43%\n",
      "ğŸ¯ clinical_medicine Accuracy (per-question delta): 12/22 = 54.55%\n",
      "ğŸ¯ college_chemistry Accuracy (per-question delta): 10/24 = 41.67%\n",
      "ğŸ¯ college_economics Accuracy (per-question delta): 26/55 = 47.27%\n",
      "ğŸ¯ college_physics Accuracy (per-question delta): 11/19 = 57.89%\n",
      "ğŸ¯ college_programming Accuracy (per-question delta): 18/37 = 48.65%\n",
      "ğŸ¯ computer_architecture Accuracy (per-question delta): 10/21 = 47.62%\n",
      "ğŸ¯ computer_network Accuracy (per-question delta): 7/19 = 36.84%\n",
      "ğŸ¯ discrete_mathematics Accuracy (per-question delta): 5/16 = 31.25%\n",
      "ğŸ¯ education_science Accuracy (per-question delta): 18/29 = 62.07%\n",
      "ğŸ¯ electrical_engineer Accuracy (per-question delta): 16/37 = 43.24%\n",
      "ğŸ¯ environmental_impact_assessment_engineer Accuracy (per-question delta): 21/31 = 67.74%\n",
      "ğŸ¯ fire_engineer Accuracy (per-question delta): 16/31 = 51.61%\n",
      "ğŸ¯ high_school_biology Accuracy (per-question delta): 7/19 = 36.84%\n",
      "ğŸ¯ high_school_chemistry Accuracy (per-question delta): 11/19 = 57.89%\n",
      "ğŸ¯ high_school_chinese Accuracy (per-question delta): 6/19 = 31.58%\n",
      "ğŸ¯ high_school_geography Accuracy (per-question delta): 8/19 = 42.11%\n",
      "ğŸ¯ high_school_history Accuracy (per-question delta): 16/20 = 80.00%\n",
      "ğŸ¯ high_school_mathematics Accuracy (per-question delta): 6/18 = 33.33%\n",
      "ğŸ¯ high_school_physics Accuracy (per-question delta): 10/19 = 52.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "max_len = 10\n",
    "answer_sheet = []\n",
    "for i in tqdm(dataset_names[:]):\n",
    "    answer_sheet += eval_dataset(i, step=step, max_len=max_len)\n",
    "    df_answer = pd.DataFrame(answer_sheet)\n",
    "    df_answer.to_csv(f\"./eval_result/answer_step_{step}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T20:37:28.943031700Z",
     "start_time": "2025-06-05T20:35:54.274165600Z"
    }
   },
   "id": "582841ba3dde28b9",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "step = 0\n",
    "max_len = 10\n",
    "answer_sheet = []\n",
    "for i in tqdm(dataset_names[:]):\n",
    "    answer_sheet += eval_dataset(i, step=step, max_len=max_len)\n",
    "    df_answer = pd.DataFrame(answer_sheet)\n",
    "    df_answer.to_csv(f\"./eval_result/answer_step_{step}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8df5bc7122f2a604",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "step = 1\n",
    "max_len = 10\n",
    "answer_sheet = []\n",
    "for i in tqdm(dataset_names[:]):\n",
    "    answer_sheet += eval_dataset(i, step=step, max_len=max_len)\n",
    "    df_answer = pd.DataFrame(answer_sheet)\n",
    "    df_answer.to_csv(f\"./eval_result/answer_step_{step}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91d10fdabf1b4e5d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/52 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5503dffb3ece412986d27a58aa681c40"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ accountant Accuracy (per-question delta): 22/49 = 44.90%\n",
      "ğŸ¯ advanced_mathematics Accuracy (per-question delta): 4/19 = 21.05%\n",
      "ğŸ¯ art_studies Accuracy (per-question delta): 18/33 = 54.55%\n",
      "ğŸ¯ basic_medicine Accuracy (per-question delta): 13/19 = 68.42%\n",
      "ğŸ¯ business_administration Accuracy (per-question delta): 16/33 = 48.48%\n",
      "ğŸ¯ chinese_language_and_literature Accuracy (per-question delta): 11/23 = 47.83%\n",
      "ğŸ¯ civil_servant Accuracy (per-question delta): 19/47 = 40.43%\n",
      "ğŸ¯ clinical_medicine Accuracy (per-question delta): 12/22 = 54.55%\n",
      "ğŸ¯ college_chemistry Accuracy (per-question delta): 10/24 = 41.67%\n",
      "ğŸ¯ college_economics Accuracy (per-question delta): 26/55 = 47.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "step = 3\n",
    "max_len = 10\n",
    "answer_sheet = []\n",
    "for i in tqdm(dataset_names[:]):\n",
    "    answer_sheet += eval_dataset(i, step=step, max_len=max_len)\n",
    "    df_answer = pd.DataFrame(answer_sheet)\n",
    "    df_answer.to_csv(f\"./eval_result/answer_step_{step}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T20:28:52.340822600Z",
     "start_time": "2025-06-05T20:28:04.787052400Z"
    }
   },
   "id": "a7407072102a5ba5",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/52 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5079939f12b94f4685c8c714bedee30f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ accountant Accuracy (per-question delta): 20/49 = 40.82%\n",
      "ğŸ¯ advanced_mathematics Accuracy (per-question delta): 4/19 = 21.05%\n",
      "ğŸ¯ art_studies Accuracy (per-question delta): 18/33 = 54.55%\n",
      "ğŸ¯ basic_medicine Accuracy (per-question delta): 13/19 = 68.42%\n",
      "ğŸ¯ business_administration Accuracy (per-question delta): 16/33 = 48.48%\n",
      "ğŸ¯ chinese_language_and_literature Accuracy (per-question delta): 11/23 = 47.83%\n",
      "ğŸ¯ civil_servant Accuracy (per-question delta): 19/47 = 40.43%\n",
      "ğŸ¯ clinical_medicine Accuracy (per-question delta): 12/22 = 54.55%\n",
      "ğŸ¯ college_chemistry Accuracy (per-question delta): 10/24 = 41.67%\n",
      "ğŸ¯ college_economics Accuracy (per-question delta): 26/55 = 47.27%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m answer_sheet \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m tqdm(dataset_names[:]):\n\u001B[1;32m----> 5\u001B[0m     answer_sheet \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43meval_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_len\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_len\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m     df_answer \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(answer_sheet)\n\u001B[0;32m      7\u001B[0m     df_answer\u001B[38;5;241m.\u001B[39mto_csv(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./eval_result/answer_step_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstep\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "Cell \u001B[1;32mIn[7], line 65\u001B[0m, in \u001B[0;36meval_dataset\u001B[1;34m(dataset_name, step, max_len)\u001B[0m\n\u001B[0;32m     62\u001B[0m H \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39mhidden_states[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m     64\u001B[0m \u001B[38;5;66;03m# === è®­ç»ƒ deltaï¼ˆä¾‹å¦‚3æ­¥ï¼‰===\u001B[39;00m\n\u001B[1;32m---> 65\u001B[0m delta \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_delta_from_H\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mH\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     67\u001B[0m \u001B[38;5;66;03m# === æ¨ç†ä¸è¯„ä¼° ===\u001B[39;00m\n\u001B[0;32m     68\u001B[0m pred_txt, pre_answer, answer, is_correct \u001B[38;5;241m=\u001B[39m evaluate_slot_ceval_eos(model\u001B[38;5;241m=\u001B[39mmodel, tokenizer\u001B[38;5;241m=\u001B[39mtokenizer,\n\u001B[0;32m     69\u001B[0m                                                                    delta\u001B[38;5;241m=\u001B[39mdelta,\n\u001B[0;32m     70\u001B[0m                                                                    example\u001B[38;5;241m=\u001B[39mex, max_len\u001B[38;5;241m=\u001B[39mmax_len, prompt\u001B[38;5;241m=\u001B[39mprompt,\n\u001B[0;32m     71\u001B[0m                                                                    verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[1;32m~\\Desktop\\è¥¿æ¹–å¤§å­¦\\week-9\\SLOT-Qwen\\delta_trainer.py:39\u001B[0m, in \u001B[0;36mtrain_delta_from_H\u001B[1;34m(model, tokenizer, prompt, H_state, step, lr)\u001B[0m\n\u001B[0;32m     37\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m     38\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m---> 39\u001B[0m     loss_log\u001B[38;5;241m.\u001B[39mappend(\u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     40\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m delta\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "step = 10\n",
    "max_len = 10\n",
    "answer_sheet = []\n",
    "for i in tqdm(dataset_names[:]):\n",
    "    answer_sheet += eval_dataset(i, step=step, max_len=max_len)\n",
    "    df_answer = pd.DataFrame(answer_sheet)\n",
    "    df_answer.to_csv(f\"./eval_result/answer_step_{step}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T20:29:57.106214Z",
     "start_time": "2025-06-05T20:28:54.063450500Z"
    }
   },
   "id": "89f2dea25ac7f546",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/52 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9207e76a06e043ff825e8f18bf9281fe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ accountant Accuracy (per-question delta): 22/49 = 44.90%\n",
      "ğŸ¯ advanced_mathematics Accuracy (per-question delta): 4/19 = 21.05%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m answer_sheet \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m tqdm(dataset_names[:]):\n\u001B[1;32m----> 5\u001B[0m     answer_sheet \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43meval_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_len\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_len\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m     df_answer \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(answer_sheet)\n\u001B[0;32m      7\u001B[0m     df_answer\u001B[38;5;241m.\u001B[39mto_csv(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./eval_result/answer_step_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstep\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "Cell \u001B[1;32mIn[7], line 65\u001B[0m, in \u001B[0;36meval_dataset\u001B[1;34m(dataset_name, step, max_len)\u001B[0m\n\u001B[0;32m     62\u001B[0m H \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39mhidden_states[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m     64\u001B[0m \u001B[38;5;66;03m# === è®­ç»ƒ deltaï¼ˆä¾‹å¦‚3æ­¥ï¼‰===\u001B[39;00m\n\u001B[1;32m---> 65\u001B[0m delta \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_delta_from_H\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtokenizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mH\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     67\u001B[0m \u001B[38;5;66;03m# === æ¨ç†ä¸è¯„ä¼° ===\u001B[39;00m\n\u001B[0;32m     68\u001B[0m pred_txt, pre_answer, answer, is_correct \u001B[38;5;241m=\u001B[39m evaluate_slot_ceval_eos(model\u001B[38;5;241m=\u001B[39mmodel, tokenizer\u001B[38;5;241m=\u001B[39mtokenizer,\n\u001B[0;32m     69\u001B[0m                                                                    delta\u001B[38;5;241m=\u001B[39mdelta,\n\u001B[0;32m     70\u001B[0m                                                                    example\u001B[38;5;241m=\u001B[39mex, max_len\u001B[38;5;241m=\u001B[39mmax_len, prompt\u001B[38;5;241m=\u001B[39mprompt,\n\u001B[0;32m     71\u001B[0m                                                                    verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[1;32m~\\Desktop\\è¥¿æ¹–å¤§å­¦\\week-9\\SLOT-Qwen\\delta_trainer.py:39\u001B[0m, in \u001B[0;36mtrain_delta_from_H\u001B[1;34m(model, tokenizer, prompt, H_state, step, lr)\u001B[0m\n\u001B[0;32m     37\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m     38\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m---> 39\u001B[0m     loss_log\u001B[38;5;241m.\u001B[39mappend(\u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     40\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m delta\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "step = 100\n",
    "max_len = 10\n",
    "answer_sheet = []\n",
    "for i in tqdm(dataset_names[:]):\n",
    "    answer_sheet += eval_dataset(i, step=step, max_len=max_len)\n",
    "    df_answer = pd.DataFrame(answer_sheet)\n",
    "    df_answer.to_csv(f\"./eval_result/answer_step_{step}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T20:31:18.436406700Z",
     "start_time": "2025-06-05T20:29:58.945985700Z"
    }
   },
   "id": "688146967bc9c2c4",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "step = 20\n",
    "max_len = 10\n",
    "answer_sheet = []\n",
    "for i in tqdm(dataset_names[:]):\n",
    "    answer_sheet += eval_dataset(i, step=step, max_len=max_len)\n",
    "    df_answer = pd.DataFrame(answer_sheet)\n",
    "    df_answer.to_csv(f\"./eval_result/answer_step_{step}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87c149a7ea991ba6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "step = 3\n",
    "max_len = 20\n",
    "answer_sheet = []\n",
    "for i in tqdm(dataset_names[:]):\n",
    "    answer_sheet += eval_dataset(i, step=step, max_len=max_len)\n",
    "    df_answer = pd.DataFrame(answer_sheet)\n",
    "    df_answer.to_csv(f\"./eval_result/answer_step_{step}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "47854d16696781f3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataset_names"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe053871b61539f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "step = 10\n",
    "max_len = 20\n",
    "answer_sheet = []\n",
    "for i in tqdm(dataset_names[:]):\n",
    "    answer_sheet += eval_dataset(i, step=step, max_len=max_len)\n",
    "    df_answer = pd.DataFrame(answer_sheet)\n",
    "    df_answer.to_csv(f\"./eval_result/answer_step_{step}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4fc6a51f4843094",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "step = 20\n",
    "max_len = 10\n",
    "answer_sheet = []\n",
    "for i in tqdm(dataset_names[:]):\n",
    "    answer_sheet += eval_dataset(i, step=step, max_len=max_len)\n",
    "    df_answer = pd.DataFrame(answer_sheet)\n",
    "    df_answer.to_csv(f\"./eval_result/answer_step_{step}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "663cdc8a398e492c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "step = 0\n",
    "max_len = 10\n",
    "answer_sheet = []\n",
    "for i in tqdm(dataset_names[:]):\n",
    "    answer_sheet += eval_dataset(i, step=step, max_len=max_len)\n",
    "    df_answer = pd.DataFrame(answer_sheet)\n",
    "    df_answer.to_csv(f\"./eval_result/answer_step_{step}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7befb53913bbd46",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "step = 3\n",
    "max_len = 10\n",
    "answer_sheet = []\n",
    "for i in tqdm(dataset_names[:]):\n",
    "    answer_sheet += eval_dataset(i, step=step, max_len=max_len)\n",
    "    df_answer = pd.DataFrame(answer_sheet)\n",
    "    df_answer.to_csv(f\"./eval_result/answer_step_{step}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9ca5530f2445291",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "step = 5\n",
    "max_len = 20\n",
    "answer_sheet = []\n",
    "for i in tqdm(dataset_names[:5]):\n",
    "    answer_sheet += eval_dataset(i, step=step, max_len=max_len)\n",
    "    df_answer = pd.DataFrame(answer_sheet)\n",
    "    df_answer.to_csv(f\"./eval_result/answer_step_{step}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abcc092b42c4f732",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "step = 6\n",
    "answer_sheet = []\n",
    "for i in tqdm(dataset_names[:]):\n",
    "    answer_sheet += eval_dataset(i, step=step)\n",
    "    df_answer = pd.DataFrame(answer_sheet)\n",
    "    df_answer.to_csv(f\"./eval_result/answer_step_{step}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e6b66e6f93db84a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "step = 30\n",
    "answer_sheet = []\n",
    "for i in tqdm(dataset_names[:]):\n",
    "    answer_sheet += eval_dataset(i, step=step)\n",
    "    df_answer = pd.DataFrame(answer_sheet)\n",
    "    df_answer.to_csv(f\"./eval_result/answer_step_{step}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "17e0a2ecba0b79d9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "step = 0\n",
    "answer_sheet = []\n",
    "for i in tqdm(dataset_names[:]):\n",
    "    answer_sheet += eval_dataset(i, step=step)\n",
    "    df_answer = pd.DataFrame(answer_sheet)\n",
    "    df_answer.to_csv(f\"./eval_result/answer_step_{step}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77a145475f7d9618",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df_answer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b73b50d1b3f57419",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pd.DataFrame(answer_sheet)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2795484e22285b5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for ex in tqdm(dataset['test'], desc=\"Evaluating per-question delta\"):\n",
    "    # === æ„é€ æ¯é“é¢˜çš„ Prompt ===\n",
    "    prompt = f\"\"\"ä»¥ä¸‹æ˜¯ä¸€é“å•é¡¹é€‰æ‹©é¢˜ï¼Œè¯·ä½ é˜…è¯»é¢˜ç›®å¹¶é€‰æ‹©æœ€åˆé€‚çš„é€‰é¡¹ã€‚\n",
    "\n",
    "é¢˜ç›®ï¼š{ex['question']}\n",
    "\n",
    "é€‰é¡¹ï¼š\n",
    "A. {ex['A']}\n",
    "B. {ex['B']}\n",
    "C. {ex['C']}\n",
    "D. {ex['D']}\n",
    "\n",
    "ç­”æ¡ˆæ˜¯ï¼š\"\"\"\n",
    "\n",
    "    # === è·å– H_state ===\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True, return_dict=True)\n",
    "    H = outputs.hidden_states[-1]\n",
    "\n",
    "    # === è®­ç»ƒ deltaï¼ˆä¾‹å¦‚3æ­¥ï¼‰===\n",
    "    delta = train_delta_from_H(model, tokenizer, prompt, H, step=3)\n",
    "\n",
    "    # === æ¨ç†ä¸è¯„ä¼° ===\n",
    "    pred, is_correct = evaluate_slot_ceval_eos(model, tokenizer, delta, ex, max_len=200, verbose=False)\n",
    "    print(pred, ex)\n",
    "    correct += int(is_correct)\n",
    "    total += 1\n",
    "\n",
    "print(f\"ğŸ¯ Accuracy (per-question delta): {correct}/{total} = {correct / total:.2%}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bbe6e22059438a2c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def get_empty_delta(H_state):\n",
    "    hidden_size = H_state.size(-1)\n",
    "    delta = nn.Parameter(torch.zeros((1, 1, hidden_size), device=H_state.device, requires_grad=True))\n",
    "\n",
    "    return delta\n",
    "\n",
    "\n",
    "delta_empty = get_empty_delta(H_state=H)\n",
    "delta_empty.shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce3f8fac32a9d102",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for ex in tqdm(dataset['test'], desc=\"Evaluating per-question delta\"):\n",
    "    # === æ„é€ æ¯é“é¢˜çš„ Prompt ===\n",
    "    prompt = f\"\"\"ä»¥ä¸‹æ˜¯ä¸€é“å•é¡¹é€‰æ‹©é¢˜ï¼Œè¯·ä½ é˜…è¯»é¢˜ç›®å¹¶é€‰æ‹©æœ€åˆé€‚çš„é€‰é¡¹ã€‚\n",
    "    \n",
    "    é¢˜ç›®ï¼š{ex['question']}\n",
    "    \n",
    "    é€‰é¡¹ï¼š\n",
    "    A. {ex['A']}\n",
    "    B. {ex['B']}\n",
    "    C. {ex['C']}\n",
    "    D. {ex['D']}\n",
    "    \n",
    "    ç­”æ¡ˆæ˜¯ï¼š\"\"\"\n",
    "\n",
    "    # === æ¨ç†ä¸è¯„ä¼° ===\n",
    "    pred, is_correct = evaluate_slot_ceval_eos(model, tokenizer, delta_empty, ex, max_len=20, verbose=True)\n",
    "    correct += int(is_correct)\n",
    "    total += 1\n",
    "\n",
    "print(f\"ğŸ¯ Accuracy (per-question delta): {correct}/{total} = {correct / total:.2%}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a559f50747db9f70",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from delta_trainer import generate_by_H_eos\n",
    "\n",
    "\n",
    "def evaluate_slot_ceval_eos_2(model, tokenizer, delta, example, max_len=20, verbose=True):\n",
    "    \"\"\"\n",
    "    åŸºäº generate_by_H_eos çš„è¯„ä¼°å‡½æ•°ï¼Œç”¨äº C-Eval å•é€‰é¢˜ç›®ã€‚\n",
    "\n",
    "    è¿”å›ï¼š\n",
    "    - predict_option: é¢„æµ‹é€‰é¡¹ï¼Œå¦‚ 'A'\n",
    "    - is_correct: æ˜¯å¦é¢„æµ‹æ­£ç¡®\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"ä»¥ä¸‹æ˜¯ä¸€é“å•é¡¹é€‰æ‹©é¢˜ï¼Œè¯·ä½ é˜…è¯»é¢˜ç›®å¹¶é€‰æ‹©æœ€åˆé€‚çš„é€‰é¡¹ã€‚\n",
    "\n",
    "é¢˜ç›®ï¼š{example['question']}\n",
    "\n",
    "é€‰é¡¹ï¼š\n",
    "A. {example['A']}\n",
    "B. {example['B']}\n",
    "C. {example['C']}\n",
    "D. {example['D']}\n",
    "\n",
    "ç­”æ¡ˆæ˜¯ï¼š\"\"\"\n",
    "\n",
    "    output_text = generate_by_H_eos(model, prompt, tokenizer, delta, answer_len=max_len)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"ğŸ” æ¨¡å‹ç”Ÿæˆç»“æœ:\\n\", output_text)\n",
    "\n",
    "    predict_option = None\n",
    "    for option in ['A', 'B', 'C', 'D']:\n",
    "        if option in output_text:\n",
    "            predict_option = option\n",
    "            break\n",
    "\n",
    "    print(predict_option, example['answer'])\n",
    "    is_correct = (predict_option == example['answer'])\n",
    "    return predict_option, predict_option, example['answer']\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7274c61d5f52b83d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for ex in tqdm(dataset['test'], desc=\"Evaluating per-question delta\"):\n",
    "    # === æ„é€ æ¯é“é¢˜çš„ Prompt ===\n",
    "    prompt = f\"\"\"ä»¥ä¸‹æ˜¯ä¸€é“å•é¡¹é€‰æ‹©é¢˜ï¼Œè¯·ä½ é˜…è¯»é¢˜ç›®å¹¶é€‰æ‹©æœ€åˆé€‚çš„é€‰é¡¹ã€‚\n",
    "    \n",
    "    é¢˜ç›®ï¼š{ex['question']}\n",
    "    \n",
    "    é€‰é¡¹ï¼š\n",
    "    A. {ex['A']}\n",
    "    B. {ex['B']}\n",
    "    C. {ex['C']}\n",
    "    D. {ex['D']}\n",
    "    \n",
    "    ç­”æ¡ˆæ˜¯ï¼š\"\"\"\n",
    "\n",
    "    # === æ¨ç†ä¸è¯„ä¼° ===\n",
    "    pred, predict, truth = evaluate_slot_ceval_eos_2(model, tokenizer, delta_empty, ex, max_len=20, verbose=False)\n",
    "    # print(predict,truth)\n",
    "    correct += int(predict == truth)\n",
    "    total += 1\n",
    "\n",
    "print(f\"ğŸ¯ Accuracy (per-question delta): {correct}/{total} = {correct / total:.2%}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5bacbd63589b8d55",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for ex in tqdm(dataset['val'], desc=\"Evaluating per-question delta\"):\n",
    "    # === æ„é€ æ¯é“é¢˜çš„ Prompt ===\n",
    "    prompt = f\"\"\"ä»¥ä¸‹æ˜¯ä¸€é“å•é¡¹é€‰æ‹©é¢˜ï¼Œè¯·ä½ é˜…è¯»é¢˜ç›®å¹¶é€‰æ‹©æœ€åˆé€‚çš„é€‰é¡¹ã€‚\n",
    "\n",
    "é¢˜ç›®ï¼š{ex['question']}\n",
    "\n",
    "é€‰é¡¹ï¼š\n",
    "A. {ex['A']}\n",
    "B. {ex['B']}\n",
    "C. {ex['C']}\n",
    "D. {ex['D']}\n",
    "\n",
    "ç­”æ¡ˆæ˜¯ï¼š\"\"\"\n",
    "    print(prompt)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3be944ae2d6143b",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
