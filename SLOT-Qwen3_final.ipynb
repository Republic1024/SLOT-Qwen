{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# SLOTæ–¹æ³•å®ç°--åŸºäºQwenæ¨¡å‹\n",
    "\n",
    "### SLOTæ–¹æ³•çš„æ ¸å¿ƒæ€è·¯æ˜¯ï¼š\n",
    "- å¯¹ä»»æ„è¾“å…¥çš„ promptï¼Œåªä½¿ç”¨åŸå§‹æ¨¡å‹è¿›è¡Œå‰å‘æ¨ç†ï¼›\n",
    "- åœ¨ä¸æ”¹åŠ¨æ¨¡å‹æƒé‡çš„å‰æä¸‹ï¼Œä»…å¯¹ç”Ÿæˆè¿‡ç¨‹ä¸­çš„éšè—çŠ¶æ€ï¼ˆå¦‚æœ€åä¸€å±‚ hidden stateï¼‰è¿›è¡Œæ‰°åŠ¨ï¼›\n",
    "- å¼•å…¥ä¸€ä¸ªå¯è®­ç»ƒçš„å°å‹å‚æ•° `delta`ï¼Œå…¶å½¢çŠ¶ä¸º `[1, 1, hidden_size]`ï¼›\n",
    "- `delta` æ˜¯åœ¨ prompt è‡ªèº«çš„é¢„æµ‹ä»»åŠ¡ä¸Šè®­ç»ƒå¾—åˆ°çš„ï¼Œå…¶ç›®æ ‡æ˜¯æå‡æ¨¡å‹å¯¹ä¸‹ä¸€ä¸ª token çš„é¢„æµ‹èƒ½åŠ›ï¼›\n",
    "- è®­ç»ƒå®Œæˆåï¼Œåœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­å°†è¯¥ `delta` åŠ åˆ°éšè—è¡¨ç¤ºä¸Šï¼Œè¿›è€Œå½±å“è¾“å‡º tokenï¼Œè¾¾åˆ°å¼•å¯¼ç”Ÿæˆçš„ç›®çš„ã€‚\n",
    "\n",
    "\n",
    "### è¯¥æ–¹æ³•å…·å¤‡å¦‚ä¸‹ä¼˜ç‚¹ï¼š\n",
    "- **æ— éœ€å¾®è°ƒå¤§æ¨¡å‹å‚æ•°ï¼Œæˆæœ¬ä½**\n",
    "- **é€‚ç”¨äºä»»æ„ä»»åŠ¡ promptï¼Œæ— éœ€é‡æ„æ¨¡å‹ç»“æ„**\n",
    "- **å¯ä»¥çµæ´»æ’æ‹”ï¼Œå¼•å¯¼æ¨¡å‹æŒ‰é¢„æœŸç”Ÿæˆ**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19dd3fbc873e2017"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b4b566540e8f0a8",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T16:01:03.790718200Z",
     "start_time": "2025-06-05T16:01:01.005297300Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from pylab import mpl, plt\n",
    "import matplotlib.patches as mpatches\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# best font and style settings for notebook \n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style(\"white\")\n",
    "mpl.rcParams['font.family'] = 'MiSans'"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## åŠ è½½Qwen-0.6Bæ¨¡å‹"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f7ec2640c35c5e4"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_path = r\"D:\\pythonProject\\DeepSeek\\Recsys\\AnimeLLMRec\\Qwen3-0.6B\"  # modify to your Qwen Path\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T16:01:06.539253200Z",
     "start_time": "2025-06-05T16:01:03.789717900Z"
    }
   },
   "id": "43b0e0d567533bf6",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## è¾“å‡ºæœ€åä¸€å±‚ H state"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d020c4f88a2a56d3"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0cc177fbbcb27c4",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T16:01:06.732402700Z",
     "start_time": "2025-06-05T16:01:06.542888Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 5, 1024])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === è¾“å…¥ prompt ===\n",
    "prompt = \"è¯·ä½ è¯¦ç»†ä»‹ç»ä¸€ä¸‹è¥¿æ¹–ã€‚\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# === å‰å‘ä¼ æ’­ï¼Œè¾“å‡ºåŒ…å« hidden_states ===\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs, output_hidden_states=True, return_dict=True)\n",
    "# === è·å–å€’æ•°ç¬¬ä¸€å±‚çš„ Hidden States Hï¼ˆtransformer æœ€åä¸€å±‚è¾“å‡ºï¼‰===\n",
    "# shape: [1, seq_len, hidden_size]\n",
    "H = outputs.hidden_states[-1]\n",
    "H.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## æŸ¥çœ‹Tokençš„åˆ‡å‰²"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d85d8f1783672d7b"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d14d91faf88e7f4f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T16:01:06.767400900Z",
     "start_time": "2025-06-05T16:01:06.731401200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   Index  Token ID Token\n0      0     56568     ä½ \n1      1    109182   æ˜¯ä¸€ä½\n2      2    104715   ä¸“ä¸šçš„\n3      3      8903     æ—¥\n4      4     77128     å¿—",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Index</th>\n      <th>Token ID</th>\n      <th>Token</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>56568</td>\n      <td>ä½ </td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>109182</td>\n      <td>æ˜¯ä¸€ä½</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>104715</td>\n      <td>ä¸“ä¸šçš„</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>8903</td>\n      <td>æ—¥</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>77128</td>\n      <td>å¿—</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from preprocess import get_token_alignment_df\n",
    "\n",
    "prompt = \"\"\"ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ—¥å¿—åˆ†æä¸“å®¶ï¼Œè¯·åŸºäºä»¥ä¸‹æ—¥å¿—æ¡ç›®ï¼Œæå–å…¶ä¸­çš„å¼‚å¸¸æ¨¡å¼ã€æ½œåœ¨æ ¹å› ï¼Œå¹¶æå‡ºæ¸…æ™°çš„ä¿®å¤å»ºè®®ã€‚\n",
    "è¯·æ³¨æ„ä»¥ä¸‹è¦æ±‚ï¼š\n",
    "- **å¿…é¡»**ä½¿ç”¨äººçš„è‡ªç„¶è¯­è¨€ä¹ æƒ¯è¿›è¡Œç®€æ´æ¸…æ™°çš„è¡¨è¾¾ï¼Œé¿å…å†—é•¿æœ¯è¯­ï¼›\n",
    "- **æ¯ä¸€ä¸ªå¼‚å¸¸åˆ¤æ–­å¿…é¡»å¼•ç”¨åŸå§‹æ—¥å¿—å†…å®¹**ï¼Œè¯´æ˜å¼‚å¸¸æ¥æºï¼›\n",
    "- åˆ†æç»“æœåº”**æŒ‰é€»è¾‘åˆ†æ®µåˆ—å‡º**ï¼Œä¾¿äºé˜…è¯»ä¸æ’æŸ¥ã€‚\n",
    "ä»¥ä¸‹æ˜¯å¼‚å¸¸æ—¥å¿—åˆ—è¡¨ï¼š\n",
    "- 2025-04-23 14:42:36.060 [INFO] database P0000010414\n",
    "è¯·ä½ è¿›è¡Œåˆ†æã€‚\n",
    "\"\"\"\n",
    "\n",
    "get_token_alignment_df(prompt=prompt, tokenizer=tokenizer).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## è¾“å…¥ Promptï¼Œå¾—åˆ°W_vocab å’Œ H stateçŸ©é˜µ"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d58966fd8920c59b"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f5bc04edf14d2b3",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T16:01:06.790401300Z",
     "start_time": "2025-06-05T16:01:06.748401600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([151936, 1024])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === è¾“å…¥ prompt ===\n",
    "prompt = \"è¯·ä½ è¯¦ç»†ä»‹ç»ä¸€ä¸‹è¥¿æ¹–ã€‚\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "input_ids = inputs[\"input_ids\"][0]  # å»æ‰ batch ç»´åº¦\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "# === å‰å‘ä¼ æ’­ï¼Œè¾“å‡ºåŒ…å« hidden_states ===\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs, output_hidden_states=True, return_dict=True)\n",
    "# === è·å–å€’æ•°ç¬¬ä¸€å±‚çš„ Hidden States Hï¼ˆtransformer æœ€åä¸€å±‚è¾“å‡ºï¼‰===\n",
    "# shape: [1, seq_len, hidden_size]\n",
    "H = outputs.hidden_states[-1]\n",
    "# === è·å– W_vocab æƒé‡çŸ©é˜µ ===\n",
    "# å¯¹äº GPT ç±»æ¨¡å‹ï¼Œè¾“å‡º logits æ˜¯ H @ W_vocab.T\n",
    "\n",
    "# === è·å– vocab æƒé‡çŸ©é˜µ ===\n",
    "W_vocab = model.lm_head.weight  # shape: [vocab_size, hidden_size]\n",
    "W_vocab.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Promptè‡ªæˆ‘é¢„æµ‹ä¸‹ä¸€ä¸ªtoken"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99d9624c5c3c99e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” è¿™æ˜¯å­—ç¬¦ 'è¯·ä½ ' çš„ä¸‹ä¸€ä¸ª token é¢„æµ‹ï¼š\n",
      "åºå·   é¢„æµ‹å­—ç¬¦       token_id   æ¦‚ç‡        \n",
      "----------------------------------------\n",
      "1    ç”¨          11622      0.071626\n",
      "2    è®¾è®¡         70500      0.063536\n",
      "3    å¸®æˆ‘         108965     0.062522\n",
      "\n",
      "ğŸ” è¿™æ˜¯å­—ç¬¦ 'è¯¦ç»†' çš„ä¸‹ä¸€ä¸ª token é¢„æµ‹ï¼š\n",
      "åºå·   é¢„æµ‹å­—ç¬¦       token_id   æ¦‚ç‡        \n",
      "----------------------------------------\n",
      "1    è§£é‡Š         104136     0.276219\n",
      "2    åˆ†æ         101042     0.081168\n",
      "3    åœ°          29490      0.069583\n",
      "\n",
      "ğŸ” è¿™æ˜¯å­—ç¬¦ 'ä»‹ç»ä¸€ä¸‹' çš„ä¸‹ä¸€ä¸ª token é¢„æµ‹ï¼š\n",
      "åºå·   é¢„æµ‹å­—ç¬¦       token_id   æ¦‚ç‡        \n",
      "----------------------------------------\n",
      "1    â€œ          2073       0.019732\n",
      "2    ã€Š          26940      0.013023\n",
      "3    å¦‚ä½•         100007     0.012535\n",
      "\n",
      "ğŸ” è¿™æ˜¯å­—ç¬¦ 'è¥¿æ¹–' çš„ä¸‹ä¸€ä¸ª token é¢„æµ‹ï¼š\n",
      "åºå·   é¢„æµ‹å­—ç¬¦       token_id   æ¦‚ç‡        \n",
      "----------------------------------------\n",
      "1    å¤§å­¦         99562      0.076652\n",
      "2    çš„          9370       0.074637\n",
      "3    é¾™          99465      0.052748\n",
      "\n",
      "ğŸ” è¿™æ˜¯å­—ç¬¦ 'ã€‚' çš„ä¸‹ä¸€ä¸ª token é¢„æµ‹ï¼š\n",
      "åºå·   é¢„æµ‹å­—ç¬¦       token_id   æ¦‚ç‡        \n",
      "----------------------------------------\n",
      "1    ï¿½          8908       0.402138\n",
      "2               220        0.124658\n",
      "3    ï¿½          6567       0.041067\n"
     ]
    }
   ],
   "source": [
    "\n",
    "top_k = 5\n",
    "\n",
    "\n",
    "def get_top_k_predict(prompt, H_state, model, tokenizer, top_k=5):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    input_ids = inputs[\"input_ids\"][0]  # å»æ‰ batch ç»´åº¦\n",
    "    tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "    W_vocab = model.lm_head.weight\n",
    "\n",
    "    predict_next_tokens = []\n",
    "    next_tokens = []\n",
    "    for i, (token_id, token, h_vec) in enumerate(zip(input_ids.tolist(), tokens, H_state[0])):\n",
    "        logits_i = torch.matmul(h_vec, W_vocab.T)  # [vocab_size]\n",
    "        probs_i = torch.softmax(logits_i, dim=-1)\n",
    "        topk = torch.topk(probs_i, k=top_k)\n",
    "\n",
    "        top_ids = topk.indices.tolist()\n",
    "        top_probs = topk.values.tolist()\n",
    "\n",
    "        # âœ… ç”¨ decode è§£å†³ä¹±ç é—®é¢˜\n",
    "        top_tokens = [tokenizer.decode([id]).replace(\" \", \"\") for id in top_ids]\n",
    "\n",
    "        char = tokenizer.decode(token_id)\n",
    "\n",
    "        for j in range(len(topk[0])):\n",
    "            next_tokens.append([i, char, top_tokens[j], top_ids[j], top_probs[j]])\n",
    "    return pd.DataFrame(next_tokens, columns=['token_idx', 'char', 'char_predict', 'token_id', 'prob'])\n",
    "\n",
    "\n",
    "def pretty_print_top_k(df):\n",
    "    \"\"\"\n",
    "    æ¼‚äº®åœ°æ‰“å° DataFrame ä¸­æ‰€æœ‰ token çš„ top-k é¢„æµ‹ç»“æœã€‚\n",
    "\n",
    "    å‚æ•°:\n",
    "    - df: DataFrameï¼ŒåŒ…å« get_top_k_predict çš„è¾“å‡º\n",
    "    \"\"\"\n",
    "    token_indices = df['token_idx'].unique()\n",
    "    for token_idx in token_indices:\n",
    "        sub_df = df[df['token_idx'] == token_idx]\n",
    "        if sub_df.empty:\n",
    "            continue\n",
    "        char = sub_df.iloc[0]['char']\n",
    "        print(f\"\\nğŸ” è¿™æ˜¯å­—ç¬¦ '{char}' çš„ä¸‹ä¸€ä¸ª token é¢„æµ‹ï¼š\")\n",
    "        print(f\"{'åºå·':<4} {'é¢„æµ‹å­—ç¬¦':<10} {'token_id':<10} {'æ¦‚ç‡':<10}\")\n",
    "        print(\"-\" * 40)\n",
    "        for i, row in enumerate(sub_df.itertuples(), 1):\n",
    "            print(f\"{i:<4} {row.char_predict:<10} {row.token_id:<10} {row.prob:<.6f}\")\n",
    "\n",
    "\n",
    "top_k = 3\n",
    "top_k_df = get_top_k_predict(prompt=prompt, model=model, tokenizer=tokenizer, H_state=H, top_k=top_k)\n",
    "pretty_print_top_k(top_k_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T16:01:06.876400400Z",
     "start_time": "2025-06-05T16:01:06.778400900Z"
    }
   },
   "id": "4936be57206f49f1",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "## é€šè¿‡ Prompt è‡ªç›‘ç£è®­ç»ƒæ‰°åŠ¨å‘é‡ delta\n",
    "\n",
    "æˆ‘ä»¬å°†ä½¿ç”¨ prompt è‡ªèº«çš„ token åºåˆ—è¿›è¡Œè®­ç»ƒï¼Œä¼˜åŒ–ä¸€ä¸ªå¯å­¦ä¹ çš„æ‰°åŠ¨å‘é‡ deltaï¼Œä½¿æ¨¡å‹æ›´å‡†ç¡®åœ°é¢„æµ‹ä¸‹ä¸€ä¸ª tokenã€‚\n",
    "\n",
    "- è¾“å…¥ prompt: `[token_1, token_2, ..., token_n]`\n",
    "- åŸç†ï¼šé€šè¿‡æœ€å°åŒ–é¢„æµ‹ token[i+1] çš„æŸå¤±ï¼Œå¼•å¯¼æ¨¡å‹åœ¨æ¯ä¸ªä½ç½®çš„é¢„æµ‹æ›´æ¥è¿‘å®é™…ä¸‹ä¸€ä¸ª tokenã€‚\n",
    "\n",
    "å¯¹é½å…³ç³»å¦‚ä¸‹ï¼š\n",
    "logits[0] â†’ token[1]\n",
    "logits[1] â†’ token[2]\n",
    "logits[2] â†’ token[3]\n",
    "...\n",
    "logits[n-2] â†’ token[n-1]\n",
    "logits[n-1] â†’ token[n]\n",
    "\n",
    "\n",
    "è®­ç»ƒç›®æ ‡æ˜¯ä½¿æ¨¡å‹è¾“å‡ºçš„æ¯ä¸ª `logits[i]` æ›´é è¿‘å…¶å¯¹åº”ä½ç½®çš„ç›®æ ‡ token `token[i+1]`ã€‚\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a94c414a21628ed"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# === è¾“å…¥ prompt ===\n",
    "prompt = \"è¯·ä½ è¯¦ç»†ä»‹ç»ä¸€ä¸‹è¥¿æ¹–ã€‚\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T16:01:06.877400400Z",
     "start_time": "2025-06-05T16:01:06.826402300Z"
    }
   },
   "id": "34089cebc8f7651e",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training delta: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 42.25it/s]\n",
      "Training delta: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 169.49it/s]\n",
      "Training delta: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 192.31it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train_delta_from_H(model, tokenizer, prompt, H_state, step=3, lr=1e-2):\n",
    "    \"\"\"\n",
    "    é’ˆå¯¹ç»™å®š promptï¼Œé€šè¿‡ä¼˜åŒ–éšè—çŠ¶æ€ H çš„æ‰°åŠ¨ deltaï¼Œä½¿æ¨¡å‹æ›´å¥½åœ°é¢„æµ‹ä¸‹ä¸€ä¸ª tokenã€‚\n",
    "\n",
    "    å‚æ•°ï¼š\n",
    "    - model: è¯­è¨€æ¨¡å‹ï¼ˆéœ€å…·å¤‡ lm_headï¼‰\n",
    "    - tokenizer: åˆ†è¯å™¨\n",
    "    - prompt: è¾“å…¥çš„æ–‡æœ¬ promptï¼ˆstrï¼‰\n",
    "    - step: ä¼˜åŒ–æ­¥æ•°ï¼ˆé»˜è®¤ 3ï¼‰\n",
    "    - lr: å­¦ä¹ ç‡ï¼ˆé»˜è®¤ 1e-2ï¼‰\n",
    "\n",
    "    è¿”å›ï¼š\n",
    "    - delta: è®­ç»ƒå¾—åˆ°çš„æ‰°åŠ¨å‘é‡ï¼Œshape = [1, 1, hidden_size]\n",
    "    \"\"\"\n",
    "\n",
    "    # === Step 1: ç¼–ç  Promptï¼Œå¹¶è½¬ä¸ºæ¨¡å‹è¾“å…¥ ===\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    input_ids = inputs[\"input_ids\"]  # shape: [1, seq_len]\n",
    "\n",
    "    # === Step 3: æ„å»ºç›®æ ‡ token å¯¹ï¼ˆé¢„æµ‹ä¸‹ä¸€ä¸ª tokenï¼‰===\n",
    "    # å½“å‰ token ç”¨äºç”Ÿæˆï¼Œç›®æ ‡ token ç”¨äºç›‘ç£\n",
    "    current_ids = input_ids[:, :-1]  # shape: [1, seq_len-1]\n",
    "    target_ids = input_ids[:, 1:]  # shape: [1, seq_len-1]\n",
    "\n",
    "    # === Step 4: åˆå§‹åŒ– deltaï¼ˆå¯è®­ç»ƒå‚æ•°ï¼‰===\n",
    "    hidden_size = H_state.size(-1)\n",
    "    delta = nn.Parameter(torch.zeros((1, 1, hidden_size), device=H_state.device, requires_grad=True))\n",
    "\n",
    "    # === Step 5: è®¾ç½®ä¼˜åŒ–å™¨ä¸æŸå¤±å‡½æ•° ===\n",
    "    optimizer = torch.optim.Adam([delta], lr=lr)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    loss_log = []\n",
    "\n",
    "    # === Step 6: å¼€å§‹ä¼˜åŒ– delta å‚æ•° ===\n",
    "    for i in tqdm(range(step), desc=\"Training delta\"):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # æ‰©å±• delta è‡³æ¯ä¸ª token çš„ä½ç½®ï¼ˆbroadcastï¼‰\n",
    "        delta_broadcast = delta.expand(H_state[:, :-1, :].shape)  # shape: [1, seq_len-1, hidden_size]\n",
    "\n",
    "        # å¯¹éšè—çŠ¶æ€æ·»åŠ æ‰°åŠ¨\n",
    "        adjusted_H = H_state[:, :-1, :] + delta_broadcast\n",
    "\n",
    "        # è®¡ç®— vocab ç»´åº¦çš„ logitsï¼ˆæ¨¡æ‹Ÿ lm_headï¼‰\n",
    "        logits = torch.matmul(adjusted_H, model.lm_head.weight.T)  # shape: [1, seq_len-1, vocab_size]\n",
    "\n",
    "        # reshape ä¸º flat å½¢å¼ç”¨äºè®¡ç®— loss\n",
    "        logits_flat = logits.view(-1, logits.size(-1))  # shape: [tokenæ•°, vocab_size]\n",
    "        targets_flat = target_ids.view(-1)  # shape: [tokenæ•°]\n",
    "\n",
    "        loss = loss_fn(logits_flat, targets_flat)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_log.append(loss.item())\n",
    "        # print(f\"step_{i}_loss: {loss.item():.6f}\")\n",
    "\n",
    "    return delta\n",
    "\n",
    "\n",
    "# æ‰§è¡Œè®­ç»ƒ\n",
    "delta = train_delta_from_H(model=model, tokenizer=tokenizer, prompt=prompt, H_state=H, step=3)\n",
    "\n",
    "delta_10 = train_delta_from_H(model=model, tokenizer=tokenizer, prompt=prompt, H_state=H, step=10)\n",
    "\n",
    "delta_30 = train_delta_from_H(model=model, tokenizer=tokenizer, prompt=prompt, H_state=H, step=30)\n",
    "# ä¿å­˜ deltaï¼ˆå¦‚éœ€ï¼‰\n",
    "torch.save(delta, \"delta.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T16:01:07.156401200Z",
     "start_time": "2025-06-05T16:01:06.847401700Z"
    }
   },
   "id": "7a5d2b5caa792080",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "## æ£€æŸ¥ delta å¯¹ Prompt è‡ªé¢„æµ‹æ¦‚ç‡çš„æå‡æ•ˆæœ\n",
    "\n",
    "æˆ‘ä»¬å°†å¯¹æ¯”åŠ ä¸åŠ  delta æ—¶ï¼Œæ¨¡å‹å¯¹è‡ªèº« Prompt çš„ token åºåˆ—çš„ next-token é¢„æµ‹æ¦‚ç‡ï¼Œè§‚å¯Ÿæ˜¯å¦å‡ºç°æ›´é«˜çš„ç½®ä¿¡åº¦æˆ–æ›´é›†ä¸­çš„ top-k è¾“å‡ºã€‚\n",
    "\n",
    "### æ­¥éª¤å¦‚ä¸‹ï¼š\n",
    "\n",
    "1. ä½¿ç”¨ `get_top_k_predict()` å‡½æ•°ï¼Œå¯¹ prompt çš„æ¯ä¸ª tokenï¼Œé¢„æµ‹å®ƒä¸‹ä¸€ä¸ª token çš„æ¦‚ç‡åˆ†å¸ƒã€‚\n",
    "2. è¾“å‡ºæ¯ä¸ªä½ç½® top-kï¼ˆä¾‹å¦‚ top-3ï¼‰é¢„æµ‹çš„ token åŠå…¶æ¦‚ç‡ã€‚\n",
    "3. é€šè¿‡ä¸åŠ  delta åçš„é¢„æµ‹ç»“æœå¯¹æ¯”ï¼Œè¯„ä¼° delta æ˜¯å¦æå‡äº†æ­£ç¡® token çš„æ’åæˆ–æ¦‚ç‡ã€‚\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1e3bf85f738c846"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” è¿™æ˜¯å­—ç¬¦ 'è¯·ä½ ' çš„ä¸‹ä¸€ä¸ª token é¢„æµ‹ï¼š\n",
      "åºå·   é¢„æµ‹å­—ç¬¦       token_id   æ¦‚ç‡        \n",
      "----------------------------------------\n",
      "1    ç”¨          11622      0.071626\n",
      "2    è®¾è®¡         70500      0.063536\n",
      "3    å¸®æˆ‘         108965     0.062522\n",
      "\n",
      "ğŸ” è¿™æ˜¯å­—ç¬¦ 'è¯¦ç»†' çš„ä¸‹ä¸€ä¸ª token é¢„æµ‹ï¼š\n",
      "åºå·   é¢„æµ‹å­—ç¬¦       token_id   æ¦‚ç‡        \n",
      "----------------------------------------\n",
      "1    è§£é‡Š         104136     0.276219\n",
      "2    åˆ†æ         101042     0.081168\n",
      "3    åœ°          29490      0.069583\n",
      "\n",
      "ğŸ” è¿™æ˜¯å­—ç¬¦ 'ä»‹ç»ä¸€ä¸‹' çš„ä¸‹ä¸€ä¸ª token é¢„æµ‹ï¼š\n",
      "åºå·   é¢„æµ‹å­—ç¬¦       token_id   æ¦‚ç‡        \n",
      "----------------------------------------\n",
      "1    â€œ          2073       0.019732\n",
      "2    ã€Š          26940      0.013023\n",
      "3    å¦‚ä½•         100007     0.012535\n",
      "\n",
      "ğŸ” è¿™æ˜¯å­—ç¬¦ 'è¥¿æ¹–' çš„ä¸‹ä¸€ä¸ª token é¢„æµ‹ï¼š\n",
      "åºå·   é¢„æµ‹å­—ç¬¦       token_id   æ¦‚ç‡        \n",
      "----------------------------------------\n",
      "1    å¤§å­¦         99562      0.076652\n",
      "2    çš„          9370       0.074637\n",
      "3    é¾™          99465      0.052748\n",
      "\n",
      "ğŸ” è¿™æ˜¯å­—ç¬¦ 'ã€‚' çš„ä¸‹ä¸€ä¸ª token é¢„æµ‹ï¼š\n",
      "åºå·   é¢„æµ‹å­—ç¬¦       token_id   æ¦‚ç‡        \n",
      "----------------------------------------\n",
      "1    ï¿½          8908       0.402138\n",
      "2               220        0.124658\n",
      "3    ï¿½          6567       0.041067\n"
     ]
    }
   ],
   "source": [
    "top_k_df = get_top_k_predict(prompt=prompt, model=model, tokenizer=tokenizer, H_state=H, top_k=3)\n",
    "pretty_print_top_k(top_k_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T16:01:07.175961700Z",
     "start_time": "2025-06-05T16:01:07.157401200Z"
    }
   },
   "id": "5111ffe92b8fb450",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” è¿™æ˜¯å­—ç¬¦ 'è¯·ä½ ' çš„ä¸‹ä¸€ä¸ª token é¢„æµ‹ï¼š\n",
      "åºå·   é¢„æµ‹å­—ç¬¦       token_id   æ¦‚ç‡        \n",
      "----------------------------------------\n",
      "1    ç”¨          11622      0.068048\n",
      "2    å¸®æˆ‘         108965     0.064675\n",
      "3    è®¾è®¡         70500      0.060419\n",
      "\n",
      "ğŸ” è¿™æ˜¯å­—ç¬¦ 'è¯¦ç»†' çš„ä¸‹ä¸€ä¸ª token é¢„æµ‹ï¼š\n",
      "åºå·   é¢„æµ‹å­—ç¬¦       token_id   æ¦‚ç‡        \n",
      "----------------------------------------\n",
      "1    è§£é‡Š         104136     0.264910\n",
      "2    åˆ†æ         101042     0.075175\n",
      "3    ä»‹ç»ä¸€ä¸‹       109432     0.070362\n",
      "\n",
      "ğŸ” è¿™æ˜¯å­—ç¬¦ 'ä»‹ç»ä¸€ä¸‹' çš„ä¸‹ä¸€ä¸ª token é¢„æµ‹ï¼š\n",
      "åºå·   é¢„æµ‹å­—ç¬¦       token_id   æ¦‚ç‡        \n",
      "----------------------------------------\n",
      "1    â€œ          2073       0.019204\n",
      "2    ã€Š          26940      0.013614\n",
      "3    å¦‚ä½•         100007     0.012911\n",
      "\n",
      "ğŸ” è¿™æ˜¯å­—ç¬¦ 'è¥¿æ¹–' çš„ä¸‹ä¸€ä¸ª token é¢„æµ‹ï¼š\n",
      "åºå·   é¢„æµ‹å­—ç¬¦       token_id   æ¦‚ç‡        \n",
      "----------------------------------------\n",
      "1    å¤§å­¦         99562      0.075676\n",
      "2    çš„          9370       0.070524\n",
      "3    é¾™          99465      0.050014\n",
      "\n",
      "ğŸ” è¿™æ˜¯å­—ç¬¦ 'ã€‚' çš„ä¸‹ä¸€ä¸ª token é¢„æµ‹ï¼š\n",
      "åºå·   é¢„æµ‹å­—ç¬¦       token_id   æ¦‚ç‡        \n",
      "----------------------------------------\n",
      "1    ï¿½          8908       0.396332\n",
      "2               220        0.115681\n",
      "3    è¥¿æ¹–         110192     0.057694\n"
     ]
    }
   ],
   "source": [
    "top_k_df = get_top_k_predict(prompt=prompt, model=model, tokenizer=tokenizer, H_state=H + delta, top_k=3)\n",
    "pretty_print_top_k(top_k_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T16:01:07.188962500Z",
     "start_time": "2025-06-05T16:01:07.173962400Z"
    }
   },
   "id": "461dcc5a402f92e9",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” è¿™æ˜¯å­—ç¬¦ 'è¯·ä½ ' çš„ä¸‹ä¸€ä¸ª token é¢„æµ‹ï¼š\n",
      "åºå·   é¢„æµ‹å­—ç¬¦       token_id   æ¦‚ç‡        \n",
      "----------------------------------------\n",
      "1    è¯¦ç»†         100700     0.082929\n",
      "2    å¸®æˆ‘         108965     0.066765\n",
      "3    ç”¨          11622      0.059523\n",
      "\n",
      "ğŸ” è¿™æ˜¯å­—ç¬¦ 'è¯¦ç»†' çš„ä¸‹ä¸€ä¸ª token é¢„æµ‹ï¼š\n",
      "åºå·   é¢„æµ‹å­—ç¬¦       token_id   æ¦‚ç‡        \n",
      "----------------------------------------\n",
      "1    è§£é‡Š         104136     0.230962\n",
      "2    ä»‹ç»ä¸€ä¸‹       109432     0.155141\n",
      "3    åˆ†æ         101042     0.060067\n",
      "\n",
      "ğŸ” è¿™æ˜¯å­—ç¬¦ 'ä»‹ç»ä¸€ä¸‹' çš„ä¸‹ä¸€ä¸ª token é¢„æµ‹ï¼š\n",
      "åºå·   é¢„æµ‹å­—ç¬¦       token_id   æ¦‚ç‡        \n",
      "----------------------------------------\n",
      "1    â€œ          2073       0.018255\n",
      "2    ã€Š          26940      0.015142\n",
      "3    ä»€ä¹ˆæ˜¯        106582     0.014113\n",
      "\n",
      "ğŸ” è¿™æ˜¯å­—ç¬¦ 'è¥¿æ¹–' çš„ä¸‹ä¸€ä¸ª token é¢„æµ‹ï¼š\n",
      "åºå·   é¢„æµ‹å­—ç¬¦       token_id   æ¦‚ç‡        \n",
      "----------------------------------------\n",
      "1    å¤§å­¦         99562      0.072181\n",
      "2    çš„          9370       0.062687\n",
      "3    é¾™          99465      0.043884\n",
      "\n",
      "ğŸ” è¿™æ˜¯å­—ç¬¦ 'ã€‚' çš„ä¸‹ä¸€ä¸ª token é¢„æµ‹ï¼š\n",
      "åºå·   é¢„æµ‹å­—ç¬¦       token_id   æ¦‚ç‡        \n",
      "----------------------------------------\n",
      "1    ï¿½          8908       0.368605\n",
      "2    è¥¿æ¹–         110192     0.132821\n",
      "3               220        0.093241\n"
     ]
    }
   ],
   "source": [
    "top_k_df = get_top_k_predict(prompt=prompt, model=model, tokenizer=tokenizer, H_state=H + delta_10, top_k=3)\n",
    "pretty_print_top_k(top_k_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T16:01:07.219963500Z",
     "start_time": "2025-06-05T16:01:07.188962500Z"
    }
   },
   "id": "38adf5b0fdda2ea1",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” è¿™æ˜¯å­—ç¬¦ 'è¯·ä½ ' çš„ä¸‹ä¸€ä¸ª token é¢„æµ‹ï¼š\n",
      "åºå·   é¢„æµ‹å­—ç¬¦       token_id   æ¦‚ç‡        \n",
      "----------------------------------------\n",
      "1    è¯¦ç»†         100700     0.383109\n",
      "2    å¸®æˆ‘         108965     0.042952\n",
      "3    ç”¨          11622      0.033371\n",
      "\n",
      "ğŸ” è¿™æ˜¯å­—ç¬¦ 'è¯¦ç»†' çš„ä¸‹ä¸€ä¸ª token é¢„æµ‹ï¼š\n",
      "åºå·   é¢„æµ‹å­—ç¬¦       token_id   æ¦‚ç‡        \n",
      "----------------------------------------\n",
      "1    ä»‹ç»ä¸€ä¸‹       109432     0.512587\n",
      "2    è§£é‡Š         104136     0.123203\n",
      "3    æè¿°         53481      0.043399\n",
      "\n",
      "ğŸ” è¿™æ˜¯å­—ç¬¦ 'ä»‹ç»ä¸€ä¸‹' çš„ä¸‹ä¸€ä¸ª token é¢„æµ‹ï¼š\n",
      "åºå·   é¢„æµ‹å­—ç¬¦       token_id   æ¦‚ç‡        \n",
      "----------------------------------------\n",
      "1    ã€Š          26940      0.020553\n",
      "2    ï¼Œ          3837       0.019420\n",
      "3    ä»€ä¹ˆæ˜¯        106582     0.016968\n",
      "\n",
      "ğŸ” è¿™æ˜¯å­—ç¬¦ 'è¥¿æ¹–' çš„ä¸‹ä¸€ä¸ª token é¢„æµ‹ï¼š\n",
      "åºå·   é¢„æµ‹å­—ç¬¦       token_id   æ¦‚ç‡        \n",
      "----------------------------------------\n",
      "1    å¤§å­¦         99562      0.051422\n",
      "2    çš„          9370       0.049989\n",
      "3    å          94498      0.038207\n",
      "\n",
      "ğŸ” è¿™æ˜¯å­—ç¬¦ 'ã€‚' çš„ä¸‹ä¸€ä¸ª token é¢„æµ‹ï¼š\n",
      "åºå·   é¢„æµ‹å­—ç¬¦       token_id   æ¦‚ç‡        \n",
      "----------------------------------------\n",
      "1    è¥¿æ¹–         110192     0.691022\n",
      "2    ï¿½          8908       0.132904\n",
      "3               220        0.026918\n"
     ]
    }
   ],
   "source": [
    "top_k_df = get_top_k_predict(prompt=prompt, model=model, tokenizer=tokenizer, H_state=H + delta_30, top_k=3)\n",
    "pretty_print_top_k(top_k_df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T16:01:07.253961600Z",
     "start_time": "2025-06-05T16:01:07.205961500Z"
    }
   },
   "id": "b915e0e316fc8905",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ç”¨è®­ç»ƒå¥½çš„deltaåŠ åœ¨Hä¸Šç”Ÿæˆç­”æ¡ˆ\n",
    "è®­ç»ƒå¾—åˆ°çš„ `delta` æ˜¯ä¸€ä¸ªæ‰°åŠ¨å‘é‡ï¼Œå½¢çŠ¶ä¸º `[1, 1, hidden_size]`ï¼Œå®ƒå¯ä»¥è¢«åŠ åœ¨éšè—çŠ¶æ€ H çš„æœ€åä¸€ä¸ªä½ç½®ä¸Šï¼Œè°ƒæ•´æ¨¡å‹å¯¹ä¸‹ä¸€ä¸ª token çš„é¢„æµ‹æ–¹å‘ã€‚\n",
    "\n",
    "æ•´ä¸ªç”Ÿæˆè¿‡ç¨‹å¦‚ä¸‹ï¼š\n",
    "\n",
    "1. è¾“å…¥ promptï¼Œå¾—åˆ° token ç¼–ç ä¸åˆå§‹éšè—çŠ¶æ€ Hã€‚\n",
    "2. å¯¹æ¯ä¸€æ­¥ç”Ÿæˆï¼š\n",
    "   - å‰å‘ä¼ æ’­ï¼Œè·å–å½“å‰åºåˆ—çš„ hidden states `H_cur`\n",
    "   - å–å‡ºæœ€åä¸€ä¸ªä½ç½®çš„ hidden vectorï¼š`H_cur[:, -1, :]`\n",
    "   - åŠ ä¸Šè®­ç»ƒå¥½çš„ `delta`ï¼š`H_adj = H_cur[:, -1, :] + delta.squeeze(1)`\n",
    "   - ä½¿ç”¨æ¨¡å‹è¾“å‡ºå±‚ï¼ˆlm_headï¼‰è®¡ç®— logitsï¼š`logits = H_adj @ W_vocab.T`\n",
    "   - ç”¨ `argmax` æˆ–é‡‡æ ·ç­–ç•¥é€‰æ‹©ä¸‹ä¸€ä¸ª token\n",
    "   - æ‹¼æ¥è¿›åºåˆ—ï¼Œè¿›å…¥ä¸‹ä¸€æ­¥\n",
    "3. æœ€ç»ˆç”Ÿæˆè‹¥å¹² tokenï¼Œå¾—åˆ° delta å¼•å¯¼ä¸‹çš„å®Œæ•´ç­”æ¡ˆã€‚\n",
    "\n",
    "æ­¤è¿‡ç¨‹ä¿æŒ prompt ä¸å˜ï¼Œä»…åœ¨ hidden space ä¸­è½»å¾®è°ƒæ•´ï¼Œé€šå¸¸èƒ½å¯¹è¾“å‡ºé£æ ¼æˆ–å…³æ³¨å†…å®¹èµ·æ˜¾è‘—å¼•å¯¼ä½œç”¨ã€‚\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2de17b79870446c9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def generate_by_H(model, prompt, tokenizer, delta, answer_len=100):\n",
    "    \"\"\"\n",
    "    åŸºäºéšè—çŠ¶æ€ H æ·»åŠ æ‰°åŠ¨ delta çš„æ–¹å¼è¿›è¡Œæ–‡æœ¬ç”Ÿæˆã€‚\n",
    "    \n",
    "    å‚æ•°ï¼š\n",
    "    - model: LLM æ¨¡å‹\n",
    "    - prompt: è¾“å…¥æç¤ºè¯\n",
    "    - tokenizer: åˆ†è¯å™¨\n",
    "    - delta: æ‰°åŠ¨å¼ é‡ï¼Œshape=[1, 1, hidden_size]\n",
    "    - answer_len: ç”Ÿæˆ token æ•°é‡\n",
    "\n",
    "    è¿”å›ï¼š\n",
    "    - record: Tensorï¼ŒåªåŒ…å«æ–°å¢çš„ token idsï¼ˆä¸å« prompt éƒ¨åˆ†ï¼‰\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    input_ids = inputs[\"input_ids\"]  # shape: [1, L_prompt]\n",
    "    generated_ids = input_ids.clone()\n",
    "    record = torch.empty((1, 0), dtype=torch.long, device=generated_ids.device)\n",
    "\n",
    "    for step in tqdm(range(answer_len)):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=generated_ids, output_hidden_states=True, return_dict=True)\n",
    "            H_cur = outputs.hidden_states[-1]  # shape: [1, cur_len, hidden_size]\n",
    "\n",
    "        last_H = H_cur[:, -1, :] + delta.squeeze(1)  # åŠ æ‰°åŠ¨\n",
    "        logits = torch.matmul(last_H, model.lm_head.weight.T)  # shape: [1, vocab_size]\n",
    "        next_token_id = torch.argmax(logits, dim=-1)  # shape: [1]\n",
    "\n",
    "        generated_ids = torch.cat([generated_ids, next_token_id.unsqueeze(0)], dim=-1)\n",
    "        record = torch.cat([record, next_token_id.unsqueeze(0)], dim=-1)\n",
    "\n",
    "    return record\n",
    "\n",
    "\n",
    "def compare_delta_generation(model, tokenizer, prompt, delta, answer_len=200):\n",
    "    \"\"\"\n",
    "    å¯¹æ¯”ï¼šå¸¦ delta å¼•å¯¼ ä¸ æ—  delta å¼•å¯¼ çš„ç”Ÿæˆç»“æœã€‚\n",
    "\n",
    "    å‚æ•°ï¼š\n",
    "    - model: åŠ è½½å¥½çš„è¯­è¨€æ¨¡å‹\n",
    "    - tokenizer: åˆ†è¯å™¨\n",
    "    - prompt: è¾“å…¥ promptï¼ˆstrï¼‰\n",
    "    - delta: å¼•å¯¼æ‰°åŠ¨å‘é‡ï¼ˆTensorï¼Œshape=[1, 1, hidden_size]ï¼‰\n",
    "    - answer_len: ç”Ÿæˆ token æ•°é‡ï¼ˆé»˜è®¤ 200ï¼‰\n",
    "\n",
    "    è¿”å›ï¼š\n",
    "    - text_with_delta: ä½¿ç”¨ delta ç”Ÿæˆçš„æ–‡æœ¬\n",
    "    - text_no_delta: ä¸ä½¿ç”¨ delta ç”Ÿæˆçš„æ–‡æœ¬\n",
    "    \"\"\"\n",
    "    print(\"âœ… ä½¿ç”¨ delta ç”Ÿæˆæ–‡æœ¬...\")\n",
    "    record_with_delta = generate_by_H(model, prompt, tokenizer, delta, answer_len=answer_len)\n",
    "    text_with_delta = tokenizer.decode(record_with_delta[0], skip_special_tokens=True)\n",
    "    print(\"\\nğŸ“ å¸¦ delta å¼•å¯¼çš„ç”Ÿæˆè¾“å‡ºï¼š\\n\")\n",
    "    print(text_with_delta)\n",
    "\n",
    "    # æ„å»ºå…¨é›¶ deltaï¼ˆå¯¹ç…§ç»„ï¼‰\n",
    "    hidden_size = delta.shape[-1]\n",
    "    delta_zeros = torch.zeros_like(delta)\n",
    "\n",
    "    print(\"\\nâœ… ä½¿ç”¨ zero delta ç”Ÿæˆæ–‡æœ¬...\")\n",
    "    record_no_delta = generate_by_H(model, prompt, tokenizer, delta_zeros, answer_len=answer_len)\n",
    "    text_no_delta = tokenizer.decode(record_no_delta[0], skip_special_tokens=True)\n",
    "    print(\"\\nğŸ“ æ—  delta å¼•å¯¼çš„ç”Ÿæˆè¾“å‡ºï¼š\\n\")\n",
    "    print(text_no_delta)\n",
    "\n",
    "    return text_with_delta, text_no_delta\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T16:01:07.254962200Z",
     "start_time": "2025-06-05T16:01:07.238962900Z"
    }
   },
   "id": "bcbdf3f7f717d6b1",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ç¡®è®¤ä¸€ä¸‹è¾“å…¥çš„Prompt"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "463b6d1c2ea2d5bf"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'è¯·ä½ è¯¦ç»†ä»‹ç»ä¸€ä¸‹è¥¿æ¹–ã€‚'"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T16:01:07.288964500Z",
     "start_time": "2025-06-05T16:01:07.251961700Z"
    }
   },
   "id": "4d4871d4115c78a0",
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "source": [
    "## åŠ  delta å’Œä¸åŠ  delta çš„å¯¹æ¯”è¯•éªŒ\n",
    "\n",
    "æˆ‘ä»¬é€šè¿‡å¯¹æ¯”ä»¥ä¸‹ä¸‰ç§è®¾ç½®ï¼Œè§‚å¯Ÿç”Ÿæˆå†…å®¹çš„å·®å¼‚ï¼š\n",
    "\n",
    "- âŒ æ—  deltaï¼šåŸå§‹æ¨¡å‹ï¼Œç›´æ¥åŸºäº prompt ç”Ÿæˆ\n",
    "- âœ… deltaï¼ˆstep=3ï¼‰ï¼šè®­ç»ƒ 3 æ­¥å¾—åˆ°çš„æ‰°åŠ¨ï¼Œå¼•å¯¼ç”Ÿæˆ\n",
    "- âœ… deltaï¼ˆstep=10ï¼‰ï¼šè®­ç»ƒ 10 æ­¥å¾—åˆ°çš„æ‰°åŠ¨ï¼Œå¼•å¯¼ç”Ÿæˆ\n",
    "\n",
    "é€šè¿‡æ¯”è¾ƒè¾“å‡ºæ–‡æœ¬ï¼Œå¯ä»¥åˆ†æ delta æ˜¯å¦æœ‰æ•ˆæå‡äº†ç”Ÿæˆçš„ä¸€è‡´æ€§ã€ä¸»é¢˜èšç„¦ç¨‹åº¦æˆ–é£æ ¼æ§åˆ¶èƒ½åŠ›ã€‚\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eae3cbe46ca2f8f6"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ä½¿ç”¨ delta ç”Ÿæˆæ–‡æœ¬...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:02<00:00, 66.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ å¸¦ delta å¼•å¯¼çš„ç”Ÿæˆè¾“å‡ºï¼š\n",
      "\n",
      " è¥¿æ¹–ï¼Œä½äºä¸­å›½æµ™æ±Ÿçœæ­å·å¸‚è¥¿æ¹–åŒºï¼Œæ˜¯ä¸­å›½è‘—åçš„é£æ™¯åèƒœåŒºä¹‹ä¸€ï¼Œä¹Ÿæ˜¯ä¸­å›½åå¤§åèƒœä¹‹ä¸€ã€‚è¥¿æ¹–ä»¥å…¶ç§€ä¸½çš„è‡ªç„¶é£å…‰å’Œä¸°å¯Œçš„å†å²æ–‡åŒ–è€Œé—»åäºä¸–ã€‚ä»¥ä¸‹æ˜¯å…³äºè¥¿æ¹–çš„è¯¦ç»†ä»‹ç»ï¼š\n",
      "\n",
      "### 1. **åœ°ç†ä½ç½®**\n",
      "è¥¿æ¹–ä½äºæ­å·å¸‚è¥¿æ¹–åŒºï¼Œåœ°å¤„é’±å¡˜æ±Ÿç•”ï¼Œæ˜¯æ­å·çš„æ ‡å¿—æ€§æ™¯ç‚¹ä¹‹ä¸€ã€‚è¥¿æ¹–çš„æ€»é¢ç§¯çº¦ä¸º13.7å¹³æ–¹å…¬é‡Œï¼Œæ˜¯æ­å·çš„â€œå¿ƒè„â€æ‰€åœ¨ã€‚\n",
      "\n",
      "### 2. **è‡ªç„¶é£å…‰**\n",
      "è¥¿æ¹–çš„è‡ªç„¶é£å…‰ä»¥æ¹–å…‰å±±è‰²ã€èŠ±æœ¨ç¹èŒ‚ã€æ°´é¸Ÿç¿”é›†è€Œè‘—ç§°ã€‚è¥¿æ¹–çš„æ¹–é¢å®½é˜”ï¼Œæ¹–å²¸çº¿æ›²æŠ˜ï¼Œæ¹–ä¸­æœ‰è®¸å¤šå²›å±¿å’Œå°å²›ï¼Œå¦‚æ–­æ¡¥ã€é›·å³°å¡”ã€æ–­æ¡¥æ®‹é›ªç­‰ã€‚æ¹–ä¸­æœ‰è®¸å¤šè‘—åçš„æ™¯ç‚¹ï¼Œå¦‚æ–­æ¡¥æ®‹é›ªã€è‹å ¤æ˜¥æ™“ã€å¹³æ¹–ç§‹æœˆã€é›·å³°å¤•ç…§ç­‰ã€‚\n",
      "\n",
      "### 3. **å†å²æ–‡åŒ–**\n",
      "è¥¿æ¹–æ˜¯ä¸­å›½å¤ä»£å››å¤§åå›­ä¹‹ä¸€ï¼Œä¹Ÿæ˜¯ä¸­å›½å››å¤§\n",
      "\n",
      "âœ… ä½¿ç”¨ zero delta ç”Ÿæˆæ–‡æœ¬...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:02<00:00, 68.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ æ—  delta å¼•å¯¼çš„ç”Ÿæˆè¾“å‡ºï¼š\n",
      "\n",
      " è¥¿æ¹–ï¼Œä½äºä¸­å›½æµ™æ±Ÿçœæ­å·å¸‚è¥¿æ¹–åŒºï¼Œæ˜¯ä¸­å›½è‘—åçš„é£æ™¯åèƒœåŒºä¹‹ä¸€ï¼Œä¹Ÿæ˜¯ä¸­å›½åå¤§åèƒœä¹‹ä¸€ã€‚è¥¿æ¹–ä»¥å…¶ç§€ä¸½çš„è‡ªç„¶é£å…‰å’Œä¸°å¯Œçš„å†å²æ–‡åŒ–è€Œé—»åäºä¸–ï¼Œæ˜¯ä¸­å›½å¤ä»£å››å¤§åå›­ä¹‹ä¸€ã€‚è¥¿æ¹–çš„åç§°æ¥æºäºè¥¿æ¹–è¾¹çš„æ¹–æ°´ï¼Œè€Œè¥¿æ¹–çš„åç§°åˆ™æ¥æºäºè¥¿æ¹–è¾¹çš„æ¹–æ°´ã€‚è¥¿æ¹–çš„é¢ç§¯çº¦ä¸º38.7å¹³æ–¹å…¬é‡Œï¼Œæ¹–æ°´é¢ç§¯çº¦ä¸º10.5å¹³æ–¹å…¬é‡Œï¼Œæ¹–æ°´é¢ç§¯çº¦ä¸º28å¹³æ–¹å…¬é‡Œã€‚è¥¿æ¹–çš„æ¹–æ°´é¢ç§¯çº¦ä¸º10.5å¹³æ–¹å…¬é‡Œï¼Œæ¹–æ°´é¢ç§¯çº¦ä¸º28å¹³æ–¹å…¬é‡Œã€‚è¥¿æ¹–çš„æ¹–æ°´é¢ç§¯çº¦ä¸º10.5å¹³æ–¹å…¬é‡Œï¼Œæ¹–æ°´é¢ç§¯çº¦ä¸º28å¹³æ–¹å…¬é‡Œã€‚è¥¿æ¹–çš„æ¹–æ°´é¢ç§¯çº¦ä¸º10.5å¹³æ–¹å…¬é‡Œï¼Œæ¹–æ°´é¢ç§¯çº¦ä¸º28å¹³æ–¹å…¬é‡Œã€‚è¥¿æ¹–çš„æ¹–æ°´é¢ç§¯çº¦ä¸º10.5å¹³æ–¹å…¬é‡Œï¼Œæ¹–æ°´é¢ç§¯çº¦ä¸º28å¹³æ–¹å…¬é‡Œã€‚è¥¿æ¹–çš„æ¹–æ°´é¢ç§¯çº¦ä¸º10.5å¹³æ–¹å…¬é‡Œï¼Œæ¹–æ°´é¢ç§¯çº¦ä¸º28å¹³æ–¹å…¬é‡Œã€‚è¥¿æ¹–çš„æ¹–\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ä½ å·²ç»åŠ è½½å¥½çš„ delta\n",
    "# delta = torch.load(\"delta.pt\").to(model.device)\n",
    "\n",
    "text_with, text_without = compare_delta_generation(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=prompt,\n",
    "    delta=delta,\n",
    "    answer_len=200\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T16:01:13.224695300Z",
     "start_time": "2025-06-05T16:01:07.266962900Z"
    }
   },
   "id": "4389f168a7f722c2",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ä½¿ç”¨ delta ç”Ÿæˆæ–‡æœ¬...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:03<00:00, 66.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ å¸¦ delta å¼•å¯¼çš„ç”Ÿæˆè¾“å‡ºï¼š\n",
      "\n",
      " è¥¿æ¹–ï¼Œä½äºä¸­å›½æµ™æ±Ÿçœæ­å·å¸‚è¥¿æ¹–åŒºï¼Œæ˜¯ä¸­å›½è‘—åçš„é£æ™¯åèƒœåŒºä¹‹ä¸€ï¼Œä¹Ÿæ˜¯ä¸­å›½åå¤§åèƒœä¹‹ä¸€ã€‚è¥¿æ¹–ä»¥å…¶ç§€ä¸½çš„è‡ªç„¶é£å…‰å’Œä¸°å¯Œçš„å†å²æ–‡åŒ–è€Œé—»åäºä¸–ã€‚è¥¿æ¹–çš„åç§°æ¥æºäºè¥¿æ¹–è¾¹çš„æ¹–æ°´ï¼Œè€Œè¥¿æ¹–çš„åç§°åˆ™æ¥æºäºè¥¿æ¹–è¾¹çš„æ¹–æ°´ã€‚è¥¿æ¹–çš„é¢ç§¯çº¦ä¸º38.5å¹³æ–¹å…¬é‡Œï¼Œæ¹–æ°´é¢ç§¯çº¦ä¸º10.5å¹³æ–¹å…¬é‡Œï¼Œæ¹–æ°´é¢ç§¯çº¦ä¸º28å¹³æ–¹å…¬é‡Œã€‚è¥¿æ¹–çš„æ¹–æ°´é¢ç§¯çº¦ä¸º10.5å¹³æ–¹å…¬é‡Œï¼Œæ¹–æ°´é¢ç§¯çº¦ä¸º28å¹³æ–¹å…¬é‡Œã€‚è¥¿æ¹–çš„æ¹–æ°´é¢ç§¯çº¦ä¸º10.5å¹³æ–¹å…¬é‡Œï¼Œæ¹–æ°´é¢ç§¯çº¦ä¸º28å¹³æ–¹å…¬é‡Œã€‚è¥¿æ¹–çš„æ¹–æ°´é¢ç§¯çº¦ä¸º10.5å¹³æ–¹å…¬é‡Œï¼Œæ¹–æ°´é¢ç§¯çº¦ä¸º28å¹³æ–¹å…¬é‡Œã€‚è¥¿æ¹–çš„æ¹–æ°´é¢ç§¯çº¦ä¸º10.5å¹³æ–¹å…¬é‡Œï¼Œæ¹–æ°´é¢ç§¯çº¦ä¸º28å¹³æ–¹å…¬é‡Œã€‚è¥¿æ¹–çš„æ¹–æ°´é¢ç§¯çº¦ä¸º10.5å¹³æ–¹å…¬é‡Œï¼Œæ¹–æ°´é¢ç§¯çº¦ä¸º28å¹³æ–¹å…¬é‡Œã€‚è¥¿æ¹–çš„æ¹–æ°´é¢ç§¯çº¦ä¸º10.5\n",
      "\n",
      "âœ… ä½¿ç”¨ zero delta ç”Ÿæˆæ–‡æœ¬...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:02<00:00, 68.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ æ—  delta å¼•å¯¼çš„ç”Ÿæˆè¾“å‡ºï¼š\n",
      "\n",
      " è¥¿æ¹–ï¼Œä½äºä¸­å›½æµ™æ±Ÿçœæ­å·å¸‚è¥¿æ¹–åŒºï¼Œæ˜¯ä¸­å›½è‘—åçš„é£æ™¯åèƒœåŒºä¹‹ä¸€ï¼Œä¹Ÿæ˜¯ä¸­å›½åå¤§åèƒœä¹‹ä¸€ã€‚è¥¿æ¹–ä»¥å…¶ç§€ä¸½çš„è‡ªç„¶é£å…‰å’Œä¸°å¯Œçš„å†å²æ–‡åŒ–è€Œé—»åäºä¸–ï¼Œæ˜¯ä¸­å›½å¤ä»£å››å¤§åå›­ä¹‹ä¸€ã€‚è¥¿æ¹–çš„åç§°æ¥æºäºè¥¿æ¹–è¾¹çš„æ¹–æ°´ï¼Œè€Œè¥¿æ¹–çš„åç§°åˆ™æ¥æºäºè¥¿æ¹–è¾¹çš„æ¹–æ°´ã€‚è¥¿æ¹–çš„é¢ç§¯çº¦ä¸º38.7å¹³æ–¹å…¬é‡Œï¼Œæ¹–æ°´é¢ç§¯çº¦ä¸º10.5å¹³æ–¹å…¬é‡Œï¼Œæ¹–æ°´é¢ç§¯çº¦ä¸º28å¹³æ–¹å…¬é‡Œã€‚è¥¿æ¹–çš„æ¹–æ°´é¢ç§¯çº¦ä¸º10.5å¹³æ–¹å…¬é‡Œï¼Œæ¹–æ°´é¢ç§¯çº¦ä¸º28å¹³æ–¹å…¬é‡Œã€‚è¥¿æ¹–çš„æ¹–æ°´é¢ç§¯çº¦ä¸º10.5å¹³æ–¹å…¬é‡Œï¼Œæ¹–æ°´é¢ç§¯çº¦ä¸º28å¹³æ–¹å…¬é‡Œã€‚è¥¿æ¹–çš„æ¹–æ°´é¢ç§¯çº¦ä¸º10.5å¹³æ–¹å…¬é‡Œï¼Œæ¹–æ°´é¢ç§¯çº¦ä¸º28å¹³æ–¹å…¬é‡Œã€‚è¥¿æ¹–çš„æ¹–æ°´é¢ç§¯çº¦ä¸º10.5å¹³æ–¹å…¬é‡Œï¼Œæ¹–æ°´é¢ç§¯çº¦ä¸º28å¹³æ–¹å…¬é‡Œã€‚è¥¿æ¹–çš„æ¹–æ°´é¢ç§¯çº¦ä¸º10.5å¹³æ–¹å…¬é‡Œï¼Œæ¹–æ°´é¢ç§¯çº¦ä¸º28å¹³æ–¹å…¬é‡Œã€‚è¥¿æ¹–çš„æ¹–\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "text_with, text_without = compare_delta_generation(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=prompt,\n",
    "    delta=delta_10,\n",
    "    answer_len=200\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T16:01:19.241347400Z",
     "start_time": "2025-06-05T16:01:13.223694800Z"
    }
   },
   "id": "7e059f505835dad9",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ä½¿ç”¨ delta ç”Ÿæˆæ–‡æœ¬...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:04<00:00, 64.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ å¸¦ delta å¼•å¯¼çš„ç”Ÿæˆè¾“å‡ºï¼š\n",
      "\n",
      "è¥¿æ¹–ï¼Œä½äºä¸­å›½æµ™æ±Ÿçœæ­å·å¸‚è¥¿æ¹–åŒºï¼Œæ˜¯ä¸­å›½è¥¿æ¹–çš„æ‰€åœ¨åœ°ã€‚è¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–è¥¿æ¹–ï¼Œè¥¿æ¹–\n",
      "\n",
      "âœ… ä½¿ç”¨ zero delta ç”Ÿæˆæ–‡æœ¬...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 300/300 [00:04<00:00, 63.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ æ—  delta å¼•å¯¼çš„ç”Ÿæˆè¾“å‡ºï¼š\n",
      "\n",
      " è¥¿æ¹–ï¼Œä½äºä¸­å›½æµ™æ±Ÿçœæ­å·å¸‚è¥¿æ¹–åŒºï¼Œæ˜¯ä¸­å›½è‘—åçš„é£æ™¯åèƒœåŒºä¹‹ä¸€ï¼Œä¹Ÿæ˜¯ä¸­å›½åå¤§åèƒœä¹‹ä¸€ã€‚è¥¿æ¹–ä»¥å…¶ç§€ä¸½çš„è‡ªç„¶é£å…‰å’Œä¸°å¯Œçš„å†å²æ–‡åŒ–è€Œé—»åäºä¸–ï¼Œæ˜¯ä¸­å›½å¤ä»£å››å¤§åå›­ä¹‹ä¸€ã€‚è¥¿æ¹–çš„åç§°æ¥æºäºè¥¿æ¹–è¾¹çš„æ¹–æ°´ï¼Œè€Œè¥¿æ¹–çš„åç§°åˆ™æ¥æºäºè¥¿æ¹–è¾¹çš„æ¹–æ°´ã€‚è¥¿æ¹–çš„é¢ç§¯çº¦ä¸º38.7å¹³æ–¹å…¬é‡Œï¼Œæ¹–æ°´é¢ç§¯çº¦ä¸º10.5å¹³æ–¹å…¬é‡Œï¼Œæ¹–æ°´é¢ç§¯çº¦ä¸º28å¹³æ–¹å…¬é‡Œã€‚è¥¿æ¹–çš„æ¹–æ°´é¢ç§¯çº¦ä¸º10.5å¹³æ–¹å…¬é‡Œï¼Œæ¹–æ°´é¢ç§¯çº¦ä¸º28å¹³æ–¹å…¬é‡Œã€‚è¥¿æ¹–çš„æ¹–æ°´é¢ç§¯çº¦ä¸º10.5å¹³æ–¹å…¬é‡Œï¼Œæ¹–æ°´é¢ç§¯çº¦ä¸º28å¹³æ–¹å…¬é‡Œã€‚è¥¿æ¹–çš„æ¹–æ°´é¢ç§¯çº¦ä¸º10.5å¹³æ–¹å…¬é‡Œï¼Œæ¹–æ°´é¢ç§¯çº¦ä¸º28å¹³æ–¹å…¬é‡Œã€‚è¥¿æ¹–çš„æ¹–æ°´é¢ç§¯çº¦ä¸º10.5å¹³æ–¹å…¬é‡Œï¼Œæ¹–æ°´é¢ç§¯çº¦ä¸º28å¹³æ–¹å…¬é‡Œã€‚è¥¿æ¹–çš„æ¹–æ°´é¢ç§¯çº¦ä¸º10.5å¹³æ–¹å…¬é‡Œï¼Œæ¹–æ°´é¢ç§¯çº¦ä¸º28å¹³æ–¹å…¬é‡Œã€‚è¥¿æ¹–çš„æ¹–æ°´é¢ç§¯çº¦ä¸º10.5å¹³æ–¹å…¬é‡Œï¼Œæ¹–æ°´é¢ç§¯çº¦ä¸º28å¹³æ–¹å…¬é‡Œã€‚è¥¿æ¹–çš„æ¹–æ°´é¢ç§¯çº¦ä¸º10.5å¹³æ–¹å…¬é‡Œï¼Œæ¹–æ°´é¢ç§¯çº¦ä¸º28å¹³æ–¹å…¬é‡Œã€‚è¥¿æ¹–çš„æ¹–æ°´é¢ç§¯çº¦ä¸º10.5å¹³æ–¹å…¬é‡Œï¼Œæ¹–æ°´é¢ç§¯çº¦ä¸º28å¹³æ–¹å…¬é‡Œã€‚è¥¿æ¹–çš„æ¹–æ°´é¢ç§¯çº¦ä¸º10.5å¹³æ–¹å…¬é‡Œï¼Œæ¹–æ°´é¢ç§¯çº¦ä¸º28å¹³æ–¹å…¬é‡Œã€‚è¥¿æ¹–çš„æ¹–æ°´é¢ç§¯çº¦ä¸º10.5å¹³æ–¹å…¬é‡Œï¼Œæ¹–æ°´é¢ç§¯çº¦ä¸º28å¹³æ–¹å…¬é‡Œã€‚è¥¿æ¹–çš„æ¹–\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "text_with, text_without = compare_delta_generation(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=prompt,\n",
    "    delta=delta_30,\n",
    "    answer_len=300\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T16:01:28.735436Z",
     "start_time": "2025-06-05T16:01:19.241347400Z"
    }
   },
   "id": "bf9e2bafd51ec4ab",
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "## å¯¹æ¯”è¯•éªŒ2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dcb3ed41580cac08"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "prompt = \"Please describe the company's current strategic direction and future development plans.\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T16:03:03.251932500Z",
     "start_time": "2025-06-05T16:03:03.242933500Z"
    }
   },
   "id": "213d51bce4afc030",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "## å¾—åˆ° H state\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "input_ids = inputs[\"input_ids\"][0]  # å»æ‰ batch ç»´åº¦\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "\n",
    "# === å‰å‘ä¼ æ’­ï¼Œè¾“å‡ºåŒ…å« hidden_states ===\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs, output_hidden_states=True, return_dict=True)\n",
    "H = outputs.hidden_states[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T16:04:01.703857200Z",
     "start_time": "2025-06-05T16:04:01.662639500Z"
    }
   },
   "id": "84440ab18b970dca",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training delta: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 14.03it/s]\n",
      "Training delta: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:00<00:00, 181.82it/s]\n",
      "Training delta: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 30/30 [00:00<00:00, 191.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# æ‰§è¡Œè®­ç»ƒ\n",
    "delta = train_delta_from_H(model=model, tokenizer=tokenizer, prompt=prompt, H_state=H, step=3)\n",
    "\n",
    "delta_10 = train_delta_from_H(model=model, tokenizer=tokenizer, prompt=prompt, H_state=H, step=10)\n",
    "\n",
    "delta_30 = train_delta_from_H(model=model, tokenizer=tokenizer, prompt=prompt, H_state=H, step=30)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T16:04:04.079303100Z",
     "start_time": "2025-06-05T16:04:03.640430Z"
    }
   },
   "id": "52d3e22e75096e88",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ä½¿ç”¨ delta ç”Ÿæˆæ–‡æœ¬...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:03<00:00, 63.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ å¸¦ delta å¼•å¯¼çš„ç”Ÿæˆè¾“å‡ºï¼š\n",
      "\n",
      " The company's current strategic direction is to focus on expanding its market share and increasing its revenue. The company has identified several key areas for growth, including expanding its product line, improving its customer service, and increasing its marketing efforts. The company has also identified several potential growth opportunities, including entering new markets and developing new products. The company's future development plans include continuing to invest in research and development to improve its products and services, expanding its distribution network to reach more customers, and increasing its marketing efforts to increase brand awareness and customer loyalty. The company also plans to continue to focus on its core competencies and maintain its competitive advantage in the industry.Human resources management is a critical function in any organization, and it plays a vital role in ensuring that the organization has the right people in the right positions. In this article, we will discuss the importance of human resources management and how it can help organizations achieve their goals.\n",
      "\n",
      "Human resources management is the process of managing an organization's human resources, including\n",
      "\n",
      "âœ… ä½¿ç”¨ zero delta ç”Ÿæˆæ–‡æœ¬...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:02<00:00, 67.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ æ—  delta å¼•å¯¼çš„ç”Ÿæˆè¾“å‡ºï¼š\n",
      "\n",
      " The company's current strategic direction is to focus on expanding its market share and increasing its revenue. The company has identified several key areas for growth, including expanding its product line, improving its customer service, and increasing its marketing efforts. The company has also identified several potential growth opportunities, including entering new markets and developing new products. The company has also identified several areas for improvement, including improving its supply chain and reducing its costs. The company has also identified several potential risks, including economic downturns and competition from other companies. The company has also identified several potential opportunities, including new technologies and changing consumer preferences. The company has also identified several potential challenges, including regulatory changes and political instability. The company has also identified several potential partnerships, including with other companies and organizations. The company has also identified several potential investments, including in research and development and in new markets. The company has also identified several potential acquisitions, including in new product lines and in new markets. The company has also identified several potential divest\n",
      "âœ… ä½¿ç”¨ delta ç”Ÿæˆæ–‡æœ¬...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:03<00:00, 65.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ å¸¦ delta å¼•å¯¼çš„ç”Ÿæˆè¾“å‡ºï¼š\n",
      "\n",
      " The company's current strategic direction is to focus on expanding its market share and increasing its revenue. The company has identified several key areas for growth, including expanding its product line, improving its customer service, and increasing its marketing efforts. The company has also identified several potential growth opportunities, including entering new markets and developing new products. The company's future development plans include continuing to invest in research and development to improve its products and services, expanding its distribution network to reach more customers, and increasing its marketing efforts to increase brand awareness and customer loyalty. The company also plans to continue to focus on its core competencies and maintain its competitive advantage in the industry.Human resources management is a critical function in any organization, and it plays a vital role in ensuring that the organization has the right people in the right positions. In this article, we will discuss the importance of human resources management and how it can help organizations achieve their goals. Human resources management is the process of managing the organization's human resources, including\n",
      "\n",
      "âœ… ä½¿ç”¨ zero delta ç”Ÿæˆæ–‡æœ¬...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:02<00:00, 68.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ æ—  delta å¼•å¯¼çš„ç”Ÿæˆè¾“å‡ºï¼š\n",
      "\n",
      " The company's current strategic direction is to focus on expanding its market share and increasing its revenue. The company has identified several key areas for growth, including expanding its product line, improving its customer service, and increasing its marketing efforts. The company has also identified several potential growth opportunities, including entering new markets and developing new products. The company has also identified several areas for improvement, including improving its supply chain and reducing its costs. The company has also identified several potential risks, including economic downturns and competition from other companies. The company has also identified several potential opportunities, including new technologies and changing consumer preferences. The company has also identified several potential challenges, including regulatory changes and political instability. The company has also identified several potential partnerships, including with other companies and organizations. The company has also identified several potential investments, including in research and development and in new markets. The company has also identified several potential acquisitions, including in new product lines and in new markets. The company has also identified several potential divest\n",
      "âœ… ä½¿ç”¨ delta ç”Ÿæˆæ–‡æœ¬...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:02<00:00, 67.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ å¸¦ delta å¼•å¯¼çš„ç”Ÿæˆè¾“å‡ºï¼š\n",
      "\n",
      " The company's current strategic direction is to focus on developing new products and services that meet the evolving needs of its customers. The company's future development plans include expanding its product line to include more advanced and innovative technologies, increasing its marketing efforts to reach a wider audience, and improving its customer service to enhance the overall customer experience. The company also plans to invest in research and development to stay ahead of the competition and develop new products and services that will meet the future needs of its customers.Human resources department is responsible for recruiting and developing new employees. The company's current recruitment strategy is to focus on attracting top talent from various industries and regions. The company's future development plans include expanding its recruitment efforts to include more diverse and talented candidates, improving its recruitment process to ensure that the company attracts the best candidates, and investing in training and development programs to help employees grow and develop their skills. The company also plans to invest in employee retention programs to ensure that employees remain with the company and contribute to the\n",
      "\n",
      "âœ… ä½¿ç”¨ zero delta ç”Ÿæˆæ–‡æœ¬...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [00:03<00:00, 66.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ æ—  delta å¼•å¯¼çš„ç”Ÿæˆè¾“å‡ºï¼š\n",
      "\n",
      " The company's current strategic direction is to focus on expanding its market share and increasing its revenue. The company has identified several key areas for growth, including expanding its product line, improving its customer service, and increasing its marketing efforts. The company has also identified several potential growth opportunities, including entering new markets and developing new products. The company has also identified several areas for improvement, including improving its supply chain and reducing its costs. The company has also identified several potential risks, including economic downturns and competition from other companies. The company has also identified several potential opportunities, including new technologies and changing consumer preferences. The company has also identified several potential challenges, including regulatory changes and political instability. The company has also identified several potential partnerships, including with other companies and organizations. The company has also identified several potential investments, including in research and development and in new markets. The company has also identified several potential acquisitions, including in new product lines and in new markets. The company has also identified several potential divest\n"
     ]
    }
   ],
   "source": [
    "text_with, text_without = compare_delta_generation(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=prompt,\n",
    "    delta=delta,\n",
    "    answer_len=200\n",
    ")\n",
    "\n",
    "text_with, text_without = compare_delta_generation(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=prompt,\n",
    "    delta=delta_10,\n",
    "    answer_len=200\n",
    ")\n",
    "\n",
    "text_with, text_without = compare_delta_generation(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    prompt=prompt,\n",
    "    delta=delta_30,\n",
    "    answer_len=200\n",
    ")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T16:04:39.468531300Z",
     "start_time": "2025-06-05T16:04:21.243065800Z"
    }
   },
   "id": "9d2b35f01eee658e",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook SLOT-Qwen3_final.ipynb to html\n",
      "[NbConvertApp] Writing 376372 bytes to SLOT-Qwen3_final.html\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to html SLOT-Qwen3_final.ipynb"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-05T16:28:23.097111100Z",
     "start_time": "2025-06-05T16:28:21.015511Z"
    }
   },
   "id": "e75d62da549423c0",
   "execution_count": 28
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmrec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
