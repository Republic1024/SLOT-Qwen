{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3d0216445bd77a79"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from pylab import mpl, plt\n",
    "import matplotlib.patches as mpatches\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# best font and style settings for notebook \n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style(\"white\")\n",
    "mpl.rcParams['font.family'] = 'MiSans'\n",
    "\n",
    "model_path = r\"./Qwen3-0.6B\"  # modify to your Qwen Path\n",
    "# model_path = r\"./Qwen3-1.7B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-06T15:33:42.821755Z",
     "start_time": "2025-06-06T15:33:40.887729600Z"
    }
   },
   "id": "5c40a0c8ce972a1a",
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from delta_trainer import train_delta_from_H, generate_by_H, evaluate_slot_ceval, evaluate_slot_ceval_eos, \\\n",
    "    evaluate_slot_ceval_eos_2\n",
    "\n",
    "# æ„é€  prompt & å¾—åˆ° H_state\n",
    "prompt = \"è¯·å†™ä¸€æ®µå…³äºAIæ•™è‚²çš„å¼•è¨€ã€‚\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs, output_hidden_states=True, return_dict=True)\n",
    "H = outputs.hidden_states[-1]\n",
    "\n",
    "# è°ƒç”¨ delta è®­ç»ƒ\n",
    "delta_3 = train_delta_from_H(model, tokenizer, prompt, H, step=3)\n",
    "delta_10 = train_delta_from_H(model, tokenizer, prompt, H, step=10)\n",
    "delta_30 = train_delta_from_H(model, tokenizer, prompt, H, step=30)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-06T15:33:44.601993500Z",
     "start_time": "2025-06-06T15:33:44.337808500Z"
    }
   },
   "id": "cc16caa5c81a8ab2",
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# generate_by_H(model=model, prompt=prompt, tokenizer=tokenizer, delta=delta_3, answer_len=200)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d86f37fe68c63257",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "['accountant',\n 'advanced_mathematics',\n 'art_studies',\n 'basic_medicine',\n 'business_administration',\n 'chinese_language_and_literature',\n 'civil_servant',\n 'clinical_medicine',\n 'college_chemistry',\n 'college_economics',\n 'college_physics',\n 'college_programming',\n 'computer_architecture',\n 'computer_network',\n 'discrete_mathematics',\n 'education_science',\n 'electrical_engineer',\n 'environmental_impact_assessment_engineer',\n 'fire_engineer',\n 'high_school_biology',\n 'high_school_chemistry',\n 'high_school_chinese',\n 'high_school_geography',\n 'high_school_history',\n 'high_school_mathematics',\n 'high_school_physics',\n 'high_school_politics',\n 'ideological_and_moral_cultivation',\n 'law',\n 'legal_professional',\n 'logic',\n 'mao_zedong_thought',\n 'marxism',\n 'metrology_engineer',\n 'middle_school_biology',\n 'middle_school_chemistry',\n 'middle_school_geography',\n 'middle_school_history',\n 'middle_school_mathematics',\n 'middle_school_physics',\n 'middle_school_politics',\n 'modern_chinese_history',\n 'operating_system',\n 'physician',\n 'plant_protection',\n 'probability_and_statistics',\n 'professional_tour_guide',\n 'sports_science',\n 'tax_accountant',\n 'teacher_qualification',\n 'urban_and_rural_planner',\n 'veterinary_medicine']"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import get_dataset_config_names\n",
    "\n",
    "# è·å–æœ¬åœ°è·¯å¾„ \"./ceval-exam\" ä¸­å¯ç”¨çš„æ‰€æœ‰å­æ•°æ®é›†åç§°ï¼ˆconfig namesï¼‰\n",
    "dataset_path = \"./ceval-exam\"\n",
    "dataset_names = get_dataset_config_names(path=dataset_path)\n",
    "dataset_names"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-06T15:33:47.771933900Z",
     "start_time": "2025-06-06T15:33:47.601893700Z"
    }
   },
   "id": "1c9ac52d60c83894",
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-06T15:33:58.166486500Z",
     "start_time": "2025-06-06T15:33:57.985491300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 10, 'question': '____é‡‡ç”¨é“¾è·¯çŠ¶æ€ç®—æ³•', 'A': 'RIP', 'B': 'OSPF', 'C': 'BGP-4', 'D': 'EGP', 'answer': 'B', 'explanation': ''}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(r\"./ceval-exam\", name=\"computer_network\")\n",
    "print(dataset['val'][10])"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def evaluate_slot_ceval_eos(model, tokenizer, delta, example, max_len=20, verbose=True):\n",
    "    \"\"\"\n",
    "    åŸºäº generate_by_H_eos çš„è¯„ä¼°å‡½æ•°ï¼Œç”¨äº C-Eval å•é€‰é¢˜ç›®ã€‚\n",
    "\n",
    "    è¿”å›ï¼š\n",
    "    - predict_option: é¢„æµ‹é€‰é¡¹ï¼Œå¦‚ 'A'\n",
    "    - is_correct: æ˜¯å¦é¢„æµ‹æ­£ç¡®\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"ä»¥ä¸‹æ˜¯ä¸€é“å•é¡¹é€‰æ‹©é¢˜ï¼Œè¯·ä½ é˜…è¯»é¢˜ç›®å¹¶é€‰æ‹©æœ€åˆé€‚çš„é€‰é¡¹ã€‚\n",
    "\n",
    "é¢˜ç›®ï¼š{example['question']}\n",
    "\n",
    "é€‰é¡¹ï¼š\n",
    "A. {example['A']}\n",
    "B. {example['B']}\n",
    "C. {example['C']}\n",
    "D. {example['D']}\n",
    "\n",
    "ç­”æ¡ˆæ˜¯ï¼š\"\"\"\n",
    "\n",
    "    output_text = generate_by_H_eos(model, prompt, tokenizer, delta, answer_len=max_len)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"ğŸ” æ¨¡å‹ç”Ÿæˆç»“æœ:\\n\", output_text)\n",
    "\n",
    "    predict_option = None\n",
    "    for option in ['A', 'B', 'C', 'D']:\n",
    "        if option in output_text:\n",
    "            predict_option = option\n",
    "            break\n",
    "\n",
    "    is_correct = (predict_option == example['answer'])\n",
    "    # return predict_option, is_correct\n",
    "    return output_text, predict_option, example['answer'], is_correct"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "154970daa54d317c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from delta_trainer import generate_by_H_eos\n",
    "\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def generate_by_H_eos_fast(model, prompt, tokenizer, delta, answer_len=100):\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨ past_key_values åŠ é€Ÿï¼Œæ”¯æŒ eos æˆªæ–­çš„ H å±‚æ‰°åŠ¨ç”Ÿæˆã€‚\n",
    "\n",
    "    å‚æ•°ï¼š\n",
    "    - model: æ”¯æŒ use_cache çš„ decoder-only æ¨¡å‹ï¼ˆå¦‚ GPT ç³»åˆ—ï¼‰\n",
    "    - prompt: è¾“å…¥æ–‡æœ¬\n",
    "    - tokenizer: åˆ†è¯å™¨\n",
    "    - delta: shape=[1, 1, hidden_size] çš„æ‰°åŠ¨å¼ é‡\n",
    "    - answer_len: æœ€å¤šç”Ÿæˆ token æ•°\n",
    "\n",
    "    è¿”å›ï¼š\n",
    "    - record_txt: è§£ç åçš„æ–‡æœ¬ï¼ˆä¸å« prompt éƒ¨åˆ†ï¼‰\n",
    "    \"\"\"\n",
    "    eos_token_id = tokenizer.eos_token_id\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    input_ids = inputs[\"input_ids\"]  # [1, L_prompt]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # åˆå§‹åŒ–æ¨ç†ï¼Œç¼“å­˜ key_values\n",
    "        outputs = model(input_ids=input_ids, return_dict=True, output_hidden_states=True, use_cache=True)\n",
    "        past_key_values = outputs.past_key_values\n",
    "\n",
    "        # é¦–ä¸ªæ‰°åŠ¨ + ç”Ÿæˆ\n",
    "        H_last = outputs.hidden_states[-1][:, -1, :] + delta.squeeze(1)  # [1, hidden_size]\n",
    "        logits = torch.matmul(H_last, model.lm_head.weight.T)\n",
    "        next_token_id = torch.argmax(logits, dim=-1, keepdim=True)  # [1, 1]\n",
    "\n",
    "    record = [next_token_id]  # æ”¶é›†ç”Ÿæˆ token\n",
    "\n",
    "    for _ in range(answer_len - 1):  # å·²ç”Ÿæˆ 1 ä¸ªï¼Œæœ€å¤šç”Ÿæˆ answer_len ä¸ª\n",
    "        if next_token_id.item() == eos_token_id:\n",
    "            break\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(\n",
    "                input_ids=next_token_id,\n",
    "                past_key_values=past_key_values,\n",
    "                return_dict=True,\n",
    "                output_hidden_states=True,\n",
    "                use_cache=True\n",
    "            )\n",
    "            past_key_values = outputs.past_key_values\n",
    "            H_last = outputs.hidden_states[-1][:, -1, :] + delta.squeeze(1)\n",
    "            logits = torch.matmul(H_last, model.lm_head.weight.T)\n",
    "            next_token_id = torch.argmax(logits, dim=-1, keepdim=True)  # [1, 1]\n",
    "\n",
    "        record.append(next_token_id)\n",
    "\n",
    "    # æ‹¼æ¥ç”Ÿæˆåºåˆ—ï¼ˆä¸å« promptï¼‰\n",
    "    gen_ids = torch.cat(record, dim=-1)  # [1, T]\n",
    "    record_txt = tokenizer.decode(gen_ids[0], skip_special_tokens=True)\n",
    "    return record_txt\n",
    "\n",
    "\n",
    "def evaluate_slot_ceval_eos(model, tokenizer, delta, example, prompt, max_len=20, verbose=True):\n",
    "    \"\"\"\n",
    "    åŸºäº generate_by_H_eos çš„è¯„ä¼°å‡½æ•°ï¼Œç”¨äº C-Eval å•é€‰é¢˜ç›®ã€‚\n",
    "\n",
    "    è¿”å›ï¼š\n",
    "    - predict_option: é¢„æµ‹é€‰é¡¹ï¼Œå¦‚ 'A'\n",
    "    - is_correct: æ˜¯å¦é¢„æµ‹æ­£ç¡®\n",
    "    # \"\"\"\n",
    "\n",
    "    # output_text = generate_by_H_eos(model, prompt, tokenizer, delta, answer_len=max_len)\n",
    "    output_text = generate_by_H_eos_fast(model, prompt, tokenizer, delta, answer_len=max_len)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"ğŸ” æ¨¡å‹ç”Ÿæˆç»“æœ:\\n\", output_text)\n",
    "\n",
    "    predict_option = None\n",
    "    for option in ['A', 'B', 'C', 'D']:\n",
    "        if option in output_text:\n",
    "            predict_option = option\n",
    "            break\n",
    "\n",
    "    is_correct = (predict_option == example['answer'])\n",
    "    # return predict_option, is_correct\n",
    "    return output_text, predict_option, example['answer'], is_correct\n",
    "\n",
    "\n",
    "def eval_dataset(dataset_name, step=3, max_len=50, lr=1e-2):\n",
    "    # dataset_name = \"computer_network\"\n",
    "    dataset = load_dataset(r\"./ceval-exam\", name=dataset_name)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    answer_sheet = []\n",
    "    for ex in tqdm(dataset['val']):\n",
    "        # === æ„é€ æ¯é“é¢˜çš„ Prompt ===\n",
    "        prompt = f\"\"\"ä»¥ä¸‹æ˜¯ä¸€é“å•é¡¹é€‰æ‹©é¢˜ï¼Œè¯·ä½ é˜…è¯»é¢˜ç›®ï¼Œé€‰æ‹©æœ€åˆé€‚çš„é€‰é¡¹ã€‚\n",
    "        é¢˜ç›®ï¼š{ex['question']}\n",
    "        é€‰é¡¹ï¼š\n",
    "        A. {ex['A']}\n",
    "        B. {ex['B']}\n",
    "        C. {ex['C']}\n",
    "        D. {ex['D']}\n",
    "        ç­”æ¡ˆæ˜¯ï¼š\"\"\"\n",
    "        prompt = f\"\"\"è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\n",
    "        \n",
    "        é¢˜ç›®ï¼š\n",
    "        {ex['question']}\n",
    "        \n",
    "        é€‰é¡¹ï¼š\n",
    "        A. {ex['A']}\n",
    "        B. {ex['B']}\n",
    "        C. {ex['C']}\n",
    "        D. {ex['D']}\n",
    "        \n",
    "        ç­”æ¡ˆæ˜¯ï¼š\"\"\"\n",
    "\n",
    "#         prompt = f\"\"\"è¯·é˜…è¯»ä»¥ä¸‹å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶ä»å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºä¸€ä¸ªæœ€åˆé€‚çš„ç­”æ¡ˆã€‚\n",
    "# \n",
    "# é¢˜ç›®ï¼š\n",
    "# {ex['question']}\n",
    "# \n",
    "# é€‰é¡¹ï¼š\n",
    "# A. {ex['A']}\n",
    "# B. {ex['B']}\n",
    "# C. {ex['C']}\n",
    "# D. {ex['D']}\n",
    "# \n",
    "# è¯·ç›´æ¥å›ç­”ï¼Œç­”æ¡ˆæ˜¯ï¼š\"\"\"\n",
    "\n",
    "        # === è·å– H_state ===\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs, output_hidden_states=True, return_dict=True)\n",
    "        H = outputs.hidden_states[-1]\n",
    "\n",
    "        # === è®­ç»ƒ deltaï¼ˆä¾‹å¦‚3æ­¥ï¼‰===\n",
    "        delta = train_delta_from_H(model, tokenizer, prompt, H, step=step, lr=lr)\n",
    "\n",
    "        # === æ¨ç†ä¸è¯„ä¼° ===\n",
    "        pred_txt, pre_answer, answer, is_correct = evaluate_slot_ceval_eos(model=model, tokenizer=tokenizer,\n",
    "                                                                           delta=delta,\n",
    "                                                                           example=ex, max_len=max_len, prompt=prompt,\n",
    "                                                                           verbose=False)\n",
    "        correct += int(is_correct)\n",
    "        total += 1\n",
    "        answer_sheet.append([prompt, pred_txt, pre_answer, answer, is_correct, dataset_name])\n",
    "    print(f\"ğŸ¯ {dataset_name} Accuracy (per-question delta): {correct}/{total} = {correct / total:.2%}\")\n",
    "    return answer_sheet"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-06T15:34:09.985263200Z",
     "start_time": "2025-06-06T15:34:09.976310600Z"
    }
   },
   "id": "24d29f838758eb6",
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "'Qwen3-0.6B'"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path.split(\"/\")[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-06T15:34:36.797978900Z",
     "start_time": "2025-06-06T15:34:36.785981200Z"
    }
   },
   "id": "3b02b85fdbbff387",
   "execution_count": 88
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/52 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9d36e80d47c3454abad8202e91bb3413"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/49 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8b258fd61dfc4061a9b132883a1ebdb3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ accountant Accuracy (per-question delta): 25/49 = 51.02%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "51417e1c0167471a857de4dd61b01152"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ advanced_mathematics Accuracy (per-question delta): 4/19 = 21.05%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/33 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c939eb0c78774c9c9cf52f0227be254c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ art_studies Accuracy (per-question delta): 17/33 = 51.52%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "74fd690bf7a74f3ca78ce725a5dce4b9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ basic_medicine Accuracy (per-question delta): 13/19 = 68.42%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/33 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21938f2bfb8345868be088cb7b08dc09"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ business_administration Accuracy (per-question delta): 15/33 = 45.45%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "589c247eab464f2c8168c2f464be22cc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ chinese_language_and_literature Accuracy (per-question delta): 10/23 = 43.48%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/47 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4274ec639c7848ed85901aa5d977d6a0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ civil_servant Accuracy (per-question delta): 20/47 = 42.55%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/22 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "79acece2f60e4af889d7345bd10984d6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ clinical_medicine Accuracy (per-question delta): 9/22 = 40.91%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "83cb83e46aa94e54af6dd3c2ed556b43"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ college_chemistry Accuracy (per-question delta): 9/24 = 37.50%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/55 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "159ad229892b486c915b95b8a208d0cf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ college_economics Accuracy (per-question delta): 27/55 = 49.09%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b71ef992051b47de901c94f52905538a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ college_physics Accuracy (per-question delta): 11/19 = 57.89%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dbb7ee07c59840728e520517ac623bfd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ college_programming Accuracy (per-question delta): 15/37 = 40.54%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/21 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8eeb675d4bca40899e65718598927cc9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ computer_architecture Accuracy (per-question delta): 8/21 = 38.10%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "340ffb1b9fab48b0a8128b0fb49882a9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ computer_network Accuracy (per-question delta): 7/19 = 36.84%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/16 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e6ac0eae8f514193975d20e0af480add"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ discrete_mathematics Accuracy (per-question delta): 5/16 = 31.25%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/29 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "615b4df2b08841b7b1e8e3081faafc6a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ education_science Accuracy (per-question delta): 19/29 = 65.52%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a271deac3de04b04a2b6d448347d0108"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ electrical_engineer Accuracy (per-question delta): 16/37 = 43.24%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/31 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "87670301f1994e85afb4651cee41b7d6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ environmental_impact_assessment_engineer Accuracy (per-question delta): 21/31 = 67.74%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/31 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d9601bb9c0134a108021997d8f2f86f3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ fire_engineer Accuracy (per-question delta): 14/31 = 45.16%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "455ff46e1eba428ba5d42f8904c0634d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ high_school_biology Accuracy (per-question delta): 9/19 = 47.37%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a3efa5d8eb364d87bd271e92f89144c3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ high_school_chemistry Accuracy (per-question delta): 7/19 = 36.84%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "42683bf53a2f4c7bb6a82abca212de1d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ high_school_chinese Accuracy (per-question delta): 7/19 = 36.84%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "664eda4f3acd4f7eb30eeb331e57991d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ high_school_geography Accuracy (per-question delta): 8/19 = 42.11%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e221d643f2b44d40a2d454e6476f5f5a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ high_school_history Accuracy (per-question delta): 16/20 = 80.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/18 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e2eeea34f11944bbaea0b2a999c74223"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ high_school_mathematics Accuracy (per-question delta): 6/18 = 33.33%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "843563e526a14aaf85fab2d2acda4534"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ high_school_physics Accuracy (per-question delta): 11/19 = 57.89%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ab4bb5ab8bf24dd0b6d0e04e3c1ad5fc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ high_school_politics Accuracy (per-question delta): 12/19 = 63.16%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "78eee919cf974604bbd3ac199b54b5f4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ ideological_and_moral_cultivation Accuracy (per-question delta): 14/19 = 73.68%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e724c809c956428db36a674ea32992d2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ law Accuracy (per-question delta): 6/24 = 25.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "70358b562cf74a70916552ed19353f4b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ legal_professional Accuracy (per-question delta): 8/23 = 34.78%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/22 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "093e1e62308d4108a6b657d14f58fae9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ logic Accuracy (per-question delta): 13/22 = 59.09%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c91c772aaebf4a2180019a3dffd244b7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ mao_zedong_thought Accuracy (per-question delta): 19/24 = 79.17%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0c371036d7ed4b149dc1ea08a0ff6bf6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ marxism Accuracy (per-question delta): 12/19 = 63.16%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9a22bdfa07a47e086533e868a279ebf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ metrology_engineer Accuracy (per-question delta): 14/24 = 58.33%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/21 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4ac186a8e0ae472e8fe7210a35333059"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ middle_school_biology Accuracy (per-question delta): 14/21 = 66.67%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6ac3ea9710ef47d09622768da10d423f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ middle_school_chemistry Accuracy (per-question delta): 13/20 = 65.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/12 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "996551f86849476a982a93b9ed3eb423"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ middle_school_geography Accuracy (per-question delta): 6/12 = 50.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/22 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fa12f86b72c34fea8f3d8fc9db876ae8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ middle_school_history Accuracy (per-question delta): 12/22 = 54.55%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6ede9517924c4d8aa996f6c3d96fa221"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ middle_school_mathematics Accuracy (per-question delta): 6/19 = 31.58%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "576bc027a2984c19abc18979b7820369"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ middle_school_physics Accuracy (per-question delta): 10/19 = 52.63%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/21 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "731dbde5453e46f498d0fdd6127c36af"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ middle_school_politics Accuracy (per-question delta): 15/21 = 71.43%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "91d6cda07b17422eb86352032402062a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ modern_chinese_history Accuracy (per-question delta): 11/23 = 47.83%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e319b4d2ca2b469194ccab3ac7e031fc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ operating_system Accuracy (per-question delta): 9/19 = 47.37%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/49 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "77e573e7330044eea5c65daee11ae849"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ physician Accuracy (per-question delta): 24/49 = 48.98%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/22 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c17db2d4709a4f3bb8806a775a4ac516"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ plant_protection Accuracy (per-question delta): 13/22 = 59.09%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/18 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ba51825207dd48e5972bd531df4151bb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ probability_and_statistics Accuracy (per-question delta): 4/18 = 22.22%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/29 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2eb4afe51dd34cd7a957b9da93bdf25f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ professional_tour_guide Accuracy (per-question delta): 15/29 = 51.72%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "82e53d91b6f74fc59acb3be13f88d705"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ sports_science Accuracy (per-question delta): 7/19 = 36.84%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/49 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6a9c7c30dc1c425ca957f7f1e87bd444"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ tax_accountant Accuracy (per-question delta): 24/49 = 48.98%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/44 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e3f023e6c72a4cbda481166cd283e6fd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ teacher_qualification Accuracy (per-question delta): 28/44 = 63.64%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/46 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9df2b0fcbf63424c9e35780e17eb19a4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ urban_and_rural_planner Accuracy (per-question delta): 29/46 = 63.04%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "af6d0ca6bf8f403a97715bea4094aef8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ veterinary_medicine Accuracy (per-question delta): 10/23 = 43.48%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/52 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a95f1b7297e41358c5b4a41e057632d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/49 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "258606aaa34349e68f51c78013c69e6c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ accountant Accuracy (per-question delta): 25/49 = 51.02%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "37c0acaf7653487cb0ff4591b93ac6a9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ advanced_mathematics Accuracy (per-question delta): 4/19 = 21.05%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/33 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a7088176f27d46e78fe8162441e4b773"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ art_studies Accuracy (per-question delta): 17/33 = 51.52%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b14af5ac9faf4d10991b7e5ed2d6b017"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ basic_medicine Accuracy (per-question delta): 13/19 = 68.42%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/33 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3edec34957ba4b6c97b36d0e18bf925c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ business_administration Accuracy (per-question delta): 15/33 = 45.45%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "327e9866fd754d14b037bc3f9ebf3a05"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ chinese_language_and_literature Accuracy (per-question delta): 10/23 = 43.48%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/47 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "44e3e6563a7f4e3faa0868bd4ea98104"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ civil_servant Accuracy (per-question delta): 20/47 = 42.55%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/22 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e8736726a6164882b5568e86676ac8c2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ clinical_medicine Accuracy (per-question delta): 9/22 = 40.91%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cabd9e64c50447b0a844941000032584"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ college_chemistry Accuracy (per-question delta): 9/24 = 37.50%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/55 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "054b43484ff842b8a7b9e7ebd14d9781"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ college_economics Accuracy (per-question delta): 26/55 = 47.27%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2503660dfb0b491db3b33229401ebee1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ college_physics Accuracy (per-question delta): 11/19 = 57.89%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8bf50e6ac2d94f1ab5c778cd9062b5ca"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ college_programming Accuracy (per-question delta): 16/37 = 43.24%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/21 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e434afd298444478b3173f947e61bfe3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ computer_architecture Accuracy (per-question delta): 8/21 = 38.10%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a63e2589571741d8aa8eed7bec6d1ffb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ computer_network Accuracy (per-question delta): 7/19 = 36.84%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/16 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5e42020b5fa44cfebcb511b7e7203c48"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ discrete_mathematics Accuracy (per-question delta): 5/16 = 31.25%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/29 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "028fc86ffbc846faa4aaf68e2d8622ad"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ education_science Accuracy (per-question delta): 19/29 = 65.52%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a07a40c3a0814cc4988e0eeaa5f54b13"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ electrical_engineer Accuracy (per-question delta): 15/37 = 40.54%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/31 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "71e70a6cb484463c8449d130f3244c79"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ environmental_impact_assessment_engineer Accuracy (per-question delta): 21/31 = 67.74%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/31 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "897d09db5a1f4a698caaaab989300f5e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ fire_engineer Accuracy (per-question delta): 14/31 = 45.16%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1bf5e2f9fd5d43f39ba0cca0ed6cfbbb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ high_school_biology Accuracy (per-question delta): 9/19 = 47.37%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad763c46df264dce89e778d776d7454b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ high_school_chemistry Accuracy (per-question delta): 7/19 = 36.84%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2be715d4f952432da2ced444f91cb971"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ high_school_chinese Accuracy (per-question delta): 7/19 = 36.84%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "113653a0eeed44ccafac8e47b90476e4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ high_school_geography Accuracy (per-question delta): 10/19 = 52.63%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "726d6ab82c3e4536b0960f81ba9dae19"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ high_school_history Accuracy (per-question delta): 17/20 = 85.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/18 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4f0b9576958f409e8a26329e251e3bfe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ high_school_mathematics Accuracy (per-question delta): 6/18 = 33.33%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f3fbb9264ad848989566ee06844e5f42"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ high_school_physics Accuracy (per-question delta): 11/19 = 57.89%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "77a58a749215499c841c82a0a784ff05"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ high_school_politics Accuracy (per-question delta): 12/19 = 63.16%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7aa018dd6c57456a837a35f4759ff333"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ ideological_and_moral_cultivation Accuracy (per-question delta): 14/19 = 73.68%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4d168fb9ed54493bb47b3fe2487cf09b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ law Accuracy (per-question delta): 6/24 = 25.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c919bebaad634a8d95e377406701fbf8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ legal_professional Accuracy (per-question delta): 8/23 = 34.78%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/22 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9671d2b685b6475bae66e1806b561d92"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ logic Accuracy (per-question delta): 12/22 = 54.55%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8260ec7f747145e88dad1c661ad71099"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ mao_zedong_thought Accuracy (per-question delta): 18/24 = 75.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9059b9f0835e468cb003a7f656bfd624"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ marxism Accuracy (per-question delta): 12/19 = 63.16%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "32e3ec46052d454fbc4daed5478d4c9c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ metrology_engineer Accuracy (per-question delta): 14/24 = 58.33%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/21 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e45478c4fc7849adbb1aaffe0baeba55"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ middle_school_biology Accuracy (per-question delta): 14/21 = 66.67%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e4243f4c73914a92ad4caf93cf24d1ec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ middle_school_chemistry Accuracy (per-question delta): 13/20 = 65.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/12 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "961c20f887ed4aa09ee580591d482bef"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ middle_school_geography Accuracy (per-question delta): 6/12 = 50.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/22 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4d10f24b60a342828dfec7aebcc13ed8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ middle_school_history Accuracy (per-question delta): 12/22 = 54.55%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b1752ab3fabd40068928a5c9019d1f02"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ middle_school_mathematics Accuracy (per-question delta): 6/19 = 31.58%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bbd84db7c531415fa5ac950ccd4c47ad"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ middle_school_physics Accuracy (per-question delta): 10/19 = 52.63%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/21 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a3246547dd0f47b797798c7227b69719"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ middle_school_politics Accuracy (per-question delta): 15/21 = 71.43%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b4d8d4bba3144b30933d4cf7ce28443a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ modern_chinese_history Accuracy (per-question delta): 11/23 = 47.83%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "343d53de6d604e5a9cc565e6c174b813"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ operating_system Accuracy (per-question delta): 9/19 = 47.37%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/49 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8533e37672b6494ba2bd7a0bd1cd19f5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ physician Accuracy (per-question delta): 24/49 = 48.98%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/22 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7b6a4fcbaad14e7daaa36f48f34e33f9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ plant_protection Accuracy (per-question delta): 13/22 = 59.09%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/18 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a70c7f2738fa4f8dbcdac39209500812"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ probability_and_statistics Accuracy (per-question delta): 5/18 = 27.78%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/29 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "472473c4fd5f4cbc8d0b570112795c81"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for step in [3, 0, 6, 9]:\n",
    "    max_len = 5\n",
    "    answer_sheet = []\n",
    "    for dataset_name in tqdm(dataset_names[:]):\n",
    "        answer_sheet += eval_dataset(dataset_name=dataset_name, step=step, max_len=max_len, lr=1e-2)\n",
    "        df_answer = pd.DataFrame(answer_sheet)\n",
    "        df_answer.to_csv(f\"./eval_result/0_6B/answer_step_{step}.csv\", index=False)\n",
    "pd.DataFrame(answer_sheet)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2025-06-06T15:34:57.567840Z"
    }
   },
   "id": "387be86860d8f430"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for step in [3, 0, 6, 9]:\n",
    "    max_len = 5\n",
    "    answer_sheet = []\n",
    "    for dataset_name in tqdm(dataset_names[:]):\n",
    "        answer_sheet += eval_dataset(dataset_name=dataset_name, step=step, max_len=max_len, lr=1e-2)\n",
    "        df_answer = pd.DataFrame(answer_sheet)\n",
    "        df_answer.to_csv(f\"./eval_result/1_7B/answer_step_{step}.csv\", index=False)\n",
    "pd.DataFrame(answer_sheet)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d1a41f8865f96fe",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/52 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fd977e37cd24408ba467ff390229cd2f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/49 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "198b5dbdb4994367834b286c66a45739"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ accountant Accuracy (per-question delta): 25/49 = 51.02%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "191ecc9273e44e24b67f043d63cb926b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ advanced_mathematics Accuracy (per-question delta): 8/19 = 42.11%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/33 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5827b456b15d487f8cab6ed3936148d4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ art_studies Accuracy (per-question delta): 21/33 = 63.64%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3b9674735c5045ef8dae6eb60d3f9631"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ basic_medicine Accuracy (per-question delta): 13/19 = 68.42%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/33 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0783f97b286940bd9bb0eb6a0099e5e4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ business_administration Accuracy (per-question delta): 20/33 = 60.61%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2611f1e8ab7d442e89976969c3fafb6f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ chinese_language_and_literature Accuracy (per-question delta): 14/23 = 60.87%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/47 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6152ac1c7d69483abb9fda1677f456b7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ civil_servant Accuracy (per-question delta): 25/47 = 53.19%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/22 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4310f943f570467eb0db69484ea666c0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ clinical_medicine Accuracy (per-question delta): 10/22 = 45.45%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c120c4fd4c1d433da5b48886876ccf9b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ college_chemistry Accuracy (per-question delta): 12/24 = 50.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/55 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7ef6f0dc315447c59cc96c9ae9c3fd10"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ college_economics Accuracy (per-question delta): 25/55 = 45.45%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "37d6fee045354fa0bb550b74daa8615e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ college_physics Accuracy (per-question delta): 8/19 = 42.11%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6fd69e0328334b38a634e9f88c602f84"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ college_programming Accuracy (per-question delta): 26/37 = 70.27%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/21 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8fc89813712848539e9cefc3544ff514"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ computer_architecture Accuracy (per-question delta): 12/21 = 57.14%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ae54148bef13404594fa085f81d07016"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ computer_network Accuracy (per-question delta): 10/19 = 52.63%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/16 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3f8892845762499e8c612b6471fd7189"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ discrete_mathematics Accuracy (per-question delta): 4/16 = 25.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/29 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aebcde8869144b47a19bc2f920ef6a57"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ education_science Accuracy (per-question delta): 20/29 = 68.97%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "709051ddcbf242e6a8afb068cf66ba5b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ electrical_engineer Accuracy (per-question delta): 17/37 = 45.95%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/31 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d54ef2aa2eda419189246df9d90e83e8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ environmental_impact_assessment_engineer Accuracy (per-question delta): 21/31 = 67.74%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/31 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "33d145bd124b489a8ae6a3f2f1d4b273"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ fire_engineer Accuracy (per-question delta): 18/31 = 58.06%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fa792fb766654a9699335ea6339f24a3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ high_school_biology Accuracy (per-question delta): 8/19 = 42.11%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d8770f53ca2e413485cd8eddf559ce00"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ high_school_chemistry Accuracy (per-question delta): 9/19 = 47.37%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b20900d8c4e42dbb826054acd6d39d1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ high_school_chinese Accuracy (per-question delta): 9/19 = 47.37%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fca9db734990409191016126482869e9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ high_school_geography Accuracy (per-question delta): 12/19 = 63.16%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dc5a3e4a4a7e4672b725f7c8068bb2bd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ high_school_history Accuracy (per-question delta): 15/20 = 75.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/18 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "06e8ca4d9dfb48e89587813c856ec457"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ high_school_mathematics Accuracy (per-question delta): 5/18 = 27.78%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1aa06913490842f4ae3fc375544a2d71"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ high_school_physics Accuracy (per-question delta): 11/19 = 57.89%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "83eec93fa01444368ea5b6ff9060e2e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ high_school_politics Accuracy (per-question delta): 14/19 = 73.68%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "198b65432dec4e718b108c4f84ef48eb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ ideological_and_moral_cultivation Accuracy (per-question delta): 14/19 = 73.68%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9e9e3db83fbf420cb3609c9ff9d41804"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ law Accuracy (per-question delta): 10/24 = 41.67%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0df2fd74b89a4f6c9aae7058509238e7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ legal_professional Accuracy (per-question delta): 9/23 = 39.13%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/22 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7a3da90612d343f4801c119ae486fd2a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ logic Accuracy (per-question delta): 12/22 = 54.55%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "161046b6a45b45f3bf5f894fd6911919"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ mao_zedong_thought Accuracy (per-question delta): 20/24 = 83.33%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3d45422a70654a3f86b733686600fa96"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ marxism Accuracy (per-question delta): 14/19 = 73.68%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "68ef08c696d14a14a50345b07085333d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ metrology_engineer Accuracy (per-question delta): 18/24 = 75.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/21 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ffdb625484ae4a7fa06d28bd6e34baad"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ middle_school_biology Accuracy (per-question delta): 18/21 = 85.71%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4c6e78e4890f4225941e0bd3e575d4c0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ middle_school_chemistry Accuracy (per-question delta): 19/20 = 95.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/12 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f7734055114249ac820917e32acb5126"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ middle_school_geography Accuracy (per-question delta): 7/12 = 58.33%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/22 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b5ef1f445f6544ed9757e8ccc8381c87"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ middle_school_history Accuracy (per-question delta): 16/22 = 72.73%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5b2a96345e6d46428e7b626e95783f27"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ middle_school_mathematics Accuracy (per-question delta): 6/19 = 31.58%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ac04fbd117ee47438d97c3099fec113a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ middle_school_physics Accuracy (per-question delta): 17/19 = 89.47%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/21 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "884d6e9b4bd14e73a2441bd22f5b8dbb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ middle_school_politics Accuracy (per-question delta): 17/21 = 80.95%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7a4416a551ce42ec863d5297198865a2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ modern_chinese_history Accuracy (per-question delta): 12/23 = 52.17%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a5a05630436e46388b80a794a92a16cc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ operating_system Accuracy (per-question delta): 8/19 = 42.11%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/49 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ae283a63d42346859b0ccab613c8be5b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ physician Accuracy (per-question delta): 29/49 = 59.18%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/22 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0b0e217adf0c4e318dd50a738719d6f3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ plant_protection Accuracy (per-question delta): 15/22 = 68.18%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/18 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "28f8fd28d97d45dd85718636b399da22"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ probability_and_statistics Accuracy (per-question delta): 7/18 = 38.89%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/29 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "369a25932ef4428c822be371f3c7489e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ professional_tour_guide Accuracy (per-question delta): 13/29 = 44.83%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a577dd15bbe54d91888b168a655c08fe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ sports_science Accuracy (per-question delta): 9/19 = 47.37%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/49 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ab931e792e07482798477e5414bb8019"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ tax_accountant Accuracy (per-question delta): 22/49 = 44.90%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/44 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "efc6b7df17664cf8b9a9b92ffb64e6ea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ teacher_qualification Accuracy (per-question delta): 36/44 = 81.82%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/46 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "acf4de613ba2468092eed47cf1100564"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ urban_and_rural_planner Accuracy (per-question delta): 34/46 = 73.91%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f4ebc326cde34393964c038bf36ce27c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ veterinary_medicine Accuracy (per-question delta): 13/23 = 56.52%\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                      0              1  2  3  \\\n0     è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...  D\\n        ä½ çš„  D  D   \n1     è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...   C\\n        è¯·  C  C   \n2     è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...   D\\n        è¯·  D  D   \n3     è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...  A\\n        ä½ çš„  A  A   \n4     è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...   C\\n        è¯·  C  C   \n...                                                 ...            ... .. ..   \n1341  è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...   A\\n        è¯·  A  A   \n1342  è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...   D\\n        è¯·  D  D   \n1343  è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...   C\\n        è¯·  C  A   \n1344  è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...   C\\n        è¯·  C  C   \n1345  è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...   C\\n        è¯·  C  C   \n\n          4                    5  \n0      True           accountant  \n1      True           accountant  \n2      True           accountant  \n3      True           accountant  \n4      True           accountant  \n...     ...                  ...  \n1341   True  veterinary_medicine  \n1342   True  veterinary_medicine  \n1343  False  veterinary_medicine  \n1344   True  veterinary_medicine  \n1345   True  veterinary_medicine  \n\n[1346 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...</td>\n      <td>D\\n        ä½ çš„</td>\n      <td>D</td>\n      <td>D</td>\n      <td>True</td>\n      <td>accountant</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...</td>\n      <td>C\\n        è¯·</td>\n      <td>C</td>\n      <td>C</td>\n      <td>True</td>\n      <td>accountant</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...</td>\n      <td>D\\n        è¯·</td>\n      <td>D</td>\n      <td>D</td>\n      <td>True</td>\n      <td>accountant</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...</td>\n      <td>A\\n        ä½ çš„</td>\n      <td>A</td>\n      <td>A</td>\n      <td>True</td>\n      <td>accountant</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...</td>\n      <td>C\\n        è¯·</td>\n      <td>C</td>\n      <td>C</td>\n      <td>True</td>\n      <td>accountant</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1341</th>\n      <td>è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...</td>\n      <td>A\\n        è¯·</td>\n      <td>A</td>\n      <td>A</td>\n      <td>True</td>\n      <td>veterinary_medicine</td>\n    </tr>\n    <tr>\n      <th>1342</th>\n      <td>è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...</td>\n      <td>D\\n        è¯·</td>\n      <td>D</td>\n      <td>D</td>\n      <td>True</td>\n      <td>veterinary_medicine</td>\n    </tr>\n    <tr>\n      <th>1343</th>\n      <td>è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...</td>\n      <td>C\\n        è¯·</td>\n      <td>C</td>\n      <td>A</td>\n      <td>False</td>\n      <td>veterinary_medicine</td>\n    </tr>\n    <tr>\n      <th>1344</th>\n      <td>è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...</td>\n      <td>C\\n        è¯·</td>\n      <td>C</td>\n      <td>C</td>\n      <td>True</td>\n      <td>veterinary_medicine</td>\n    </tr>\n    <tr>\n      <th>1345</th>\n      <td>è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...</td>\n      <td>C\\n        è¯·</td>\n      <td>C</td>\n      <td>C</td>\n      <td>True</td>\n      <td>veterinary_medicine</td>\n    </tr>\n  </tbody>\n</table>\n<p>1346 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for step in [15]:\n",
    "    max_len = 5\n",
    "    answer_sheet = []\n",
    "    for dataset_name in tqdm(dataset_names[:]):\n",
    "        answer_sheet += eval_dataset(dataset_name=dataset_name, step=step, max_len=max_len, lr=1e-2)\n",
    "        df_answer = pd.DataFrame(answer_sheet)\n",
    "        df_answer.to_csv(f\"./eval_result/1_7B/answer_step_{step}.csv\", index=False)\n",
    "pd.DataFrame(answer_sheet)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-06T15:29:06.909273100Z",
     "start_time": "2025-06-06T15:20:39.837677Z"
    }
   },
   "id": "36b7dc42d77e04e1",
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for step in [3, 0, 6, 12]:\n",
    "    max_len = 30\n",
    "    answer_sheet = []\n",
    "    for i in tqdm(dataset_names[:]):\n",
    "        answer_sheet += eval_dataset(i, step=step, max_len=max_len, lr=1e-3)\n",
    "        df_answer = pd.DataFrame(answer_sheet)\n",
    "        df_answer.to_csv(f\"./eval_result/1_7B/answer_step_{step}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39220cfac51cfcc2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for step in [3]:\n",
    "    max_len = 50\n",
    "    answer_sheet = []\n",
    "    for i in tqdm(dataset_names[8]):\n",
    "        answer_sheet += eval_dataset(i, step=step, max_len=max_len, lr=1e-3)\n",
    "        df_answer = pd.DataFrame(answer_sheet)\n",
    "        df_answer.to_csv(f\"./eval_result/1_7B/answer_step_{step}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cbde9d64a1dae016",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pd.DataFrame(answer_sheet)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3ab4f334f4c6030",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
