{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3d0216445bd77a79"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from pylab import mpl, plt\n",
    "import matplotlib.patches as mpatches\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# best font and style settings for notebook \n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style(\"white\")\n",
    "mpl.rcParams['font.family'] = 'MiSans'\n",
    "\n",
    "model_path = r\"./Qwen3-0.6B\"  # modify to your Qwen Path\n",
    "# model_path = r\"./Qwen3-1.7B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c40a0c8ce972a1a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from delta_trainer import train_delta_from_H, generate_by_H, evaluate_slot_ceval, evaluate_slot_ceval_eos, \\\n",
    "    evaluate_slot_ceval_eos_2\n",
    "\n",
    "# æ„é€  prompt & å¾—åˆ° H_state\n",
    "prompt = \"è¯·å†™ä¸€æ®µå…³äºAIæ•™è‚²çš„å¼•è¨€ã€‚\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs, output_hidden_states=True, return_dict=True)\n",
    "H = outputs.hidden_states[-1]\n",
    "\n",
    "# è°ƒç”¨ delta è®­ç»ƒ\n",
    "delta_3 = train_delta_from_H(model, tokenizer, prompt, H, step=3)\n",
    "delta_10 = train_delta_from_H(model, tokenizer, prompt, H, step=10)\n",
    "delta_30 = train_delta_from_H(model, tokenizer, prompt, H, step=30)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc16caa5c81a8ab2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# generate_by_H(model=model, prompt=prompt, tokenizer=tokenizer, delta=delta_3, answer_len=200)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d86f37fe68c63257",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from datasets import get_dataset_config_names\n",
    "\n",
    "# è·å–æœ¬åœ°è·¯å¾„ \"./ceval-exam\" ä¸­å¯ç”¨çš„æ‰€æœ‰å­æ•°æ®é›†åç§°ï¼ˆconfig namesï¼‰\n",
    "dataset_path = \"./ceval-exam\"\n",
    "dataset_names = get_dataset_config_names(path=dataset_path)\n",
    "dataset_names"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c9ac52d60c83894",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(r\"./ceval-exam\", name=\"computer_network\")\n",
    "print(dataset['val'][10])"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def evaluate_slot_ceval_eos(model, tokenizer, delta, example, max_len=20, verbose=True):\n",
    "    \"\"\"\n",
    "    åŸºäº generate_by_H_eos çš„è¯„ä¼°å‡½æ•°ï¼Œç”¨äº C-Eval å•é€‰é¢˜ç›®ã€‚\n",
    "\n",
    "    è¿”å›ï¼š\n",
    "    - predict_option: é¢„æµ‹é€‰é¡¹ï¼Œå¦‚ 'A'\n",
    "    - is_correct: æ˜¯å¦é¢„æµ‹æ­£ç¡®\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"ä»¥ä¸‹æ˜¯ä¸€é“å•é¡¹é€‰æ‹©é¢˜ï¼Œè¯·ä½ é˜…è¯»é¢˜ç›®å¹¶é€‰æ‹©æœ€åˆé€‚çš„é€‰é¡¹ã€‚\n",
    "\n",
    "é¢˜ç›®ï¼š{example['question']}\n",
    "\n",
    "é€‰é¡¹ï¼š\n",
    "A. {example['A']}\n",
    "B. {example['B']}\n",
    "C. {example['C']}\n",
    "D. {example['D']}\n",
    "\n",
    "ç­”æ¡ˆæ˜¯ï¼š\"\"\"\n",
    "\n",
    "    output_text = generate_by_H_eos(model, prompt, tokenizer, delta, answer_len=max_len)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"ğŸ” æ¨¡å‹ç”Ÿæˆç»“æœ:\\n\", output_text)\n",
    "\n",
    "    predict_option = None\n",
    "    for option in ['A', 'B', 'C', 'D']:\n",
    "        if option in output_text:\n",
    "            predict_option = option\n",
    "            break\n",
    "\n",
    "    is_correct = (predict_option == example['answer'])\n",
    "    # return predict_option, is_correct\n",
    "    return output_text, predict_option, example['answer'], is_correct"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "154970daa54d317c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from delta_trainer import generate_by_H_eos\n",
    "\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def generate_by_H_eos_fast(model, prompt, tokenizer, delta, answer_len=100):\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨ past_key_values åŠ é€Ÿï¼Œæ”¯æŒ eos æˆªæ–­çš„ H å±‚æ‰°åŠ¨ç”Ÿæˆã€‚\n",
    "\n",
    "    å‚æ•°ï¼š\n",
    "    - model: æ”¯æŒ use_cache çš„ decoder-only æ¨¡å‹ï¼ˆå¦‚ GPT ç³»åˆ—ï¼‰\n",
    "    - prompt: è¾“å…¥æ–‡æœ¬\n",
    "    - tokenizer: åˆ†è¯å™¨\n",
    "    - delta: shape=[1, 1, hidden_size] çš„æ‰°åŠ¨å¼ é‡\n",
    "    - answer_len: æœ€å¤šç”Ÿæˆ token æ•°\n",
    "\n",
    "    è¿”å›ï¼š\n",
    "    - record_txt: è§£ç åçš„æ–‡æœ¬ï¼ˆä¸å« prompt éƒ¨åˆ†ï¼‰\n",
    "    \"\"\"\n",
    "    eos_token_id = tokenizer.eos_token_id\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    input_ids = inputs[\"input_ids\"]  # [1, L_prompt]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # åˆå§‹åŒ–æ¨ç†ï¼Œç¼“å­˜ key_values\n",
    "        outputs = model(input_ids=input_ids, return_dict=True, output_hidden_states=True, use_cache=True)\n",
    "        past_key_values = outputs.past_key_values\n",
    "\n",
    "        # é¦–ä¸ªæ‰°åŠ¨ + ç”Ÿæˆ\n",
    "        H_last = outputs.hidden_states[-1][:, -1, :] + delta.squeeze(1)  # [1, hidden_size]\n",
    "        logits = torch.matmul(H_last, model.lm_head.weight.T)\n",
    "        next_token_id = torch.argmax(logits, dim=-1, keepdim=True)  # [1, 1]\n",
    "\n",
    "    record = [next_token_id]  # æ”¶é›†ç”Ÿæˆ token\n",
    "\n",
    "    for _ in range(answer_len - 1):  # å·²ç”Ÿæˆ 1 ä¸ªï¼Œæœ€å¤šç”Ÿæˆ answer_len ä¸ª\n",
    "        if next_token_id.item() == eos_token_id:\n",
    "            break\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(\n",
    "                input_ids=next_token_id,\n",
    "                past_key_values=past_key_values,\n",
    "                return_dict=True,\n",
    "                output_hidden_states=True,\n",
    "                use_cache=True\n",
    "            )\n",
    "            past_key_values = outputs.past_key_values\n",
    "            H_last = outputs.hidden_states[-1][:, -1, :] + delta.squeeze(1)\n",
    "            logits = torch.matmul(H_last, model.lm_head.weight.T)\n",
    "            next_token_id = torch.argmax(logits, dim=-1, keepdim=True)  # [1, 1]\n",
    "\n",
    "        record.append(next_token_id)\n",
    "\n",
    "    # æ‹¼æ¥ç”Ÿæˆåºåˆ—ï¼ˆä¸å« promptï¼‰\n",
    "    gen_ids = torch.cat(record, dim=-1)  # [1, T]\n",
    "    record_txt = tokenizer.decode(gen_ids[0], skip_special_tokens=True)\n",
    "    return record_txt\n",
    "\n",
    "\n",
    "def evaluate_slot_ceval_eos(model, tokenizer, delta, example, prompt, max_len=20, verbose=True):\n",
    "    \"\"\"\n",
    "    åŸºäº generate_by_H_eos çš„è¯„ä¼°å‡½æ•°ï¼Œç”¨äº C-Eval å•é€‰é¢˜ç›®ã€‚\n",
    "\n",
    "    è¿”å›ï¼š\n",
    "    - predict_option: é¢„æµ‹é€‰é¡¹ï¼Œå¦‚ 'A'\n",
    "    - is_correct: æ˜¯å¦é¢„æµ‹æ­£ç¡®\n",
    "    # \"\"\"\n",
    "\n",
    "    # output_text = generate_by_H_eos(model, prompt, tokenizer, delta, answer_len=max_len)\n",
    "    output_text = generate_by_H_eos_fast(model, prompt, tokenizer, delta, answer_len=max_len)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"ğŸ” æ¨¡å‹ç”Ÿæˆç»“æœ:\\n\", output_text)\n",
    "\n",
    "    predict_option = None\n",
    "    for option in ['A', 'B', 'C', 'D']:\n",
    "        if option in output_text:\n",
    "            predict_option = option\n",
    "            break\n",
    "\n",
    "    is_correct = (predict_option == example['answer'])\n",
    "    # return predict_option, is_correct\n",
    "    return output_text, predict_option, example['answer'], is_correct\n",
    "\n",
    "\n",
    "def eval_dataset(dataset_name, step=3, max_len=50, lr=1e-2):\n",
    "    # dataset_name = \"computer_network\"\n",
    "    dataset = load_dataset(r\"./ceval-exam\", name=dataset_name)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    answer_sheet = []\n",
    "    for ex in tqdm(dataset['val']):\n",
    "        # === æ„é€ æ¯é“é¢˜çš„ Prompt ===\n",
    "        prompt = f\"\"\"ä»¥ä¸‹æ˜¯ä¸€é“å•é¡¹é€‰æ‹©é¢˜ï¼Œè¯·ä½ é˜…è¯»é¢˜ç›®ï¼Œé€‰æ‹©æœ€åˆé€‚çš„é€‰é¡¹ã€‚\n",
    "        é¢˜ç›®ï¼š{ex['question']}\n",
    "        é€‰é¡¹ï¼š\n",
    "        A. {ex['A']}\n",
    "        B. {ex['B']}\n",
    "        C. {ex['C']}\n",
    "        D. {ex['D']}\n",
    "        ç­”æ¡ˆæ˜¯ï¼š\"\"\"\n",
    "        prompt = f\"\"\"è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\n",
    "        \n",
    "        é¢˜ç›®ï¼š\n",
    "        {ex['question']}\n",
    "        \n",
    "        é€‰é¡¹ï¼š\n",
    "        A. {ex['A']}\n",
    "        B. {ex['B']}\n",
    "        C. {ex['C']}\n",
    "        D. {ex['D']}\n",
    "        \n",
    "        ç­”æ¡ˆæ˜¯ï¼š\"\"\"\n",
    "\n",
    "        #         prompt = f\"\"\"è¯·é˜…è¯»ä»¥ä¸‹å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶ä»å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºä¸€ä¸ªæœ€åˆé€‚çš„ç­”æ¡ˆã€‚\n",
    "        # \n",
    "        # é¢˜ç›®ï¼š\n",
    "        # {ex['question']}\n",
    "        # \n",
    "        # é€‰é¡¹ï¼š\n",
    "        # A. {ex['A']}\n",
    "        # B. {ex['B']}\n",
    "        # C. {ex['C']}\n",
    "        # D. {ex['D']}\n",
    "        # \n",
    "        # è¯·ç›´æ¥å›ç­”ï¼Œç­”æ¡ˆæ˜¯ï¼š\"\"\"\n",
    "\n",
    "        # === è·å– H_state ===\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs, output_hidden_states=True, return_dict=True)\n",
    "        H = outputs.hidden_states[-1]\n",
    "\n",
    "        # === è®­ç»ƒ deltaï¼ˆä¾‹å¦‚3æ­¥ï¼‰===\n",
    "        delta = train_delta_from_H(model, tokenizer, prompt, H, step=step, lr=lr)\n",
    "\n",
    "        # === æ¨ç†ä¸è¯„ä¼° ===\n",
    "        pred_txt, pre_answer, answer, is_correct = evaluate_slot_ceval_eos(model=model, tokenizer=tokenizer,\n",
    "                                                                           delta=delta,\n",
    "                                                                           example=ex, max_len=max_len, prompt=prompt,\n",
    "                                                                           verbose=False)\n",
    "        correct += int(is_correct)\n",
    "        total += 1\n",
    "        answer_sheet.append([prompt, pred_txt, pre_answer, answer, is_correct, dataset_name])\n",
    "    print(f\"ğŸ¯ {dataset_name} Accuracy (per-question delta): {correct}/{total} = {correct / total:.2%}\")\n",
    "    return answer_sheet"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "24d29f838758eb6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "model_path.split(\"/\")[-1]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b02b85fdbbff387",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ environmental_impact_assessment_engineer Accuracy (per-question delta): 23/31 = 74.19%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/31 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3071883e586a4208b782a95da1169aa3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ fire_engineer Accuracy (per-question delta): 14/31 = 45.16%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f5835d2230ef427d86ada63dee079136"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ high_school_biology Accuracy (per-question delta): 8/19 = 42.11%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0b4a46d299fa4812bf913490e2a43be1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ high_school_chemistry Accuracy (per-question delta): 9/19 = 47.37%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bec856be754e4a97816bdc26f2731d20"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ high_school_chinese Accuracy (per-question delta): 6/19 = 31.58%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3af7cf0d16824487a817c794132f9db6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ high_school_geography Accuracy (per-question delta): 10/19 = 52.63%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e39dd35a585c460fb5c7a18857f5cc08"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ high_school_history Accuracy (per-question delta): 17/20 = 85.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/18 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "40c94c13f06047ca8bb556a02f68e786"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ high_school_mathematics Accuracy (per-question delta): 6/18 = 33.33%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "62c352026a2741e0a9d5420b2c007aea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ high_school_physics Accuracy (per-question delta): 10/19 = 52.63%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ae946c108714021a71c83f751cf7433"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ high_school_politics Accuracy (per-question delta): 12/19 = 63.16%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d66fed1dd76645769208ca0702b19254"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ ideological_and_moral_cultivation Accuracy (per-question delta): 15/19 = 78.95%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4d011c601e094a43bbabb00a81937626"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ law Accuracy (per-question delta): 4/24 = 16.67%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ccb22eb5149947728f7bfbb766c61ff3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ legal_professional Accuracy (per-question delta): 8/23 = 34.78%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/22 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f43fb34336d84bf18c0e7ed4ed634f21"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ logic Accuracy (per-question delta): 13/22 = 59.09%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "92e97aaa5d1a4def96fa89d03d58efd7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ mao_zedong_thought Accuracy (per-question delta): 17/24 = 70.83%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1df5acc7897c4b86865bedf98e9eee71"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ marxism Accuracy (per-question delta): 12/19 = 63.16%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b90e93e0743c4ae6b110c9098077c3b4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ metrology_engineer Accuracy (per-question delta): 16/24 = 66.67%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/21 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "321c1c7002e34b4d9fafc78f813a638a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ middle_school_biology Accuracy (per-question delta): 14/21 = 66.67%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f8203e42cc3047059fe30bda0de60222"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ middle_school_chemistry Accuracy (per-question delta): 13/20 = 65.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/12 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5ad0b8c3e3f34bf7804af9ebb279ab45"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ middle_school_geography Accuracy (per-question delta): 9/12 = 75.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/22 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1e3631297b3f488c93abd78399ccf600"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ middle_school_history Accuracy (per-question delta): 13/22 = 59.09%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "62b610a90d994d7a80f83c674d7d5826"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ middle_school_mathematics Accuracy (per-question delta): 6/19 = 31.58%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aee15151428346f39812232f357af60b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ middle_school_physics Accuracy (per-question delta): 10/19 = 52.63%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/21 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8ac06fef50294c4fa3c0c4337039ffac"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ middle_school_politics Accuracy (per-question delta): 14/21 = 66.67%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a8a01132e1b74c0e9ba6420a59a1e51c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ modern_chinese_history Accuracy (per-question delta): 11/23 = 47.83%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7c93a9ba846040759bf5178cafb42299"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ operating_system Accuracy (per-question delta): 10/19 = 52.63%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/49 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c4d4a884c50a4fcc9b748fd808a9c0e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ physician Accuracy (per-question delta): 23/49 = 46.94%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/22 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "538f4c1225654c7a8d75208aedcb542f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ plant_protection Accuracy (per-question delta): 12/22 = 54.55%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/18 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e511c75529934d6c91a655e633b1c55a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ probability_and_statistics Accuracy (per-question delta): 5/18 = 27.78%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/29 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b15d5674115c4e5ebcf2805d26167235"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ professional_tour_guide Accuracy (per-question delta): 15/29 = 51.72%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4651e4bee7494a7786de471254a75536"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ sports_science Accuracy (per-question delta): 7/19 = 36.84%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/49 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b8e193bae22649d7818852807c9a3dad"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ tax_accountant Accuracy (per-question delta): 24/49 = 48.98%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/44 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "37fa4e9624424fc9b2f3910555186b7e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ teacher_qualification Accuracy (per-question delta): 29/44 = 65.91%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/46 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "929962c65917471788589167689625dc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ urban_and_rural_planner Accuracy (per-question delta): 31/46 = 67.39%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "37cae68caa4d489ba7d84740a78c6b95"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ veterinary_medicine Accuracy (per-question delta): 11/23 = 47.83%\n"
     ]
    },
    {
     "data": {
      "text/plain": "                                                      0                1  2  \\\n0     è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...     D\\n        ï¿½  D   \n1     è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...             C. ç´§  C   \n2     è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...            D. åˆåŒ  D   \n3     è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...            B. 30  B   \n4     è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...    C\\n        è§£æ  C   \n...                                                 ...              ... ..   \n1341  è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...            A. å°¿ç´   A   \n1342  è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...    D\\n        è§£æ  D   \n1343  è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...           A. ç»“æ„åŸŸ  A   \n1344  è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...            B. ç›¸åº”  B   \n1345  è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...  A. DNA\\n         A   \n\n      3      4                    5  \n0     D   True           accountant  \n1     C   True           accountant  \n2     D   True           accountant  \n3     A  False           accountant  \n4     C   True           accountant  \n...  ..    ...                  ...  \n1341  A   True  veterinary_medicine  \n1342  D   True  veterinary_medicine  \n1343  A   True  veterinary_medicine  \n1344  C  False  veterinary_medicine  \n1345  C  False  veterinary_medicine  \n\n[1346 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...</td>\n      <td>D\\n        ï¿½</td>\n      <td>D</td>\n      <td>D</td>\n      <td>True</td>\n      <td>accountant</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...</td>\n      <td>C. ç´§</td>\n      <td>C</td>\n      <td>C</td>\n      <td>True</td>\n      <td>accountant</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...</td>\n      <td>D. åˆåŒ</td>\n      <td>D</td>\n      <td>D</td>\n      <td>True</td>\n      <td>accountant</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...</td>\n      <td>B. 30</td>\n      <td>B</td>\n      <td>A</td>\n      <td>False</td>\n      <td>accountant</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...</td>\n      <td>C\\n        è§£æ</td>\n      <td>C</td>\n      <td>C</td>\n      <td>True</td>\n      <td>accountant</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1341</th>\n      <td>è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...</td>\n      <td>A. å°¿ç´ </td>\n      <td>A</td>\n      <td>A</td>\n      <td>True</td>\n      <td>veterinary_medicine</td>\n    </tr>\n    <tr>\n      <th>1342</th>\n      <td>è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...</td>\n      <td>D\\n        è§£æ</td>\n      <td>D</td>\n      <td>D</td>\n      <td>True</td>\n      <td>veterinary_medicine</td>\n    </tr>\n    <tr>\n      <th>1343</th>\n      <td>è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...</td>\n      <td>A. ç»“æ„åŸŸ</td>\n      <td>A</td>\n      <td>A</td>\n      <td>True</td>\n      <td>veterinary_medicine</td>\n    </tr>\n    <tr>\n      <th>1344</th>\n      <td>è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...</td>\n      <td>B. ç›¸åº”</td>\n      <td>B</td>\n      <td>C</td>\n      <td>False</td>\n      <td>veterinary_medicine</td>\n    </tr>\n    <tr>\n      <th>1345</th>\n      <td>è¯·ä½ æ‰®æ¼”ä¸€ä½ä¸“ä¸šçš„è€ƒè¯•åŠ©æ‰‹ï¼Œé˜…è¯»ä¸‹é¢çš„å•é¡¹é€‰æ‹©é¢˜ï¼Œå¹¶æ ¹æ®å†…å®¹åœ¨å››ä¸ªé€‰é¡¹ä¸­é€‰å‡ºæœ€åˆé€‚çš„ä¸€ä¸ªã€‚\\...</td>\n      <td>A. DNA\\n</td>\n      <td>A</td>\n      <td>C</td>\n      <td>False</td>\n      <td>veterinary_medicine</td>\n    </tr>\n  </tbody>\n</table>\n<p>1346 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for step in [12, 15, 18]:\n",
    "    max_len = 5\n",
    "    answer_sheet = []\n",
    "    for dataset_name in tqdm(dataset_names[:]):\n",
    "        answer_sheet += eval_dataset(dataset_name=dataset_name, step=step, max_len=max_len, lr=1e-2)\n",
    "        df_answer = pd.DataFrame(answer_sheet)\n",
    "        df_answer.to_csv(f\"./eval_result/0_6B/answer_step_{step}.csv\", index=False)\n",
    "pd.DataFrame(answer_sheet)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7fa44f85f90e6fd5",
   "execution_count": 90
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for step in [3, 0, 6, 9]:\n",
    "    max_len = 5\n",
    "    answer_sheet = []\n",
    "    for dataset_name in tqdm(dataset_names[:]):\n",
    "        answer_sheet += eval_dataset(dataset_name=dataset_name, step=step, max_len=max_len, lr=1e-2)\n",
    "        df_answer = pd.DataFrame(answer_sheet)\n",
    "        df_answer.to_csv(f\"./eval_result/0_6B/answer_step_{step}.csv\", index=False)\n",
    "pd.DataFrame(answer_sheet)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "387be86860d8f430",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for step in [3, 0, 6, 9]:\n",
    "    max_len = 5\n",
    "    answer_sheet = []\n",
    "    for dataset_name in tqdm(dataset_names[:]):\n",
    "        answer_sheet += eval_dataset(dataset_name=dataset_name, step=step, max_len=max_len, lr=1e-2)\n",
    "        df_answer = pd.DataFrame(answer_sheet)\n",
    "        df_answer.to_csv(f\"./eval_result/1_7B/answer_step_{step}.csv\", index=False)\n",
    "pd.DataFrame(answer_sheet)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d1a41f8865f96fe",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for step in [15]:\n",
    "    max_len = 5\n",
    "    answer_sheet = []\n",
    "    for dataset_name in tqdm(dataset_names[:]):\n",
    "        answer_sheet += eval_dataset(dataset_name=dataset_name, step=step, max_len=max_len, lr=1e-2)\n",
    "        df_answer = pd.DataFrame(answer_sheet)\n",
    "        df_answer.to_csv(f\"./eval_result/1_7B/answer_step_{step}.csv\", index=False)\n",
    "pd.DataFrame(answer_sheet)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36b7dc42d77e04e1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for step in [3, 0, 6, 12]:\n",
    "    max_len = 30\n",
    "    answer_sheet = []\n",
    "    for i in tqdm(dataset_names[:]):\n",
    "        answer_sheet += eval_dataset(i, step=step, max_len=max_len, lr=1e-3)\n",
    "        df_answer = pd.DataFrame(answer_sheet)\n",
    "        df_answer.to_csv(f\"./eval_result/1_7B/answer_step_{step}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39220cfac51cfcc2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for step in [3]:\n",
    "    max_len = 50\n",
    "    answer_sheet = []\n",
    "    for i in tqdm(dataset_names[8]):\n",
    "        answer_sheet += eval_dataset(i, step=step, max_len=max_len, lr=1e-3)\n",
    "        df_answer = pd.DataFrame(answer_sheet)\n",
    "        df_answer.to_csv(f\"./eval_result/1_7B/answer_step_{step}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cbde9d64a1dae016",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pd.DataFrame(answer_sheet)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3ab4f334f4c6030",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
