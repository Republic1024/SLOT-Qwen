{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3d0216445bd77a79"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import numpy as np\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from pylab import mpl, plt\n",
    "import matplotlib.patches as mpatches\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# best font and style settings for notebook \n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style(\"white\")\n",
    "mpl.rcParams['font.family'] = 'MiSans'\n",
    "\n",
    "model_path = r\"D:\\pythonProject\\DeepSeek\\Recsys\\AnimeLLMRec\\Qwen3-0.6B\"  # modify to your Qwen Path\n",
    "model_path = r\"./Qwen3-1.7B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c40a0c8ce972a1a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from delta_trainer import train_delta_from_H, generate_by_H, evaluate_slot_ceval, evaluate_slot_ceval_eos, \\\n",
    "    evaluate_slot_ceval_eos_2\n",
    "\n",
    "# 构造 prompt & 得到 H_state\n",
    "prompt = \"请写一段关于AI教育的引言。\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs, output_hidden_states=True, return_dict=True)\n",
    "H = outputs.hidden_states[-1]\n",
    "\n",
    "# 调用 delta 训练\n",
    "delta_3 = train_delta_from_H(model, tokenizer, prompt, H, step=3)\n",
    "delta_10 = train_delta_from_H(model, tokenizer, prompt, H, step=10)\n",
    "delta_30 = train_delta_from_H(model, tokenizer, prompt, H, step=30)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc16caa5c81a8ab2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# generate_by_H(model=model, prompt=prompt, tokenizer=tokenizer, delta=delta_3, answer_len=200)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d86f37fe68c63257",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from datasets import get_dataset_config_names\n",
    "\n",
    "# 获取本地路径 \"./ceval-exam\" 中可用的所有子数据集名称（config names）\n",
    "dataset_path = \"./ceval-exam\"\n",
    "dataset_names = get_dataset_config_names(path=dataset_path)\n",
    "dataset_names"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c9ac52d60c83894",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(r\"./ceval-exam\", name=\"computer_network\")\n",
    "print(dataset['val'][0])"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def evaluate_slot_ceval_eos(model, tokenizer, delta, example, max_len=20, verbose=True):\n",
    "    \"\"\"\n",
    "    基于 generate_by_H_eos 的评估函数，用于 C-Eval 单选题目。\n",
    "\n",
    "    返回：\n",
    "    - predict_option: 预测选项，如 'A'\n",
    "    - is_correct: 是否预测正确\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"以下是一道单项选择题，请你阅读题目并选择最合适的选项。\n",
    "\n",
    "题目：{example['question']}\n",
    "\n",
    "选项：\n",
    "A. {example['A']}\n",
    "B. {example['B']}\n",
    "C. {example['C']}\n",
    "D. {example['D']}\n",
    "\n",
    "答案是：\"\"\"\n",
    "\n",
    "    output_text = generate_by_H_eos(model, prompt, tokenizer, delta, answer_len=max_len)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"🔍 模型生成结果:\\n\", output_text)\n",
    "\n",
    "    predict_option = None\n",
    "    for option in ['A', 'B', 'C', 'D']:\n",
    "        if option in output_text:\n",
    "            predict_option = option\n",
    "            break\n",
    "\n",
    "    is_correct = (predict_option == example['answer'])\n",
    "    # return predict_option, is_correct\n",
    "    return output_text, predict_option, example['answer'], is_correct"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "154970daa54d317c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# dataset_name = \"computer_network\"\n",
    "# dataset = load_dataset(r\"./ceval-exam\", name=dataset_name)\n",
    "# \n",
    "# correct = 0\n",
    "# total = 0\n",
    "# \n",
    "# answer_sheet = []\n",
    "# for ex in tqdm(dataset['val'], desc=\"Evaluating per-question delta\"):\n",
    "#     # === 构造每道题的 Prompt ===\n",
    "#     prompt = f\"\"\"以下是一道单项选择题，请你阅读题目，结合题目的知识背景，选择最合适的选项。\n",
    "#     题目：{ex['question']}\n",
    "#     \n",
    "#     选项：\n",
    "#     A. {ex['A']}\n",
    "#     B. {ex['B']}\n",
    "#     C. {ex['C']}\n",
    "#     D. {ex['D']}\n",
    "#     \n",
    "#     答案是：\"\"\"\n",
    "# \n",
    "#     # === 获取 H_state ===\n",
    "#     inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(**inputs, output_hidden_states=True, return_dict=True)\n",
    "#     H = outputs.hidden_states[-1]\n",
    "# \n",
    "#     # === 训练 delta（例如3步）===\n",
    "#     delta = train_delta_from_H(model, tokenizer, prompt, H, step=30)\n",
    "# \n",
    "#     # === 推理与评估 ===\n",
    "#     pred, pre_answer, answer, is_correct = evaluate_slot_ceval_eos(model, tokenizer, delta, ex, max_len=20,\n",
    "#                                                                    verbose=False)\n",
    "#     correct += int(is_correct)\n",
    "#     total += 1\n",
    "#     answer_sheet.append([pred, pre_answer, answer, is_correct, dataset_name])\n",
    "# print(f\"🎯 Accuracy (per-question delta): {correct}/{total} = {correct / total:.2%}\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "52ec9dd491c117a1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def evaluate_slot_ceval_eos(model, tokenizer, delta, example, prompt, max_len=20, verbose=True):\n",
    "    \"\"\"\n",
    "    基于 generate_by_H_eos 的评估函数，用于 C-Eval 单选题目。\n",
    "\n",
    "    返回：\n",
    "    - predict_option: 预测选项，如 'A'\n",
    "    - is_correct: 是否预测正确\n",
    "    # \"\"\"\n",
    "\n",
    "    output_text = generate_by_H_eos(model, prompt, tokenizer, delta, answer_len=max_len)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"🔍 模型生成结果:\\n\", output_text)\n",
    "\n",
    "    predict_option = None\n",
    "    for option in ['A', 'B', 'C', 'D']:\n",
    "        if option in output_text:\n",
    "            predict_option = option\n",
    "            break\n",
    "\n",
    "    is_correct = (predict_option == example['answer'])\n",
    "    # return predict_option, is_correct\n",
    "    return output_text, predict_option, example['answer'], is_correct\n",
    "\n",
    "\n",
    "def eval_dataset(dataset_name, step=3, max_len=50, lr=1e-2):\n",
    "    # dataset_name = \"computer_network\"\n",
    "    dataset = load_dataset(r\"./ceval-exam\", name=dataset_name)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    answer_sheet = []\n",
    "    for ex in tqdm(dataset['val']):\n",
    "        # === 构造每道题的 Prompt ===\n",
    "        prompt = f\"\"\"以下是一道单项选择题，请你阅读题目，选择最合适的选项。\n",
    "        题目：{ex['question']}\n",
    "        选项：\n",
    "        A. {ex['A']}\n",
    "        B. {ex['B']}\n",
    "        C. {ex['C']}\n",
    "        D. {ex['D']}\n",
    "        答案是：\"\"\"\n",
    "        prompt = f\"\"\"请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\n",
    "        \n",
    "        题目：\n",
    "        {ex['question']}\n",
    "        \n",
    "        选项：\n",
    "        A. {ex['A']}\n",
    "        B. {ex['B']}\n",
    "        C. {ex['C']}\n",
    "        D. {ex['D']}\n",
    "        \n",
    "        答案是：\"\"\"\n",
    "\n",
    "        # === 获取 H_state ===\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs, output_hidden_states=True, return_dict=True)\n",
    "        H = outputs.hidden_states[-1]\n",
    "\n",
    "        # === 训练 delta（例如3步）===\n",
    "        delta = train_delta_from_H(model, tokenizer, prompt, H, step=step, lr=lr)\n",
    "\n",
    "        # === 推理与评估 ===\n",
    "        pred_txt, pre_answer, answer, is_correct = evaluate_slot_ceval_eos(model=model, tokenizer=tokenizer,\n",
    "                                                                           delta=delta,\n",
    "                                                                           example=ex, max_len=max_len, prompt=prompt,\n",
    "                                                                           verbose=False)\n",
    "        correct += int(is_correct)\n",
    "        total += 1\n",
    "        answer_sheet.append([prompt, pred_txt, pre_answer, answer, is_correct, dataset_name])\n",
    "    print(f\"🎯 {dataset_name} Accuracy (per-question delta): {correct}/{total} = {correct / total:.2%}\")\n",
    "    return answer_sheet"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-06T13:21:42.209962700Z",
     "start_time": "2025-06-06T13:21:42.197964300Z"
    }
   },
   "id": "24d29f838758eb6",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from delta_trainer import generate_by_H_eos"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d14006ad9fb5ee14",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "len(dataset_names)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d1a41f8865f96fe",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/52 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "80b4ab9fafce48cea7685a147f54b56d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/49 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1a6b10d91896459db0d6ba4e066695c0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 accountant Accuracy (per-question delta): 26/49 = 53.06%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8dde0667248f4f049bf9bf82710bf061"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 advanced_mathematics Accuracy (per-question delta): 7/19 = 36.84%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/33 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f72a630c1984f649f1ee862b74ad39d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 art_studies Accuracy (per-question delta): 20/33 = 60.61%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "08628e08386d4ba8856619d744305c6a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 basic_medicine Accuracy (per-question delta): 14/19 = 73.68%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/33 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b8be30dd470e4815bef32eddb13baf24"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 business_administration Accuracy (per-question delta): 18/33 = 54.55%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bca3440fb96549e2aa5a663070056b43"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 chinese_language_and_literature Accuracy (per-question delta): 14/23 = 60.87%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/47 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b2b286440291467283f10490b6f19184"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 civil_servant Accuracy (per-question delta): 25/47 = 53.19%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/22 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1b1b9a35b1e84e52b49150faa0af61f8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 clinical_medicine Accuracy (per-question delta): 11/22 = 50.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c6ab10f4e9f247188644c878c3b4ac7e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 college_chemistry Accuracy (per-question delta): 12/24 = 50.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/55 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0eddb24613b0401bbe9b77ec9ec7b469"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 college_economics Accuracy (per-question delta): 23/55 = 41.82%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aaa6fb0435504e2e9bde8226e3186065"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 college_physics Accuracy (per-question delta): 8/19 = 42.11%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "62ec71fde95346bab60eed18c443c692"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 college_programming Accuracy (per-question delta): 26/37 = 70.27%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/21 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c9649c2b9e1f40e9ac184ee7221739b4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 computer_architecture Accuracy (per-question delta): 13/21 = 61.90%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e9603baa0c3f43e8b68750a1649785a3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 computer_network Accuracy (per-question delta): 10/19 = 52.63%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/16 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5d76c90e1c444956b9f11e40ef726587"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 discrete_mathematics Accuracy (per-question delta): 4/16 = 25.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/29 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "355abbaf03d7440b9e01534a28718841"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 education_science Accuracy (per-question delta): 21/29 = 72.41%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9348fe6db9d43ed8cef0387c7c40556"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 electrical_engineer Accuracy (per-question delta): 15/37 = 40.54%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/31 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d7bc16a9c71542e59619ffc9f9434304"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 environmental_impact_assessment_engineer Accuracy (per-question delta): 21/31 = 67.74%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/31 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2786dd047a964ef9b43fe729f91b41d7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 fire_engineer Accuracy (per-question delta): 19/31 = 61.29%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a98de6da471e486aac18245857a4572f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 high_school_biology Accuracy (per-question delta): 9/19 = 47.37%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4333bc917f27447c908f1824d85856f9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 high_school_chemistry Accuracy (per-question delta): 11/19 = 57.89%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1d4c4c9111004e058024522e8bf4f269"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 high_school_chinese Accuracy (per-question delta): 8/19 = 42.11%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "869a3fc0b89e4291b02c3334b6339d18"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 high_school_geography Accuracy (per-question delta): 13/19 = 68.42%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6550e5c9cd304ff8b59b8ad04c2c9474"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 high_school_history Accuracy (per-question delta): 15/20 = 75.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/18 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "38ad5e6c9ddd4bec807001b26aeed421"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 high_school_mathematics Accuracy (per-question delta): 6/18 = 33.33%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "08f4d25bf89a46ce8bf98d7c5ddd940b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 high_school_physics Accuracy (per-question delta): 11/19 = 57.89%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "97e8a8e0f7134861b094ebc6469a80d0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 high_school_politics Accuracy (per-question delta): 13/19 = 68.42%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f77b20ef588e4bfbb8198f26d2734712"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 ideological_and_moral_cultivation Accuracy (per-question delta): 14/19 = 73.68%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2be6e6334a4c4e46a795804367c06803"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 law Accuracy (per-question delta): 11/24 = 45.83%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c73f0ed87bb549eb92f6a9fd0220945b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 legal_professional Accuracy (per-question delta): 9/23 = 39.13%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/22 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "efaeec2a3be84d229fc8b8513633757c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 logic Accuracy (per-question delta): 12/22 = 54.55%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2d4b2fa4af4e48bdb899400ed5b30d45"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 mao_zedong_thought Accuracy (per-question delta): 20/24 = 83.33%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5b32c745929444bda81596bed2a48ac6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 marxism Accuracy (per-question delta): 14/19 = 73.68%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c7060aee2bb3451aa440798b15041c54"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 metrology_engineer Accuracy (per-question delta): 17/24 = 70.83%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/21 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1179141c97954c48bd2e3c109fd6c087"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 middle_school_biology Accuracy (per-question delta): 19/21 = 90.48%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5a13dff15cb442d880d3ccdf001c72ee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 middle_school_chemistry Accuracy (per-question delta): 19/20 = 95.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/12 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "67877796a00447e2907a5fa100935e68"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 middle_school_geography Accuracy (per-question delta): 7/12 = 58.33%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/22 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6a2f972c3e6346aca22140d000688247"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 middle_school_history Accuracy (per-question delta): 16/22 = 72.73%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5328cfdea2654a0882f8f3699f337961"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 middle_school_mathematics Accuracy (per-question delta): 7/19 = 36.84%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "348c783d512a4fa9a426c4cfbcc44a42"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 middle_school_physics Accuracy (per-question delta): 17/19 = 89.47%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/21 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c026a5fe000a42559ed6e0a706fe257c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 middle_school_politics Accuracy (per-question delta): 17/21 = 80.95%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3324bce03aff4fa184f2001e2e1c2bad"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 modern_chinese_history Accuracy (per-question delta): 13/23 = 56.52%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3dfddfa043184ba5a547782cab6e868a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 operating_system Accuracy (per-question delta): 8/19 = 42.11%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/49 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "936cee99582945f5a0c778595ab75338"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 physician Accuracy (per-question delta): 27/49 = 55.10%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/22 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7823744a593a47c3b6c358f903e8f1e1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 plant_protection Accuracy (per-question delta): 15/22 = 68.18%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/18 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3be933be191747ceb985d12e3dc1a8f1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 probability_and_statistics Accuracy (per-question delta): 3/18 = 16.67%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/29 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "79b3d07b8a8a4a05a90fc00635fda2cd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 professional_tour_guide Accuracy (per-question delta): 13/29 = 44.83%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8a5e8866c8e347688570a0ebf796d92a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 sports_science Accuracy (per-question delta): 11/19 = 57.89%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/49 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d80044af24f243759496b8e5ebad0c1d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 tax_accountant Accuracy (per-question delta): 23/49 = 46.94%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/44 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "46d26477489d433581a157a4630dc14c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 teacher_qualification Accuracy (per-question delta): 36/44 = 81.82%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/46 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3da79417ccd347678396313ba0c76a5c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 urban_and_rural_planner Accuracy (per-question delta): 34/46 = 73.91%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ce61e7bd1b3d40a9ba1b3220aa87dcff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 veterinary_medicine Accuracy (per-question delta): 13/23 = 56.52%\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "max_len = 10\n",
    "answer_sheet = []\n",
    "for i in tqdm(dataset_names[:]):\n",
    "    answer_sheet += eval_dataset(i, step=step, max_len=max_len)\n",
    "    df_answer = pd.DataFrame(answer_sheet)\n",
    "    df_answer.to_csv(f\"./eval_result/1_7B/answer_step_{step}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-06T13:51:24.388590300Z",
     "start_time": "2025-06-06T13:44:12.289566200Z"
    }
   },
   "id": "e9d54146fa6f8b72",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "step = 6\n",
    "max_len = 10\n",
    "answer_sheet = []\n",
    "for i in tqdm(dataset_names[:]):\n",
    "    answer_sheet += eval_dataset(i, step=step, max_len=max_len)\n",
    "    df_answer = pd.DataFrame(answer_sheet)\n",
    "    df_answer.to_csv(f\"./eval_result/1_7B/answer_step_{step}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "df52e87dc781b8b1"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/52 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "745566667825415f979057fe12b1cb28"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/49 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "118ecd6b1f134c96a5ee88ef27725f95"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 accountant Accuracy (per-question delta): 25/49 = 51.02%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "35083a997f814333aeeeb09da9eed637"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 advanced_mathematics Accuracy (per-question delta): 8/19 = 42.11%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/33 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "438067f3638147f2856ed785ef48c0ce"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 art_studies Accuracy (per-question delta): 21/33 = 63.64%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8c3f0f37454e4647a8df103c5575464c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 basic_medicine Accuracy (per-question delta): 14/19 = 73.68%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/33 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "28ae037a0dda4af7b18dbd07fc2de807"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 business_administration Accuracy (per-question delta): 20/33 = 60.61%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c7dda84ebc9348ca8a6063e1b39da43d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 chinese_language_and_literature Accuracy (per-question delta): 14/23 = 60.87%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/47 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d65d539c20b4465ca06b3fd96567a8fb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 civil_servant Accuracy (per-question delta): 26/47 = 55.32%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/22 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "60ba6871b96f454899c74f004aa68fbf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 clinical_medicine Accuracy (per-question delta): 10/22 = 45.45%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1cd53c7596ce4920bd4742347ceab6d0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 college_chemistry Accuracy (per-question delta): 12/24 = 50.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/55 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "985cbce967564d2a8127ee8432a25529"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 college_economics Accuracy (per-question delta): 25/55 = 45.45%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "72f2d2dff31c423dbfed6fa46a6a8658"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 college_physics Accuracy (per-question delta): 8/19 = 42.11%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "954666cf9ab042958d2be2c4a1b7a084"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 college_programming Accuracy (per-question delta): 26/37 = 70.27%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/21 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8f21d4a21a5e4a129ef46aa29f2477ff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 computer_architecture Accuracy (per-question delta): 11/21 = 52.38%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "51fcdf5ebddb47ae80aedfb81fd42f37"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 computer_network Accuracy (per-question delta): 10/19 = 52.63%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/16 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a5a8ec957b244a42b8db9e227511357a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 discrete_mathematics Accuracy (per-question delta): 4/16 = 25.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/29 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "440be5f2f92b4d58a2ea165faa19acd0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 education_science Accuracy (per-question delta): 20/29 = 68.97%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bbecc6751c94485c92ae5fea5da3d395"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 electrical_engineer Accuracy (per-question delta): 18/37 = 48.65%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/31 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "218b6b3385144d3e82e78d4679e8c069"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 environmental_impact_assessment_engineer Accuracy (per-question delta): 21/31 = 67.74%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/31 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0f9cab47c0e04f98a0ae10be20ccd130"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 fire_engineer Accuracy (per-question delta): 18/31 = 58.06%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "50398906bda544778fdcfdda40587591"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 high_school_biology Accuracy (per-question delta): 8/19 = 42.11%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "758a0e4872804dad860c46cfd7ac6a1d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 high_school_chemistry Accuracy (per-question delta): 9/19 = 47.37%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "283dda39ff88486cb749af498770fab3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 high_school_chinese Accuracy (per-question delta): 9/19 = 47.37%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2d976ee3ac034179881db30d2662e634"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 high_school_geography Accuracy (per-question delta): 12/19 = 63.16%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "82e79c466d5440fe8aceaaeee7101d69"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 high_school_history Accuracy (per-question delta): 15/20 = 75.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/18 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a893f9b8b99d484981ea52bf834043da"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 high_school_mathematics Accuracy (per-question delta): 5/18 = 27.78%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3ece6e84bd834d1fa2350abdf89b37f4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 high_school_physics Accuracy (per-question delta): 11/19 = 57.89%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8381883fd0744b2ca52edec6804e7353"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 high_school_politics Accuracy (per-question delta): 14/19 = 73.68%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "43fb62681fb34cff92c660f938dc29e4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 ideological_and_moral_cultivation Accuracy (per-question delta): 13/19 = 68.42%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e571f81ca244e9b90daf51d4720773b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 law Accuracy (per-question delta): 10/24 = 41.67%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "796144d869e7452c917b8caca172aa6f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 legal_professional Accuracy (per-question delta): 9/23 = 39.13%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/22 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "120c89e419ac4ef6b250f7a5159259e0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 logic Accuracy (per-question delta): 12/22 = 54.55%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4ebaeff211204f2eaf76b18f61447468"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 mao_zedong_thought Accuracy (per-question delta): 20/24 = 83.33%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a6162f0e2e7c4704aec123ae2d9a4cf0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 marxism Accuracy (per-question delta): 14/19 = 73.68%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e67c6c6172ae4bc49946d4e71dbbf9c3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 metrology_engineer Accuracy (per-question delta): 18/24 = 75.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/21 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b1f780f2637a455ead44623a9a009dbc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 middle_school_biology Accuracy (per-question delta): 18/21 = 85.71%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ab811c05ddea45b7856c0a5030e23316"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 middle_school_chemistry Accuracy (per-question delta): 19/20 = 95.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/12 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5d5a1504e08b4818a84857c3f0d41234"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 middle_school_geography Accuracy (per-question delta): 7/12 = 58.33%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/22 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a90c1a05592245b4a4f4612496f5f3c0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 middle_school_history Accuracy (per-question delta): 16/22 = 72.73%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "89d64f9490a745118cc7d00d82fa9707"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 middle_school_mathematics Accuracy (per-question delta): 6/19 = 31.58%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f88192b0727c472a92a06cbe6aac2ee3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 middle_school_physics Accuracy (per-question delta): 17/19 = 89.47%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/21 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bbeb8ce2cee84a4a9c3fa86351c5268c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 middle_school_politics Accuracy (per-question delta): 17/21 = 80.95%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "463b68a6295c44edafa29d95668e32aa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 modern_chinese_history Accuracy (per-question delta): 12/23 = 52.17%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "66bdf505f24c421fbe680059f1bb5231"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 operating_system Accuracy (per-question delta): 8/19 = 42.11%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/49 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2e7cf15eaab7467b944b72f427800dfe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 physician Accuracy (per-question delta): 29/49 = 59.18%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/22 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f9e4443f858c403ba9cd757e9bf6cee3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 plant_protection Accuracy (per-question delta): 15/22 = 68.18%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/18 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fbf78a3f074243d484a7442ab251b40a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "step = 18\n",
    "max_len = 10\n",
    "answer_sheet = []\n",
    "for i in tqdm(dataset_names[:]):\n",
    "    answer_sheet += eval_dataset(i, step=step, max_len=max_len)\n",
    "    df_answer = pd.DataFrame(answer_sheet)\n",
    "    df_answer.to_csv(f\"./eval_result/1_7B/answer_step_{step}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2025-06-06T13:51:24.392591500Z"
    }
   },
   "id": "10b0fd9712e7c3ce",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "step = 15\n",
    "max_len = 10\n",
    "answer_sheet = []\n",
    "for i in tqdm(dataset_names[:]):\n",
    "    answer_sheet += eval_dataset(i, step=step, max_len=max_len)\n",
    "    df_answer = pd.DataFrame(answer_sheet)\n",
    "    df_answer.to_csv(f\"./eval_result/1_7B/answer_step_{step}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-06-06T13:44:05.699399800Z"
    }
   },
   "id": "2e13c7e51d907d39",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/52 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e5d16ef055834e01bc4075ed16a5fb79"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/49 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "58bc89f731674b6f91fa6d5a661978d5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 accountant Accuracy (per-question delta): 25/49 = 51.02%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "40d291dfdb044c94800a079b18b9e770"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 advanced_mathematics Accuracy (per-question delta): 7/19 = 36.84%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/33 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f2026fd191334e7e8d9274df09ff9c80"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 art_studies Accuracy (per-question delta): 21/33 = 63.64%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6a59419f757b4599b896f5ded3c94cfe"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 basic_medicine Accuracy (per-question delta): 13/19 = 68.42%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/33 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c3bbc39eb0654e18894e6961316ff77f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 business_administration Accuracy (per-question delta): 20/33 = 60.61%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b7d34c332f044963a3db109c0190af24"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 chinese_language_and_literature Accuracy (per-question delta): 14/23 = 60.87%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/47 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3bf833ead8ab492787b8b74a1f079d79"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 civil_servant Accuracy (per-question delta): 25/47 = 53.19%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/22 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6f312a90189542448b649640f2c0fcad"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 clinical_medicine Accuracy (per-question delta): 10/22 = 45.45%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a89a083710d14e048b07abbd26efb1e4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 college_chemistry Accuracy (per-question delta): 12/24 = 50.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/55 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "674793e5d7ff4a96a872f07fe80b346f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 college_economics Accuracy (per-question delta): 26/55 = 47.27%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7b97a05568194da9b47d0ee3450c8832"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 college_physics Accuracy (per-question delta): 9/19 = 47.37%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "427354f26dfa4d05aa99ba826013b4fd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 college_programming Accuracy (per-question delta): 25/37 = 67.57%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/21 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c2566e79df0e47f8926747840993caa4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 computer_architecture Accuracy (per-question delta): 13/21 = 61.90%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6a45379613844c15abd57209d54c73f3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 computer_network Accuracy (per-question delta): 10/19 = 52.63%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/16 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "45f9713ccd104715b0502444732bde15"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 discrete_mathematics Accuracy (per-question delta): 4/16 = 25.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/29 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c7fa3d921336492ebc8eb114516cdcd9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 education_science Accuracy (per-question delta): 21/29 = 72.41%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/37 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b8f022c46e774840b1d96550bec06a0b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 electrical_engineer Accuracy (per-question delta): 17/37 = 45.95%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/31 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "697cf328337d4d77b0498f6475793771"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 environmental_impact_assessment_engineer Accuracy (per-question delta): 21/31 = 67.74%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/31 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "80ab04e15f4942829b2dab69dc34ab41"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 fire_engineer Accuracy (per-question delta): 18/31 = 58.06%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a50f8d8ea24c4b84b63f53bc1fceaa29"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 high_school_biology Accuracy (per-question delta): 8/19 = 42.11%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "300258aed0a948209b182244ee1bd563"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 high_school_chemistry Accuracy (per-question delta): 10/19 = 52.63%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aaff62d5485a4b8f9b18468bea93b961"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 high_school_chinese Accuracy (per-question delta): 9/19 = 47.37%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8206afcc7732453b8141b8e64b497696"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 high_school_geography Accuracy (per-question delta): 12/19 = 63.16%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "99f8cf5c38394cc9bc4b9ae22d6a2a71"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 high_school_history Accuracy (per-question delta): 15/20 = 75.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/18 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0d07768b05d44ab893ae5da41447e479"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 high_school_mathematics Accuracy (per-question delta): 5/18 = 27.78%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "01b40b4c6dc941db886c97a663ff050c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 high_school_physics Accuracy (per-question delta): 11/19 = 57.89%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2c1d8333ebcc4c5b80a50ae843a6a679"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 high_school_politics Accuracy (per-question delta): 14/19 = 73.68%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ca1ea442529a489eb8731d17f9c5bc92"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 ideological_and_moral_cultivation Accuracy (per-question delta): 14/19 = 73.68%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6222da9fc6e349e9953a49cb40db5102"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 law Accuracy (per-question delta): 10/24 = 41.67%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5b79388e5a184cb8872a3d9b65e45164"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 legal_professional Accuracy (per-question delta): 9/23 = 39.13%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/22 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fd99eb1651ce4d129ca7c7da0de2062b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 logic Accuracy (per-question delta): 12/22 = 54.55%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a768727ff338486799661b925b13e3eb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 mao_zedong_thought Accuracy (per-question delta): 20/24 = 83.33%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ea259e5ba0f4404822df12ffd106290"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 marxism Accuracy (per-question delta): 14/19 = 73.68%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/24 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "908da3b0288f4b32b77850087e208732"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 metrology_engineer Accuracy (per-question delta): 18/24 = 75.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/21 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "93dde18a330b4419b57c3376b0ffdce7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 middle_school_biology Accuracy (per-question delta): 18/21 = 85.71%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aff27ce5b9e74414bb1a0ad32a8bde0c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 middle_school_chemistry Accuracy (per-question delta): 19/20 = 95.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/12 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8439a95905fe45e68096204870099113"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 middle_school_geography Accuracy (per-question delta): 7/12 = 58.33%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/22 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "58c7b6347add4aa2a95926c204828683"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 middle_school_history Accuracy (per-question delta): 16/22 = 72.73%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3f7627ac3cd7494487f8b2279b650b68"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 middle_school_mathematics Accuracy (per-question delta): 7/19 = 36.84%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "14a609f4aecf444685538d770ec4f735"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 middle_school_physics Accuracy (per-question delta): 17/19 = 89.47%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/21 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3dde99736e5a4070b8f7202b6e2e2b4c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 middle_school_politics Accuracy (per-question delta): 17/21 = 80.95%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f2afe0ed8dad4d0f9efac9c27bf414f4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 modern_chinese_history Accuracy (per-question delta): 12/23 = 52.17%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1cc7e605b3344ca2b540a85d31cfb354"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 operating_system Accuracy (per-question delta): 8/19 = 42.11%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/49 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7100873738a1465a97d56fbcfb9a4aff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 physician Accuracy (per-question delta): 29/49 = 59.18%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/22 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5de597f8c24e46eca6bc71999a889b2b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 plant_protection Accuracy (per-question delta): 15/22 = 68.18%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/18 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "723c271253c24d6aab4cd6e21558de16"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 probability_and_statistics Accuracy (per-question delta): 5/18 = 27.78%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/29 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9c91e2e93e7942279f0f369450d4a11c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 professional_tour_guide Accuracy (per-question delta): 13/29 = 44.83%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/19 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6282addb6a9042409e4cb45ecf7586ba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 sports_science Accuracy (per-question delta): 9/19 = 47.37%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/49 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0d032a32e57543b6a093b145f9bacd53"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 tax_accountant Accuracy (per-question delta): 22/49 = 44.90%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/44 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c60c949c61f549c591c40b0b756c74ee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 teacher_qualification Accuracy (per-question delta): 36/44 = 81.82%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/46 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "73f2bffbfc1142fb81d78af1cf7130ee"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 urban_and_rural_planner Accuracy (per-question delta): 34/46 = 73.91%\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/23 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6858df31967547f7859c52d2342f8e33"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 veterinary_medicine Accuracy (per-question delta): 13/23 = 56.52%\n"
     ]
    }
   ],
   "source": [
    "step = 12\n",
    "max_len = 10\n",
    "answer_sheet = []\n",
    "for i in tqdm(dataset_names[:]):\n",
    "    answer_sheet += eval_dataset(i, step=step, max_len=max_len)\n",
    "    df_answer = pd.DataFrame(answer_sheet)\n",
    "    df_answer.to_csv(f\"./eval_result/1_7B/answer_step_{step}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-06T13:32:23.295162800Z",
     "start_time": "2025-06-06T13:22:03.956410600Z"
    }
   },
   "id": "ede00a5e75b4ae2c",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "step = 9\n",
    "max_len = 10\n",
    "answer_sheet = []\n",
    "for i in tqdm(dataset_names[:]):\n",
    "    answer_sheet += eval_dataset(i, step=step, max_len=max_len)\n",
    "    df_answer = pd.DataFrame(answer_sheet)\n",
    "    df_answer.to_csv(f\"./eval_result/1_7B/answer_step_{step}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b1d64dcbc199153",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                                      0  \\\n0     请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...   \n1     请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...   \n2     请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...   \n3     请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...   \n4     请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...   \n...                                                 ...   \n1341  请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...   \n1342  请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...   \n1343  请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...   \n1344  请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...   \n1345  请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...   \n\n                                         1  2  3      4                    5  \n0                      D\\n        你的回答应为：D  D  D   True           accountant  \n1     C\\n        请说明理由。\\n        \\n         C  C   True           accountant  \n2     D\\n        请说明理由。\\n        \\n         D  D   True           accountant  \n3             A\\n        请说明理由。\\n        �  A  A   True           accountant  \n4     C\\n        请说明理由。\\n        \\n         C  C   True           accountant  \n...                                    ... .. ..    ...                  ...  \n1341  A\\n        请说明理由。\\n        \\n         A  A   True  veterinary_medicine  \n1342                   D\\n        请说明理由： 本  D  D   True  veterinary_medicine  \n1343                   C\\n        请说明理由： 该  C  A  False  veterinary_medicine  \n1344  C\\n        请说明理由。\\n        \\n         C  C   True  veterinary_medicine  \n1345          C\\n        请说明理由：\\n        �  C  C   True  veterinary_medicine  \n\n[1346 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...</td>\n      <td>D\\n        你的回答应为：D</td>\n      <td>D</td>\n      <td>D</td>\n      <td>True</td>\n      <td>accountant</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...</td>\n      <td>C\\n        请说明理由。\\n        \\n</td>\n      <td>C</td>\n      <td>C</td>\n      <td>True</td>\n      <td>accountant</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...</td>\n      <td>D\\n        请说明理由。\\n        \\n</td>\n      <td>D</td>\n      <td>D</td>\n      <td>True</td>\n      <td>accountant</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...</td>\n      <td>A\\n        请说明理由。\\n        �</td>\n      <td>A</td>\n      <td>A</td>\n      <td>True</td>\n      <td>accountant</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...</td>\n      <td>C\\n        请说明理由。\\n        \\n</td>\n      <td>C</td>\n      <td>C</td>\n      <td>True</td>\n      <td>accountant</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1341</th>\n      <td>请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...</td>\n      <td>A\\n        请说明理由。\\n        \\n</td>\n      <td>A</td>\n      <td>A</td>\n      <td>True</td>\n      <td>veterinary_medicine</td>\n    </tr>\n    <tr>\n      <th>1342</th>\n      <td>请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...</td>\n      <td>D\\n        请说明理由： 本</td>\n      <td>D</td>\n      <td>D</td>\n      <td>True</td>\n      <td>veterinary_medicine</td>\n    </tr>\n    <tr>\n      <th>1343</th>\n      <td>请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...</td>\n      <td>C\\n        请说明理由： 该</td>\n      <td>C</td>\n      <td>A</td>\n      <td>False</td>\n      <td>veterinary_medicine</td>\n    </tr>\n    <tr>\n      <th>1344</th>\n      <td>请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...</td>\n      <td>C\\n        请说明理由。\\n        \\n</td>\n      <td>C</td>\n      <td>C</td>\n      <td>True</td>\n      <td>veterinary_medicine</td>\n    </tr>\n    <tr>\n      <th>1345</th>\n      <td>请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...</td>\n      <td>C\\n        请说明理由：\\n        �</td>\n      <td>C</td>\n      <td>C</td>\n      <td>True</td>\n      <td>veterinary_medicine</td>\n    </tr>\n  </tbody>\n</table>\n<p>1346 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(answer_sheet)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-06T13:20:37.352919200Z",
     "start_time": "2025-06-06T13:20:37.327921Z"
    }
   },
   "id": "e3ab4f334f4c6030",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "step = 6\n",
    "max_len = 10\n",
    "answer_sheet = []\n",
    "for i in tqdm(dataset_names[:]):\n",
    "    answer_sheet += eval_dataset(i, step=step, max_len=max_len)\n",
    "    df_answer = pd.DataFrame(answer_sheet)\n",
    "    df_answer.to_csv(f\"./eval_result/1_7B/answer_step_{step}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b893d03f381eabb2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "step = 3\n",
    "max_len = 10\n",
    "answer_sheet = []\n",
    "for i in tqdm(dataset_names[:]):\n",
    "    answer_sheet += eval_dataset(i, step=step, max_len=max_len)\n",
    "    df_answer = pd.DataFrame(answer_sheet)\n",
    "    df_answer.to_csv(f\"./eval_result/1_7B/answer_step_{step}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6f11cbd929207da",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "step = 0\n",
    "max_len = 10\n",
    "answer_sheet = []\n",
    "for i in tqdm(dataset_names[:]):\n",
    "    answer_sheet += eval_dataset(i, step=step, max_len=max_len)\n",
    "    df_answer = pd.DataFrame(answer_sheet)\n",
    "    df_answer.to_csv(f\"./eval_result/1_7B/answer_step_{step}.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "723b68c8959da502",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                                      0  \\\n0     请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...   \n1     请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...   \n2     请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...   \n3     请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...   \n4     请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...   \n...                                                 ...   \n1341  请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...   \n1342  请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...   \n1343  请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...   \n1344  请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...   \n1345  请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...   \n\n                                         1  2  3      4                    5  \n0                      D\\n        你的回答应为：D  D  D   True           accountant  \n1     C\\n        请说明理由。\\n        \\n         C  C   True           accountant  \n2     D\\n        请说明理由。\\n        \\n         D  D   True           accountant  \n3             A\\n        请说明理由。\\n        �  A  A   True           accountant  \n4     C\\n        请说明理由。\\n        \\n         C  C   True           accountant  \n...                                    ... .. ..    ...                  ...  \n1341  A\\n        请说明理由。\\n        \\n         A  A   True  veterinary_medicine  \n1342                   D\\n        请说明理由： 本  D  D   True  veterinary_medicine  \n1343                   C\\n        请说明理由： 该  C  A  False  veterinary_medicine  \n1344  C\\n        请说明理由。\\n        \\n         C  C   True  veterinary_medicine  \n1345          C\\n        请说明理由：\\n        �  C  C   True  veterinary_medicine  \n\n[1346 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...</td>\n      <td>D\\n        你的回答应为：D</td>\n      <td>D</td>\n      <td>D</td>\n      <td>True</td>\n      <td>accountant</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...</td>\n      <td>C\\n        请说明理由。\\n        \\n</td>\n      <td>C</td>\n      <td>C</td>\n      <td>True</td>\n      <td>accountant</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...</td>\n      <td>D\\n        请说明理由。\\n        \\n</td>\n      <td>D</td>\n      <td>D</td>\n      <td>True</td>\n      <td>accountant</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...</td>\n      <td>A\\n        请说明理由。\\n        �</td>\n      <td>A</td>\n      <td>A</td>\n      <td>True</td>\n      <td>accountant</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...</td>\n      <td>C\\n        请说明理由。\\n        \\n</td>\n      <td>C</td>\n      <td>C</td>\n      <td>True</td>\n      <td>accountant</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1341</th>\n      <td>请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...</td>\n      <td>A\\n        请说明理由。\\n        \\n</td>\n      <td>A</td>\n      <td>A</td>\n      <td>True</td>\n      <td>veterinary_medicine</td>\n    </tr>\n    <tr>\n      <th>1342</th>\n      <td>请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...</td>\n      <td>D\\n        请说明理由： 本</td>\n      <td>D</td>\n      <td>D</td>\n      <td>True</td>\n      <td>veterinary_medicine</td>\n    </tr>\n    <tr>\n      <th>1343</th>\n      <td>请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...</td>\n      <td>C\\n        请说明理由： 该</td>\n      <td>C</td>\n      <td>A</td>\n      <td>False</td>\n      <td>veterinary_medicine</td>\n    </tr>\n    <tr>\n      <th>1344</th>\n      <td>请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...</td>\n      <td>C\\n        请说明理由。\\n        \\n</td>\n      <td>C</td>\n      <td>C</td>\n      <td>True</td>\n      <td>veterinary_medicine</td>\n    </tr>\n    <tr>\n      <th>1345</th>\n      <td>请你扮演一位专业的考试助手，阅读下面的单项选择题，并根据内容在四个选项中选出最合适的一个。\\...</td>\n      <td>C\\n        请说明理由：\\n        �</td>\n      <td>C</td>\n      <td>C</td>\n      <td>True</td>\n      <td>veterinary_medicine</td>\n    </tr>\n  </tbody>\n</table>\n<p>1346 rows × 6 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(answer_sheet)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-06T13:20:26.789174Z",
     "start_time": "2025-06-06T13:20:26.777174800Z"
    }
   },
   "id": "a2795484e22285b5",
   "execution_count": 21
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
